Traceback (most recent call last):
  File "second_clf.py", line 6, in <module>
    from adv_function import *
  File "/home/zhiyu/DeepSuite/adversarial/adv_function/__init__.py", line 5, in <module>
    from .attention import *
  File "/home/zhiyu/DeepSuite/adversarial/adv_function/attention.py", line 6, in <module>
    from torch.utils.data import DataLoader, Dataset
  File "/home/zhiyu/anaconda3/envs/GPU/lib/python3.6/site-packages/torch/__init__.py", line 190, in <module>
    from torch._C import *
RuntimeError: KeyboardInterrupt: 
start time : Wed Mar  3 21:21:45 2021
Namespace(dataset='mnist', k_kmnc=10, k_nc=0.75, k_tknc=3, model='leNet_4', path0='/media/data0/DeepSuite', path1='/media/data1/DeepSuite', sa_layer=-1, sa_n=1000)
load leNet_4...
2021-03-03 21:21:46.555258: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-03-03 21:21:46.589512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:25:00.0 name: Quadro RTX 8000 computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.43GiB deviceMemoryBandwidth: 625.94GiB/s
2021-03-03 21:21:46.589589: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-03-03 21:21:46.591083: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-03-03 21:21:46.592690: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-03-03 21:21:46.592996: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-03-03 21:21:46.594445: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-03-03 21:21:46.595109: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-03-03 21:21:46.598148: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 21:21:46.603041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2021-03-03 21:21:46.603483: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2021-03-03 21:21:46.624664: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2600000000 Hz
2021-03-03 21:21:46.638405: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e57dc93260 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-03-03 21:21:46.638474: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-03-03 21:21:46.646365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:25:00.0 name: Quadro RTX 8000 computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.43GiB deviceMemoryBandwidth: 625.94GiB/s
2021-03-03 21:21:46.646469: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-03-03 21:21:46.646510: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-03-03 21:21:46.646544: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-03-03 21:21:46.646577: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-03-03 21:21:46.646610: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-03-03 21:21:46.646642: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-03-03 21:21:46.646675: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 21:21:46.656609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2021-03-03 21:21:46.656666: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-03-03 21:21:50.823027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-03 21:21:50.823082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2021-03-03 21:21:50.823090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2021-03-03 21:21:50.831199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 44688 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:25:00.0, compute capability: 7.5)
2021-03-03 21:21:50.834566: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e62d408070 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-03-03 21:21:50.834601: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5
start time : Wed Mar  3 21:21:51 2021
Namespace(dataset='mnist', k_kmnc=10, k_nc=0.75, k_tknc=3, model='leNet_5', path0='/media/data0/DeepSuite', path1='/media/data1/DeepSuite', sa_layer=-1, sa_n=1000)
load leNet_5...
2021-03-03 21:21:51.871268: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-03-03 21:21:51.907862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:25:00.0 name: Quadro RTX 8000 computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.43GiB deviceMemoryBandwidth: 625.94GiB/s
2021-03-03 21:21:51.907947: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-03-03 21:21:51.909573: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-03-03 21:21:51.911327: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-03-03 21:21:51.911653: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-03-03 21:21:51.913226: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-03-03 21:21:51.913938: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-03-03 21:21:51.917222: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 21:21:51.919544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2021-03-03 21:21:51.919990: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2021-03-03 21:21:51.941248: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2600000000 Hz
2021-03-03 21:21:51.953595: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5582ec4b77a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-03-03 21:21:51.953666: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-03-03 21:21:51.957239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:25:00.0 name: Quadro RTX 8000 computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.43GiB deviceMemoryBandwidth: 625.94GiB/s
2021-03-03 21:21:51.957296: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-03-03 21:21:51.957325: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-03-03 21:21:51.957338: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-03-03 21:21:51.957350: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-03-03 21:21:51.957362: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-03-03 21:21:51.957373: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-03-03 21:21:51.957386: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 21:21:51.961312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2021-03-03 21:21:51.961361: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
/media/data1/DeepSuite/trained_models/mnist/leNet_4.h5
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
activation1 (Conv2D)         (None, 28, 28, 6)         156       
_________________________________________________________________
pool1 (MaxPooling2D)         (None, 14, 14, 6)         0         
_________________________________________________________________
activation2 (Conv2D)         (None, 14, 14, 16)        2416      
_________________________________________________________________
pool2 (MaxPooling2D)         (None, 7, 7, 16)          0         
_________________________________________________________________
flatten (Flatten)            (None, 784)               0         
_________________________________________________________________
fc (Dense)                   (None, 84)                65940     
_________________________________________________________________
dense (Dense)                (None, 10)                850       
_________________________________________________________________
predictions (Activation)     (None, 10)                0         
=================================================================
Total params: 69,362
Trainable params: 69,362
Non-trainable params: 0
_________________________________________________________________
None
  0%|          | 0/7 [00:00<?, ?it/s]2021-03-03 21:21:52.891808: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 21:21:54.461221: W tensorflow/stream_executor/gpu/asm_compiler.cc:116] *** WARNING *** You are using ptxas 9.1.108, which is older than 9.2.88. ptxas 9.x before 9.2.88 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You do not need to update to CUDA 9.2.88; cherry-picking the ptxas binary is sufficient.
2021-03-03 21:21:54.587473: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 65280, output: ptxas fatal   : Value 'sm_75' is not defined for option 'gpu-name'

Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
2021-03-03 21:21:56.568499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-03 21:21:56.568560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2021-03-03 21:21:56.568569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2021-03-03 21:21:56.572637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1163 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:25:00.0, compute capability: 7.5)
2021-03-03 21:21:56.575921: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558399bbcea0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-03-03 21:21:56.575961: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5
/media/data1/DeepSuite/trained_models/mnist/leNet_5.h5
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
activation1 (Conv2D)         (None, 28, 28, 6)         156       
_________________________________________________________________
pool1 (MaxPooling2D)         (None, 14, 14, 6)         0         
_________________________________________________________________
activation2 (Conv2D)         (None, 14, 14, 16)        2416      
_________________________________________________________________
pool2 (MaxPooling2D)         (None, 7, 7, 16)          0         
_________________________________________________________________
flatten (Flatten)            (None, 784)               0         
_________________________________________________________________
fc1 (Dense)                  (None, 120)               94200     
_________________________________________________________________
fc2 (Dense)                  (None, 84)                10164     
_________________________________________________________________
dense (Dense)                (None, 10)                850       
_________________________________________________________________
prediction (Activation)      (None, 10)                0         
=================================================================
Total params: 107,786
Trainable params: 107,786
Non-trainable params: 0
_________________________________________________________________
None
  0%|          | 0/8 [00:00<?, ?it/s]2021-03-03 21:21:57.559191: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-03-03 21:21:57.592851: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 21:21:57.807868: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2021-03-03 21:21:57.817141: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2021-03-03 21:21:57.823245: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
  0%|          | 0/8 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "second_clf.py", line 168, in <module>
    main()
  File "second_clf.py", line 118, in main
    ori_train_traces, ori_test_traces, ori_train_y, ori_test_y = load_ori_traces(args.path0, args.path1, args.dataset, args.model, fitness)
  File "second_clf.py", line 99, in load_ori_traces
    train_traces = cal_samples_trace(model, x_train, fitness)
  File "/home/zhiyu/DeepSuite/adversarial/adv_function/trace.py", line 51, in cal_samples_trace
    layer_output = temp_model.predict(dataset, batch_size=batch_size, verbose=0)
  File "/home/zhiyu/anaconda3/envs/GPU/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py", line 88, in _method_wrapper
    return method(self, *args, **kwargs)
  File "/home/zhiyu/anaconda3/envs/GPU/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py", line 1268, in predict
    tmp_batch_outputs = predict_function(iterator)
  File "/home/zhiyu/anaconda3/envs/GPU/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 580, in __call__
    result = self._call(*args, **kwds)
  File "/home/zhiyu/anaconda3/envs/GPU/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 650, in _call
    return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access
  File "/home/zhiyu/anaconda3/envs/GPU/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1665, in _filtered_call
    self.captured_inputs)
  File "/home/zhiyu/anaconda3/envs/GPU/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1746, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File "/home/zhiyu/anaconda3/envs/GPU/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 598, in call
    ctx=ctx)
  File "/home/zhiyu/anaconda3/envs/GPU/lib/python3.6/site-packages/tensorflow/python/eager/execute.py", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node model/activation1/Conv2D (defined at /home/zhiyu/DeepSuite/adversarial/adv_function/trace.py:51) ]] [Op:__inference_predict_function_458]

Function call stack:
predict_function

 14%|█▍        | 1/7 [00:13<01:21, 13.51s/it]start time : Wed Mar  3 21:22:06 2021
Namespace(dataset='mnist', k_kmnc=10, k_nc=0.75, k_tknc=3, model='leNet_5', path0='/media/data0/DeepSuite', path1='/media/data1/DeepSuite', sa_layer=-1, sa_n=1000)
load leNet_5...
2021-03-03 21:22:07.232833: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-03-03 21:22:07.263313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:5b:00.0 name: Quadro RTX 8000 computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.43GiB deviceMemoryBandwidth: 625.94GiB/s
2021-03-03 21:22:07.263399: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-03-03 21:22:07.264817: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-03-03 21:22:07.266375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-03-03 21:22:07.266683: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-03-03 21:22:07.268056: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-03-03 21:22:07.268716: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-03-03 21:22:07.271638: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 21:22:07.276490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2021-03-03 21:22:07.276909: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2021-03-03 21:22:07.298604: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2600000000 Hz
2021-03-03 21:22:07.304598: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558e6b872470 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-03-03 21:22:07.304632: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-03-03 21:22:07.307729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:5b:00.0 name: Quadro RTX 8000 computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.43GiB deviceMemoryBandwidth: 625.94GiB/s
2021-03-03 21:22:07.307788: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-03-03 21:22:07.307804: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-03-03 21:22:07.307825: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-03-03 21:22:07.307838: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-03-03 21:22:07.307849: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-03-03 21:22:07.307861: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-03-03 21:22:07.307873: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 21:22:07.313391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2021-03-03 21:22:07.313434: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
 29%|██▊       | 2/7 [00:17<00:38,  7.77s/it]2021-03-03 21:22:12.251604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-03 21:22:12.251660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2021-03-03 21:22:12.251668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2021-03-03 21:22:12.259337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 44688 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:5b:00.0, compute capability: 7.5)
2021-03-03 21:22:12.262278: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558f1afea1b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-03-03 21:22:12.262309: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5
/media/data1/DeepSuite/trained_models/mnist/leNet_5.h5
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
activation1 (Conv2D)         (None, 28, 28, 6)         156       
_________________________________________________________________
pool1 (MaxPooling2D)         (None, 14, 14, 6)         0         
_________________________________________________________________
activation2 (Conv2D)         (None, 14, 14, 16)        2416      
_________________________________________________________________
pool2 (MaxPooling2D)         (None, 7, 7, 16)          0         
_________________________________________________________________
flatten (Flatten)            (None, 784)               0         
_________________________________________________________________
fc1 (Dense)                  (None, 120)               94200     
_________________________________________________________________
fc2 (Dense)                  (None, 84)                10164     
_________________________________________________________________
dense (Dense)                (None, 10)                850       
_________________________________________________________________
prediction (Activation)      (None, 10)                0         
=================================================================
Total params: 107,786
Trainable params: 107,786
Non-trainable params: 0
_________________________________________________________________
None
  0%|          | 0/8 [00:00<?, ?it/s]2021-03-03 21:22:14.416406: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 21:22:16.365638: W tensorflow/stream_executor/gpu/asm_compiler.cc:116] *** WARNING *** You are using ptxas 9.1.108, which is older than 9.2.88. ptxas 9.x before 9.2.88 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You do not need to update to CUDA 9.2.88; cherry-picking the ptxas binary is sufficient.
2021-03-03 21:22:16.587416: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 65280, output: ptxas fatal   : Value 'sm_75' is not defined for option 'gpu-name'

Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
2021-03-03 21:22:21.755127: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
start time : Wed Mar  3 21:22:24 2021
Namespace(dataset='cifar10', k_kmnc=10, k_nc=0.75, k_tknc=3, model='resnet20_cifar10', path0='/media/data0/DeepSuite', path1='/media/data1/DeepSuite', sa_layer=-1, sa_n=1000)
 43%|████▎     | 3/7 [00:35<00:49, 12.41s/it]load resnet20_cifar10...
2021-03-03 21:22:29.962380: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-03-03 21:22:29.989719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:9b:00.0 name: Quadro RTX 8000 computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.43GiB deviceMemoryBandwidth: 625.94GiB/s
2021-03-03 21:22:29.989804: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-03-03 21:22:29.991245: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-03-03 21:22:29.992685: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-03-03 21:22:29.992985: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-03-03 21:22:29.994431: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-03-03 21:22:29.995104: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-03-03 21:22:29.998292: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 21:22:30.002333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2021-03-03 21:22:30.002747: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2021-03-03 21:22:30.042002: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2600000000 Hz
2021-03-03 21:22:30.049536: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556789e961e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-03-03 21:22:30.049572: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-03-03 21:22:30.052314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:9b:00.0 name: Quadro RTX 8000 computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.43GiB deviceMemoryBandwidth: 625.94GiB/s
2021-03-03 21:22:30.052365: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-03-03 21:22:30.052379: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-03-03 21:22:30.052388: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-03-03 21:22:30.052398: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-03-03 21:22:30.052407: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-03-03 21:22:30.052416: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-03-03 21:22:30.052436: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 21:22:30.056454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2021-03-03 21:22:30.056492: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
 12%|█▎        | 1/8 [00:19<02:15, 19.36s/it]start time : Wed Mar  3 21:22:37 2021
Namespace(dataset='cifar10', k_kmnc=10, k_nc=0.75, k_tknc=3, model='resnet50_cifar10', path0='/media/data0/DeepSuite', path1='/media/data1/DeepSuite', sa_layer=-1, sa_n=1000)
 25%|██▌       | 2/8 [00:23<01:01, 10.32s/it] 57%|█████▋    | 4/7 [00:45<00:34, 11.52s/it] 71%|███████▏  | 5/7 [00:46<00:15,  7.71s/it] 86%|████████▌ | 6/7 [00:47<00:05,  5.40s/it]2021-03-03 21:22:40.179730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-03 21:22:40.179804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2021-03-03 21:22:40.179812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2021-03-03 21:22:40.187321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 33063 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:9b:00.0, compute capability: 7.5)
2021-03-03 21:22:40.190255: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5568377b5340 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-03-03 21:22:40.190317: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5
100%|██████████| 7/7 [00:48<00:00,  3.93s/it]100%|██████████| 7/7 [00:48<00:00,  6.88s/it]
  0%|          | 0/7 [00:00<?, ?it/s]load resnet50_cifar10...
2021-03-03 21:22:42.983555: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-03-03 21:22:43.011517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:c8:00.0 name: Quadro RTX 8000 computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.43GiB deviceMemoryBandwidth: 625.94GiB/s
2021-03-03 21:22:43.011639: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-03-03 21:22:43.013143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-03-03 21:22:43.014818: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-03-03 21:22:43.015151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-03-03 21:22:43.016596: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-03-03 21:22:43.017246: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-03-03 21:22:43.020342: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 21:22:43.025282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2021-03-03 21:22:43.025702: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2021-03-03 21:22:43.061839: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2600000000 Hz
2021-03-03 21:22:43.072354: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558eb59e1460 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-03-03 21:22:43.072426: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-03-03 21:22:43.078755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:c8:00.0 name: Quadro RTX 8000 computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.43GiB deviceMemoryBandwidth: 625.94GiB/s
2021-03-03 21:22:43.078852: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-03-03 21:22:43.078870: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-03-03 21:22:43.078882: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-03-03 21:22:43.078893: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-03-03 21:22:43.078904: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-03-03 21:22:43.078915: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-03-03 21:22:43.078928: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 21:22:43.084771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2021-03-03 21:22:43.084839: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
/media/data1/DeepSuite/trained_models/cifar10/resnet20_cifar10.h5
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 16)   0           activation_1[0][0]               
                                                                 batch_normalization_3[0][0]      
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 32, 32, 16)   2320        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 32, 32, 16)   2320        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 16)   0           activation_3[0][0]               
                                                                 batch_normalization_5[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 32, 32, 16)   2320        activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 32, 32, 16)   2320        activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          conv2d_7[0][0]                   
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 16)   0           activation_5[0][0]               
                                                                 batch_normalization_7[0][0]      
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 16, 16, 32)   4640        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 16, 16, 32)   128         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 16, 16, 32)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 16, 16, 32)   9248        activation_8[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 16, 16, 32)   544         activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 16, 16, 32)   128         conv2d_9[0][0]                   
__________________________________________________________________________________________________
add_4 (Add)                     (None, 16, 16, 32)   0           conv2d_10[0][0]                  
                                                                 batch_normalization_9[0][0]      
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 16, 16, 32)   0           add_4[0][0]                      
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 16, 16, 32)   9248        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 16, 16, 32)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 16, 16, 32)   9248        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_12[0][0]                  
__________________________________________________________________________________________________
add_5 (Add)                     (None, 16, 16, 32)   0           activation_9[0][0]               
                                                                 batch_normalization_11[0][0]     
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]                      
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 16, 16, 32)   9248        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 16, 16, 32)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 16, 16, 32)   9248        activation_12[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 16, 16, 32)   128         conv2d_14[0][0]                  
__________________________________________________________________________________________________
add_6 (Add)                     (None, 16, 16, 32)   0           activation_11[0][0]              
                                                                 batch_normalization_13[0][0]     
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 16, 16, 32)   0           add_6[0][0]                      
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 8, 8, 64)     18496       activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 8, 8, 64)     256         conv2d_15[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 8, 8, 64)     0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 8, 8, 64)     36928       activation_14[0][0]              
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 8, 8, 64)     2112        activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 8, 8, 64)     256         conv2d_16[0][0]                  
__________________________________________________________________________________________________
add_7 (Add)                     (None, 8, 8, 64)     0           conv2d_17[0][0]                  
                                                                 batch_normalization_15[0][0]     
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 8, 8, 64)     0           add_7[0][0]                      
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 8, 8, 64)     36928       activation_15[0][0]              
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 8, 8, 64)     256         conv2d_18[0][0]                  
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 8, 8, 64)     0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 8, 8, 64)     36928       activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 8, 8, 64)     256         conv2d_19[0][0]                  
__________________________________________________________________________________________________
add_8 (Add)                     (None, 8, 8, 64)     0           activation_15[0][0]              
                                                                 batch_normalization_17[0][0]     
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 8, 8, 64)     0           add_8[0][0]                      
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 8, 8, 64)     36928       activation_17[0][0]              
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 8, 8, 64)     256         conv2d_20[0][0]                  
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 8, 8, 64)     0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 8, 8, 64)     36928       activation_18[0][0]              
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 8, 8, 64)     256         conv2d_21[0][0]                  
__________________________________________________________________________________________________
add_9 (Add)                     (None, 8, 8, 64)     0           activation_17[0][0]              
                                                                 batch_normalization_19[0][0]     
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 8, 8, 64)     0           add_9[0][0]                      
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_19[0][0]              
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 10)           650         flatten_1[0][0]                  
==================================================================================================
Total params: 274,442
Trainable params: 273,066
Non-trainable params: 1,376
__________________________________________________________________________________________________
None
  0%|          | 0/70 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:05<00:30,  5.10s/it]2021-03-03 21:22:46.235314: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
 29%|██▊       | 2/7 [00:05<00:12,  2.49s/it]2021-03-03 21:22:48.189879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-03 21:22:48.189933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2021-03-03 21:22:48.189941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2021-03-03 21:22:48.197457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 44688 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:c8:00.0, compute capability: 7.5)
2021-03-03 21:22:48.199762: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558f640a8ac0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-03-03 21:22:48.199799: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5
2021-03-03 21:22:50.341245: W tensorflow/stream_executor/gpu/asm_compiler.cc:116] *** WARNING *** You are using ptxas 9.1.108, which is older than 9.2.88. ptxas 9.x before 9.2.88 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You do not need to update to CUDA 9.2.88; cherry-picking the ptxas binary is sufficient.
2021-03-03 21:22:50.570197: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 65280, output: ptxas fatal   : Value 'sm_75' is not defined for option 'gpu-name'

Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
/media/data1/DeepSuite/trained_models/cifar10/resnet50_cifar10.h5
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 16)   0           activation_1[0][0]               
                                                                 batch_normalization_3[0][0]      
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 32, 32, 16)   2320        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 32, 32, 16)   2320        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 16)   0           activation_3[0][0]               
                                                                 batch_normalization_5[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 32, 32, 16)   2320        activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 32, 32, 16)   2320        activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          conv2d_7[0][0]                   
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 16)   0           activation_5[0][0]               
                                                                 batch_normalization_7[0][0]      
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 32, 32, 16)   2320        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 32, 32, 16)   2320        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]                   
__________________________________________________________________________________________________
add_4 (Add)                     (None, 32, 32, 16)   0           activation_7[0][0]               
                                                                 batch_normalization_9[0][0]      
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 32, 32, 16)   0           add_4[0][0]                      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 32, 32, 16)   2320        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 32, 32, 16)   64          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 32, 32, 16)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 32, 32, 16)   2320        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 32, 32, 16)   64          conv2d_11[0][0]                  
__________________________________________________________________________________________________
add_5 (Add)                     (None, 32, 32, 16)   0           activation_9[0][0]               
                                                                 batch_normalization_11[0][0]     
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 32, 32, 16)   0           add_5[0][0]                      
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 32, 32, 16)   2320        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 32, 32, 16)   64          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 32, 32, 16)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 32, 32, 16)   2320        activation_12[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 32, 32, 16)   64          conv2d_13[0][0]                  
__________________________________________________________________________________________________
add_6 (Add)                     (None, 32, 32, 16)   0           activation_11[0][0]              
                                                                 batch_normalization_13[0][0]     
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 32, 32, 16)   0           add_6[0][0]                      
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 32, 32, 16)   2320        activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 32, 32, 16)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 32, 32, 16)   2320        activation_14[0][0]              
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 32, 32, 16)   64          conv2d_15[0][0]                  
__________________________________________________________________________________________________
add_7 (Add)                     (None, 32, 32, 16)   0           activation_13[0][0]              
                                                                 batch_normalization_15[0][0]     
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 32, 32, 16)   0           add_7[0][0]                      
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 32, 32, 16)   2320        activation_15[0][0]              
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 32, 32, 16)   64          conv2d_16[0][0]                  
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 32, 32, 16)   0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 32, 32, 16)   2320        activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 32, 32, 16)   64          conv2d_17[0][0]                  
__________________________________________________________________________________________________
add_8 (Add)                     (None, 32, 32, 16)   0           activation_15[0][0]              
                                                                 batch_normalization_17[0][0]     
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 32, 32, 16)   0           add_8[0][0]                      
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 32, 32, 16)   2320        activation_17[0][0]              
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 32, 32, 16)   64          conv2d_18[0][0]                  
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 32, 32, 16)   0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 32, 32, 16)   2320        activation_18[0][0]              
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 32, 32, 16)   64          conv2d_19[0][0]                  
__________________________________________________________________________________________________
add_9 (Add)                     (None, 32, 32, 16)   0           activation_17[0][0]              
                                                                 batch_normalization_19[0][0]     
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 32, 32, 16)   0           add_9[0][0]                      
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 16, 16, 32)   4640        activation_19[0][0]              
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 16, 16, 32)   128         conv2d_20[0][0]                  
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 16, 16, 32)   0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 16, 16, 32)   9248        activation_20[0][0]              
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 16, 16, 32)   544         activation_19[0][0]              
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 16, 16, 32)   128         conv2d_21[0][0]                  
__________________________________________________________________________________________________
add_10 (Add)                    (None, 16, 16, 32)   0           conv2d_22[0][0]                  
                                                                 batch_normalization_21[0][0]     
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 16, 16, 32)   0           add_10[0][0]                     
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 16, 16, 32)   9248        activation_21[0][0]              
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 16, 16, 32)   128         conv2d_23[0][0]                  
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 16, 16, 32)   0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 16, 16, 32)   9248        activation_22[0][0]              
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 16, 16, 32)   128         conv2d_24[0][0]                  
__________________________________________________________________________________________________
add_11 (Add)                    (None, 16, 16, 32)   0           activation_21[0][0]              
                                                                 batch_normalization_23[0][0]     
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 16, 16, 32)   0           add_11[0][0]                     
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 16, 16, 32)   9248        activation_23[0][0]              
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 16, 16, 32)   128         conv2d_25[0][0]                  
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 16, 16, 32)   0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 16, 16, 32)   9248        activation_24[0][0]              
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 16, 16, 32)   128         conv2d_26[0][0]                  
__________________________________________________________________________________________________
add_12 (Add)                    (None, 16, 16, 32)   0           activation_23[0][0]              
                                                                 batch_normalization_25[0][0]     
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 16, 16, 32)   0           add_12[0][0]                     
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 16, 16, 32)   9248        activation_25[0][0]              
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 16, 16, 32)   128         conv2d_27[0][0]                  
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 16, 16, 32)   0           batch_normalization_26[0][0]     
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 16, 16, 32)   9248        activation_26[0][0]              
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 16, 16, 32)   128         conv2d_28[0][0]                  
__________________________________________________________________________________________________
add_13 (Add)                    (None, 16, 16, 32)   0           activation_25[0][0]              
                                                                 batch_normalization_27[0][0]     
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 16, 16, 32)   0           add_13[0][0]                     
__________________________________________________________________________________________________
conv2d_29 (Conv2D)              (None, 16, 16, 32)   9248        activation_27[0][0]              
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 16, 16, 32)   128         conv2d_29[0][0]                  
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 16, 16, 32)   0           batch_normalization_28[0][0]     
__________________________________________________________________________________________________
conv2d_30 (Conv2D)              (None, 16, 16, 32)   9248        activation_28[0][0]              
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 16, 16, 32)   128         conv2d_30[0][0]                  
__________________________________________________________________________________________________
add_14 (Add)                    (None, 16, 16, 32)   0           activation_27[0][0]              
                                                                 batch_normalization_29[0][0]     
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 16, 16, 32)   0           add_14[0][0]                     
__________________________________________________________________________________________________
conv2d_31 (Conv2D)              (None, 16, 16, 32)   9248        activation_29[0][0]              
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 16, 16, 32)   128         conv2d_31[0][0]                  
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 16, 16, 32)   0           batch_normalization_30[0][0]     
__________________________________________________________________________________________________
conv2d_32 (Conv2D)              (None, 16, 16, 32)   9248        activation_30[0][0]              
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 16, 16, 32)   128         conv2d_32[0][0]                  
__________________________________________________________________________________________________
add_15 (Add)                    (None, 16, 16, 32)   0           activation_29[0][0]              
                                                                 batch_normalization_31[0][0]     
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 16, 16, 32)   0           add_15[0][0]                     
__________________________________________________________________________________________________
conv2d_33 (Conv2D)              (None, 16, 16, 32)   9248        activation_31[0][0]              
__________________________________________________________________________________________________
batch_normalization_32 (BatchNo (None, 16, 16, 32)   128         conv2d_33[0][0]                  
__________________________________________________________________________________________________
activation_32 (Activation)      (None, 16, 16, 32)   0           batch_normalization_32[0][0]     
__________________________________________________________________________________________________
conv2d_34 (Conv2D)              (None, 16, 16, 32)   9248        activation_32[0][0]              
__________________________________________________________________________________________________
batch_normalization_33 (BatchNo (None, 16, 16, 32)   128         conv2d_34[0][0]                  
__________________________________________________________________________________________________
add_16 (Add)                    (None, 16, 16, 32)   0           activation_31[0][0]              
                                                                 batch_normalization_33[0][0]     
__________________________________________________________________________________________________
activation_33 (Activation)      (None, 16, 16, 32)   0           add_16[0][0]                     
__________________________________________________________________________________________________
conv2d_35 (Conv2D)              (None, 16, 16, 32)   9248        activation_33[0][0]              
__________________________________________________________________________________________________
batch_normalization_34 (BatchNo (None, 16, 16, 32)   128         conv2d_35[0][0]                  
__________________________________________________________________________________________________
activation_34 (Activation)      (None, 16, 16, 32)   0           batch_normalization_34[0][0]     
__________________________________________________________________________________________________
conv2d_36 (Conv2D)              (None, 16, 16, 32)   9248        activation_34[0][0]              
__________________________________________________________________________________________________
batch_normalization_35 (BatchNo (None, 16, 16, 32)   128         conv2d_36[0][0]                  
__________________________________________________________________________________________________
add_17 (Add)                    (None, 16, 16, 32)   0           activation_33[0][0]              
                                                                 batch_normalization_35[0][0]     
__________________________________________________________________________________________________
activation_35 (Activation)      (None, 16, 16, 32)   0           add_17[0][0]                     
__________________________________________________________________________________________________
conv2d_37 (Conv2D)              (None, 16, 16, 32)   9248        activation_35[0][0]              
__________________________________________________________________________________________________
batch_normalization_36 (BatchNo (None, 16, 16, 32)   128         conv2d_37[0][0]                  
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 16, 16, 32)   0           batch_normalization_36[0][0]     
__________________________________________________________________________________________________
conv2d_38 (Conv2D)              (None, 16, 16, 32)   9248        activation_36[0][0]              
__________________________________________________________________________________________________
batch_normalization_37 (BatchNo (None, 16, 16, 32)   128         conv2d_38[0][0]                  
__________________________________________________________________________________________________
add_18 (Add)                    (None, 16, 16, 32)   0           activation_35[0][0]              
                                                                 batch_normalization_37[0][0]     
__________________________________________________________________________________________________
activation_37 (Activation)      (None, 16, 16, 32)   0           add_18[0][0]                     
__________________________________________________________________________________________________
conv2d_39 (Conv2D)              (None, 8, 8, 64)     18496       activation_37[0][0]              
__________________________________________________________________________________________________
batch_normalization_38 (BatchNo (None, 8, 8, 64)     256         conv2d_39[0][0]                  
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 8, 8, 64)     0           batch_normalization_38[0][0]     
__________________________________________________________________________________________________
conv2d_40 (Conv2D)              (None, 8, 8, 64)     36928       activation_38[0][0]              
__________________________________________________________________________________________________
conv2d_41 (Conv2D)              (None, 8, 8, 64)     2112        activation_37[0][0]              
__________________________________________________________________________________________________
batch_normalization_39 (BatchNo (None, 8, 8, 64)     256         conv2d_40[0][0]                  
__________________________________________________________________________________________________
add_19 (Add)                    (None, 8, 8, 64)     0           conv2d_41[0][0]                  
                                                                 batch_normalization_39[0][0]     
__________________________________________________________________________________________________
activation_39 (Activation)      (None, 8, 8, 64)     0           add_19[0][0]                     
__________________________________________________________________________________________________
conv2d_42 (Conv2D)              (None, 8, 8, 64)     36928       activation_39[0][0]              
__________________________________________________________________________________________________
batch_normalization_40 (BatchNo (None, 8, 8, 64)     256         conv2d_42[0][0]                  
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 8, 8, 64)     0           batch_normalization_40[0][0]     
__________________________________________________________________________________________________
conv2d_43 (Conv2D)              (None, 8, 8, 64)     36928       activation_40[0][0]              
__________________________________________________________________________________________________
batch_normalization_41 (BatchNo (None, 8, 8, 64)     256         conv2d_43[0][0]                  
__________________________________________________________________________________________________
add_20 (Add)                    (None, 8, 8, 64)     0           activation_39[0][0]              
                                                                 batch_normalization_41[0][0]     
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 8, 8, 64)     0           add_20[0][0]                     
__________________________________________________________________________________________________
conv2d_44 (Conv2D)              (None, 8, 8, 64)     36928       activation_41[0][0]              
__________________________________________________________________________________________________
batch_normalization_42 (BatchNo (None, 8, 8, 64)     256         conv2d_44[0][0]                  
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 8, 8, 64)     0           batch_normalization_42[0][0]     
__________________________________________________________________________________________________
conv2d_45 (Conv2D)              (None, 8, 8, 64)     36928       activation_42[0][0]              
__________________________________________________________________________________________________
batch_normalization_43 (BatchNo (None, 8, 8, 64)     256         conv2d_45[0][0]                  
__________________________________________________________________________________________________
add_21 (Add)                    (None, 8, 8, 64)     0           activation_41[0][0]              
                                                                 batch_normalization_43[0][0]     
__________________________________________________________________________________________________
activation_43 (Activation)      (None, 8, 8, 64)     0           add_21[0][0]                     
__________________________________________________________________________________________________
conv2d_46 (Conv2D)              (None, 8, 8, 64)     36928       activation_43[0][0]              
__________________________________________________________________________________________________
batch_normalization_44 (BatchNo (None, 8, 8, 64)     256         conv2d_46[0][0]                  
__________________________________________________________________________________________________
activation_44 (Activation)      (None, 8, 8, 64)     0           batch_normalization_44[0][0]     
__________________________________________________________________________________________________
conv2d_47 (Conv2D)              (None, 8, 8, 64)     36928       activation_44[0][0]              
__________________________________________________________________________________________________
batch_normalization_45 (BatchNo (None, 8, 8, 64)     256         conv2d_47[0][0]                  
__________________________________________________________________________________________________
add_22 (Add)                    (None, 8, 8, 64)     0           activation_43[0][0]              
                                                                 batch_normalization_45[0][0]     
__________________________________________________________________________________________________
activation_45 (Activation)      (None, 8, 8, 64)     0           add_22[0][0]                     
__________________________________________________________________________________________________
conv2d_48 (Conv2D)              (None, 8, 8, 64)     36928       activation_45[0][0]              
__________________________________________________________________________________________________
batch_normalization_46 (BatchNo (None, 8, 8, 64)     256         conv2d_48[0][0]                  
__________________________________________________________________________________________________
activation_46 (Activation)      (None, 8, 8, 64)     0           batch_normalization_46[0][0]     
__________________________________________________________________________________________________
conv2d_49 (Conv2D)              (None, 8, 8, 64)     36928       activation_46[0][0]              
__________________________________________________________________________________________________
batch_normalization_47 (BatchNo (None, 8, 8, 64)     256         conv2d_49[0][0]                  
__________________________________________________________________________________________________
add_23 (Add)                    (None, 8, 8, 64)     0           activation_45[0][0]              
                                                                 batch_normalization_47[0][0]     
__________________________________________________________________________________________________
activation_47 (Activation)      (None, 8, 8, 64)     0           add_23[0][0]                     
__________________________________________________________________________________________________
conv2d_50 (Conv2D)              (None, 8, 8, 64)     36928       activation_47[0][0]              
__________________________________________________________________________________________________
batch_normalization_48 (BatchNo (None, 8, 8, 64)     256         conv2d_50[0][0]                  
__________________________________________________________________________________________________
activation_48 (Activation)      (None, 8, 8, 64)     0           batch_normalization_48[0][0]     
__________________________________________________________________________________________________
conv2d_51 (Conv2D)              (None, 8, 8, 64)     36928       activation_48[0][0]              
__________________________________________________________________________________________________
batch_normalization_49 (BatchNo (None, 8, 8, 64)     256         conv2d_51[0][0]                  
__________________________________________________________________________________________________
add_24 (Add)                    (None, 8, 8, 64)     0           activation_47[0][0]              
                                                                 batch_normalization_49[0][0]     
__________________________________________________________________________________________________
activation_49 (Activation)      (None, 8, 8, 64)     0           add_24[0][0]                     
__________________________________________________________________________________________________
conv2d_52 (Conv2D)              (None, 8, 8, 64)     36928       activation_49[0][0]              
__________________________________________________________________________________________________
batch_normalization_50 (BatchNo (None, 8, 8, 64)     256         conv2d_52[0][0]                  
__________________________________________________________________________________________________
activation_50 (Activation)      (None, 8, 8, 64)     0           batch_normalization_50[0][0]     
__________________________________________________________________________________________________
conv2d_53 (Conv2D)              (None, 8, 8, 64)     36928       activation_50[0][0]              
__________________________________________________________________________________________________
batch_normalization_51 (BatchNo (None, 8, 8, 64)     256         conv2d_53[0][0]                  
__________________________________________________________________________________________________
add_25 (Add)                    (None, 8, 8, 64)     0           activation_49[0][0]              
                                                                 batch_normalization_51[0][0]     
__________________________________________________________________________________________________
activation_51 (Activation)      (None, 8, 8, 64)     0           add_25[0][0]                     
__________________________________________________________________________________________________
conv2d_54 (Conv2D)              (None, 8, 8, 64)     36928       activation_51[0][0]              
__________________________________________________________________________________________________
batch_normalization_52 (BatchNo (None, 8, 8, 64)     256         conv2d_54[0][0]                  
__________________________________________________________________________________________________
activation_52 (Activation)      (None, 8, 8, 64)     0           batch_normalization_52[0][0]     
__________________________________________________________________________________________________
conv2d_55 (Conv2D)              (None, 8, 8, 64)     36928       activation_52[0][0]              
__________________________________________________________________________________________________
batch_normalization_53 (BatchNo (None, 8, 8, 64)     256         conv2d_55[0][0]                  
__________________________________________________________________________________________________
add_26 (Add)                    (None, 8, 8, 64)     0           activation_51[0][0]              
                                                                 batch_normalization_53[0][0]     
__________________________________________________________________________________________________
activation_53 (Activation)      (None, 8, 8, 64)     0           add_26[0][0]                     
__________________________________________________________________________________________________
conv2d_56 (Conv2D)              (None, 8, 8, 64)     36928       activation_53[0][0]              
__________________________________________________________________________________________________
batch_normalization_54 (BatchNo (None, 8, 8, 64)     256         conv2d_56[0][0]                  
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 8, 8, 64)     0           batch_normalization_54[0][0]     
__________________________________________________________________________________________________
conv2d_57 (Conv2D)              (None, 8, 8, 64)     36928       activation_54[0][0]              
__________________________________________________________________________________________________
batch_normalization_55 (BatchNo (None, 8, 8, 64)     256         conv2d_57[0][0]                  
__________________________________________________________________________________________________
add_27 (Add)                    (None, 8, 8, 64)     0           activation_53[0][0]              
                                                                 batch_normalization_55[0][0]     
__________________________________________________________________________________________________
activation_55 (Activation)      (None, 8, 8, 64)     0           add_27[0][0]                     
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_55[0][0]              
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 10)           650         flatten_1[0][0]                  
==================================================================================================
Total params: 861,770
Trainable params: 857,706
Non-trainable params: 4,064
__________________________________________________________________________________________________
None
  0%|          | 0/196 [00:00<?, ?it/s] 43%|████▎     | 3/7 [00:11<00:16,  4.06s/it]2021-03-03 21:22:52.594578: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 614400000 exceeds 10% of free system memory.
2021-03-03 21:22:53.213116: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
 57%|█████▋    | 4/7 [00:13<00:09,  3.01s/it] 71%|███████▏  | 5/7 [00:13<00:03,  1.98s/it] 86%|████████▌ | 6/7 [00:13<00:01,  1.35s/it]100%|██████████| 7/7 [00:13<00:00,  1.04it/s]100%|██████████| 7/7 [00:13<00:00,  1.93s/it]
2021-03-03 21:22:54.815155: W tensorflow/stream_executor/gpu/asm_compiler.cc:116] *** WARNING *** You are using ptxas 9.1.108, which is older than 9.2.88. ptxas 9.x before 9.2.88 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You do not need to update to CUDA 9.2.88; cherry-picking the ptxas binary is sufficient.
2021-03-03 21:22:54.980333: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 65280, output: ptxas fatal   : Value 'sm_75' is not defined for option 'gpu-name'

Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
2021-03-03 21:22:56.317494: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
 38%|███▊      | 3/8 [00:44<01:16, 15.33s/it]2021-03-03 21:22:59.863831: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-03-03 21:23:04.570213: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 3276800000 exceeds 10% of free system memory.
2021-03-03 21:23:06.581753: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 3276800000 exceeds 10% of free system memory.
 50%|█████     | 4/8 [00:54<00:53, 13.32s/it] 62%|██████▎   | 5/8 [00:55<00:26,  8.85s/it] 75%|███████▌  | 6/8 [00:56<00:12,  6.19s/it] 88%|████████▊ | 7/8 [00:57<00:04,  4.51s/it]100%|██████████| 8/8 [00:58<00:00,  3.41s/it]100%|██████████| 8/8 [00:58<00:00,  7.37s/it]
  0%|          | 0/8 [00:00<?, ?it/s] 12%|█▎        | 1/8 [00:06<00:48,  6.93s/it] 25%|██▌       | 2/8 [00:07<00:19,  3.27s/it]  1%|▏         | 1/70 [00:36<41:37, 36.20s/it]  1%|          | 1/196 [00:29<1:36:52, 29.81s/it]2021-03-03 21:23:22.649291: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 614400000 exceeds 10% of free system memory.
2021-03-03 21:23:23.641455: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 3276800000 exceeds 10% of free system memory.
2021-03-03 21:23:23.725346: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 3276800000 exceeds 10% of free system memory.
 38%|███▊      | 3/8 [00:15<00:26,  5.30s/it] 50%|█████     | 4/8 [00:17<00:15,  3.91s/it] 62%|██████▎   | 5/8 [00:17<00:07,  2.58s/it] 75%|███████▌  | 6/8 [00:17<00:03,  1.78s/it] 88%|████████▊ | 7/8 [00:17<00:01,  1.26s/it]100%|██████████| 8/8 [00:17<00:00,  1.08it/s]100%|██████████| 8/8 [00:17<00:00,  2.25s/it]
  1%|          | 2/196 [00:45<1:09:29, 21.49s/it]2021-03-03 21:23:38.098004: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 614400000 exceeds 10% of free system memory.
  3%|▎         | 2/70 [00:54<28:59, 25.58s/it]2021-03-03 21:23:41.591440: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 3276800000 exceeds 10% of free system memory.
  2%|▏         | 3/196 [00:58<56:22, 17.53s/it]    4%|▍         | 3/70 [01:08<22:56, 20.55s/it]2021-03-03 21:24:15.154468: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 3276800000 exceeds 10% of free system memory.
  2%|▏         | 4/196 [01:27<1:10:50, 22.14s/it]  6%|▌         | 4/70 [01:41<27:54, 25.38s/it]2021-03-03 21:24:28.943400: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 3276800000 exceeds 10% of free system memory.
  3%|▎         | 5/196 [01:40<1:00:16, 18.94s/it]  7%|▋         | 5/70 [01:56<23:17, 21.49s/it]  3%|▎         | 6/196 [01:52<52:20, 16.53s/it]    9%|▊         | 6/70 [02:10<20:09, 18.89s/it]  4%|▎         | 7/196 [02:07<50:44, 16.11s/it] 10%|█         | 7/70 [02:24<18:21, 17.48s/it]Traceback (most recent call last):
  File "second_clf.py", line 6, in <module>
    from adv_function import *
  File "/home/zhiyu/DeepSuite/adversarial/adv_function/__init__.py", line 2, in <module>
    from .attacks import *
  File "/home/zhiyu/DeepSuite/adversarial/adv_function/attacks.py", line 1, in <module>
    from art.attacks.evasion import ProjectedGradientDescent, \
  File "/home/zhiyu/anaconda3/envs/GPU/lib/python3.6/site-packages/art/__init__.py", line 7, in <module>
    from art import attacks
  File "/home/zhiyu/anaconda3/envs/GPU/lib/python3.6/site-packages/art/attacks/__init__.py", line 8, in <module>
    from art.attacks import evasion
  File "/home/zhiyu/anaconda3/envs/GPU/lib/python3.6/site-packages/art/attacks/evasion/__init__.py", line 4, in <module>
    from art.attacks.evasion.adversarial_patch.adversarial_patch import AdversarialPatch
  File "/home/zhiyu/anaconda3/envs/GPU/lib/python3.6/site-packages/art/attacks/evasion/adversarial_patch/adversarial_patch.py", line 31, in <module>
    from art.attacks.evasion.adversarial_patch.adversarial_patch_numpy import AdversarialPatchNumpy
  File "/home/zhiyu/anaconda3/envs/GPU/lib/python3.6/site-packages/art/attacks/evasion/adversarial_patch/adversarial_patch_numpy.py", line 33, in <module>
    from tqdm.auto import trange
  File "/home/zhiyu/anaconda3/envs/GPU/lib/python3.6/site-packages/tqdm/auto.py", line 29, in <module>
    from .asyncio import tqdm as asyncio_tqdm
  File "/home/zhiyu/anaconda3/envs/GPU/lib/python3.6/site-packages/tqdm/asyncio.py", line 10, in <module>
    import asyncio
  File "/home/zhiyu/anaconda3/envs/GPU/lib/python3.6/asyncio/__init__.py", line 28, in <module>
    from .streams import *
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 779, in get_code
  File "<frozen importlib._bootstrap_external>", line 487, in _compile_bytecode
KeyboardInterrupt
  4%|▍         | 8/196 [02:21<48:30, 15.48s/it]start time : Wed Mar  3 21:25:15 2021
Namespace(dataset='mnist', k_kmnc=10, k_nc=0.75, k_tknc=3, model='leNet_4', path0='/media/data0/DeepSuite', path1='/media/data1/DeepSuite', sa_layer=-1, sa_n=1000)
load leNet_4...
2021-03-03 21:25:16.411159: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-03-03 21:25:16.443166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:25:00.0 name: Quadro RTX 8000 computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.43GiB deviceMemoryBandwidth: 625.94GiB/s
2021-03-03 21:25:16.443243: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-03-03 21:25:16.446528: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-03-03 21:25:16.448654: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-03-03 21:25:16.450311: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-03-03 21:25:16.453894: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-03-03 21:25:16.454835: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-03-03 21:25:16.460017: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 21:25:16.464903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2021-03-03 21:25:16.465124: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2021-03-03 21:25:16.505926: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2600000000 Hz
2021-03-03 21:25:16.517447: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b68d2ef0a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-03-03 21:25:16.517478: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-03-03 21:25:16.521175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:25:00.0 name: Quadro RTX 8000 computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.43GiB deviceMemoryBandwidth: 625.94GiB/s
2021-03-03 21:25:16.521231: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-03-03 21:25:16.521251: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-03-03 21:25:16.521267: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-03-03 21:25:16.521283: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-03-03 21:25:16.521298: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-03-03 21:25:16.521313: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-03-03 21:25:16.521329: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 21:25:16.529134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2021-03-03 21:25:16.529170: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-03-03 21:25:20.855365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-03 21:25:20.855429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2021-03-03 21:25:20.855436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2021-03-03 21:25:20.863080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 44688 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:25:00.0, compute capability: 7.5)
2021-03-03 21:25:20.865557: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b73b0a4630 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-03-03 21:25:20.865600: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5
/media/data1/DeepSuite/trained_models/mnist/leNet_4.h5
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
activation1 (Conv2D)         (None, 28, 28, 6)         156       
_________________________________________________________________
pool1 (MaxPooling2D)         (None, 14, 14, 6)         0         
_________________________________________________________________
activation2 (Conv2D)         (None, 14, 14, 16)        2416      
_________________________________________________________________
pool2 (MaxPooling2D)         (None, 7, 7, 16)          0         
_________________________________________________________________
flatten (Flatten)            (None, 784)               0         
_________________________________________________________________
fc (Dense)                   (None, 84)                65940     
_________________________________________________________________
dense (Dense)                (None, 10)                850       
_________________________________________________________________
predictions (Activation)     (None, 10)                0         
=================================================================
Total params: 69,362
Trainable params: 69,362
Non-trainable params: 0
_________________________________________________________________
None
  0%|          | 0/7 [00:00<?, ?it/s]2021-03-03 21:25:22.611724: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
start time : Wed Mar  3 21:25:22 2021
Namespace(dataset='mnist', k_kmnc=10, k_nc=0.75, k_tknc=3, model='leNet_5', path0='/media/data0/DeepSuite', path1='/media/data1/DeepSuite', sa_layer=-1, sa_n=1000)
load leNet_5...
2021-03-03 21:25:23.533995: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-03-03 21:25:23.565307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:5b:00.0 name: Quadro RTX 8000 computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.43GiB deviceMemoryBandwidth: 625.94GiB/s
2021-03-03 21:25:23.565405: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-03-03 21:25:23.566958: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-03-03 21:25:23.568597: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-03-03 21:25:23.568899: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-03-03 21:25:23.570408: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-03-03 21:25:23.571104: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-03-03 21:25:23.574227: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 21:25:23.579187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2021-03-03 21:25:23.579716: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2021-03-03 21:25:23.610846: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2600000000 Hz
2021-03-03 21:25:23.617074: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5590acd005d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-03-03 21:25:23.617115: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-03-03 21:25:23.621028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:5b:00.0 name: Quadro RTX 8000 computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.43GiB deviceMemoryBandwidth: 625.94GiB/s
2021-03-03 21:25:23.621126: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-03-03 21:25:23.621142: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-03-03 21:25:23.621152: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-03-03 21:25:23.621162: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-03-03 21:25:23.621171: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-03-03 21:25:23.621180: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-03-03 21:25:23.621190: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 21:25:23.627797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2021-03-03 21:25:23.627856: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-03-03 21:25:24.759957: W tensorflow/stream_executor/gpu/asm_compiler.cc:116] *** WARNING *** You are using ptxas 9.1.108, which is older than 9.2.88. ptxas 9.x before 9.2.88 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You do not need to update to CUDA 9.2.88; cherry-picking the ptxas binary is sufficient.
2021-03-03 21:25:24.942590: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 65280, output: ptxas fatal   : Value 'sm_75' is not defined for option 'gpu-name'

Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
 11%|█▏        | 8/70 [02:41<17:43, 17.15s/it]2021-03-03 21:25:28.103175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-03 21:25:28.103224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2021-03-03 21:25:28.103232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2021-03-03 21:25:28.110901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 44688 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:5b:00.0, compute capability: 7.5)
2021-03-03 21:25:28.113685: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55915c472340 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-03-03 21:25:28.113719: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5
  5%|▍         | 9/196 [02:36<47:16, 15.17s/it]2021-03-03 21:25:29.446264: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
/media/data1/DeepSuite/trained_models/mnist/leNet_5.h5
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
activation1 (Conv2D)         (None, 28, 28, 6)         156       
_________________________________________________________________
pool1 (MaxPooling2D)         (None, 14, 14, 6)         0         
_________________________________________________________________
activation2 (Conv2D)         (None, 14, 14, 16)        2416      
_________________________________________________________________
pool2 (MaxPooling2D)         (None, 7, 7, 16)          0         
_________________________________________________________________
flatten (Flatten)            (None, 784)               0         
_________________________________________________________________
fc1 (Dense)                  (None, 120)               94200     
_________________________________________________________________
fc2 (Dense)                  (None, 84)                10164     
_________________________________________________________________
dense (Dense)                (None, 10)                850       
_________________________________________________________________
prediction (Activation)      (None, 10)                0         
=================================================================
Total params: 107,786
Trainable params: 107,786
Non-trainable params: 0
_________________________________________________________________
None
  0%|          | 0/8 [00:00<?, ?it/s]2021-03-03 21:25:29.996771: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 21:25:31.945510: W tensorflow/stream_executor/gpu/asm_compiler.cc:116] *** WARNING *** You are using ptxas 9.1.108, which is older than 9.2.88. ptxas 9.x before 9.2.88 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You do not need to update to CUDA 9.2.88; cherry-picking the ptxas binary is sufficient.
2021-03-03 21:25:32.119638: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 65280, output: ptxas fatal   : Value 'sm_75' is not defined for option 'gpu-name'

Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
2021-03-03 21:25:34.768322: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 1128960000 exceeds 10% of free system memory.
2021-03-03 21:25:36.124578: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-03-03 21:25:40.786439: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 1128960000 exceeds 10% of free system memory.
 14%|█▍        | 1/7 [00:19<01:55, 19.30s/it] 13%|█▎        | 9/70 [02:58<17:30, 17.23s/it]  5%|▌         | 10/196 [02:53<49:02, 15.82s/it] 12%|█▎        | 1/8 [00:16<01:57, 16.85s/it] 29%|██▊       | 2/7 [00:24<00:54, 10.93s/it]2021-03-03 21:25:47.099391: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 282240000 exceeds 10% of free system memory.
 25%|██▌       | 2/8 [00:21<00:59,  9.91s/it] 14%|█▍        | 10/70 [03:12<16:06, 16.11s/it]2021-03-03 21:25:57.293564: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 752640000 exceeds 10% of free system memory.
  6%|▌         | 11/196 [03:08<47:24, 15.38s/it]2021-03-03 21:26:01.655352: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 752640000 exceeds 10% of free system memory.
 43%|████▎     | 3/7 [00:45<01:01, 15.42s/it] 38%|███▊      | 3/8 [00:41<01:11, 14.34s/it] 16%|█▌        | 11/70 [03:26<15:26, 15.71s/it] 57%|█████▋    | 4/7 [00:54<00:39, 13.09s/it]  6%|▌         | 12/196 [03:24<48:22, 15.78s/it] 71%|███████▏  | 5/7 [00:56<00:18,  9.09s/it] 50%|█████     | 4/8 [00:50<00:49, 12.30s/it] 86%|████████▌ | 6/7 [00:58<00:06,  6.70s/it] 62%|██████▎   | 5/8 [00:52<00:25,  8.56s/it]100%|██████████| 7/7 [01:00<00:00,  5.16s/it]100%|██████████| 7/7 [01:00<00:00,  8.67s/it]
  0%|          | 0/7 [00:00<?, ?it/s] 75%|███████▌  | 6/8 [00:54<00:12,  6.30s/it] 17%|█▋        | 12/70 [03:39<14:18, 14.80s/it] 88%|████████▊ | 7/8 [00:56<00:04,  4.84s/it]100%|██████████| 8/8 [00:58<00:00,  3.91s/it]100%|██████████| 8/8 [00:58<00:00,  7.28s/it]
  0%|          | 0/8 [00:00<?, ?it/s] 14%|█▍        | 1/7 [00:06<00:38,  6.47s/it] 29%|██▊       | 2/7 [00:07<00:15,  3.18s/it]  7%|▋         | 13/196 [03:38<46:13, 15.16s/it] 12%|█▎        | 1/8 [00:06<00:42,  6.12s/it] 25%|██▌       | 2/8 [00:06<00:18,  3.03s/it] 43%|████▎     | 3/7 [00:14<00:20,  5.01s/it] 57%|█████▋    | 4/7 [00:16<00:10,  3.63s/it] 71%|███████▏  | 5/7 [00:16<00:04,  2.43s/it] 19%|█▊        | 13/70 [03:54<14:02, 14.78s/it] 86%|████████▌ | 6/7 [00:16<00:01,  1.72s/it]100%|██████████| 7/7 [00:17<00:00,  1.27s/it]100%|██████████| 7/7 [00:17<00:00,  2.44s/it]
 38%|███▊      | 3/8 [00:13<00:24,  4.83s/it] 50%|█████     | 4/8 [00:15<00:14,  3.60s/it] 62%|██████▎   | 5/8 [00:16<00:07,  2.44s/it]  7%|▋         | 14/196 [03:52<44:37, 14.71s/it] 75%|███████▌  | 6/8 [00:16<00:03,  1.75s/it] 88%|████████▊ | 7/8 [00:16<00:01,  1.31s/it]100%|██████████| 8/8 [00:17<00:00,  1.00s/it]100%|██████████| 8/8 [00:17<00:00,  2.15s/it]
 20%|██        | 14/70 [04:08<13:28, 14.44s/it]  8%|▊         | 15/196 [04:06<43:48, 14.52s/it] 21%|██▏       | 15/70 [04:20<12:37, 13.77s/it]  8%|▊         | 16/196 [04:19<42:02, 14.01s/it] 23%|██▎       | 16/70 [04:32<12:03, 13.40s/it]  9%|▊         | 17/196 [04:32<41:29, 13.91s/it] 24%|██▍       | 17/70 [04:45<11:35, 13.13s/it]  9%|▉         | 18/196 [04:44<39:37, 13.36s/it] 26%|██▌       | 18/70 [04:57<11:12, 12.94s/it] 10%|▉         | 19/196 [04:56<38:11, 12.94s/it] 27%|██▋       | 19/70 [05:10<10:54, 12.82s/it] 10%|█         | 20/196 [05:09<37:18, 12.72s/it] 29%|██▊       | 20/70 [05:22<10:35, 12.71s/it] 11%|█         | 21/196 [05:21<36:47, 12.61s/it] 30%|███       | 21/70 [05:35<10:28, 12.83s/it] 11%|█         | 22/196 [05:34<36:49, 12.70s/it] 31%|███▏      | 22/70 [05:48<10:11, 12.73s/it] 12%|█▏        | 23/196 [05:47<36:41, 12.72s/it] 33%|███▎      | 23/70 [06:01<10:05, 12.89s/it] 12%|█▏        | 24/196 [05:59<36:02, 12.57s/it] 34%|███▍      | 24/70 [06:14<09:47, 12.76s/it] 13%|█▎        | 25/196 [06:12<35:59, 12.63s/it] 13%|█▎        | 26/196 [06:25<36:03, 12.73s/it] 14%|█▍        | 27/196 [06:37<35:50, 12.72s/it] 36%|███▌      | 25/70 [06:49<14:39, 19.55s/it]start time : Wed Mar  3 21:29:41 2021
Namespace(dataset='mnist', k_kmnc=10, k_nc=0.75, k_tknc=3, model='leNet_1', path0='/media/data0/DeepSuite', path1='/media/data1/DeepSuite', sa_layer=-1, sa_n=1000)
load leNet_1...
2021-03-03 21:29:41.697325: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-03-03 21:29:41.735711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:5b:00.0 name: Quadro RTX 8000 computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.43GiB deviceMemoryBandwidth: 625.94GiB/s
2021-03-03 21:29:41.735796: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-03-03 21:29:41.737343: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-03-03 21:29:41.738808: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-03-03 21:29:41.739105: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-03-03 21:29:41.740664: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-03-03 21:29:41.741412: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-03-03 21:29:41.744544: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 21:29:41.749738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2021-03-03 21:29:41.750118: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2021-03-03 21:29:41.766961: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2600000000 Hz
2021-03-03 21:29:41.780158: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562910c77ef0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-03-03 21:29:41.780226: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-03-03 21:29:41.785932: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:5b:00.0 name: Quadro RTX 8000 computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.43GiB deviceMemoryBandwidth: 625.94GiB/s
2021-03-03 21:29:41.786040: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-03-03 21:29:41.786073: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-03-03 21:29:41.786097: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-03-03 21:29:41.786121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-03-03 21:29:41.786145: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-03-03 21:29:41.786168: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-03-03 21:29:41.786192: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 21:29:41.793760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2021-03-03 21:29:41.793814: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
 14%|█▍        | 28/196 [06:51<36:28, 13.02s/it]2021-03-03 21:29:46.387948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-03 21:29:46.388003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2021-03-03 21:29:46.388010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2021-03-03 21:29:46.396885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 44688 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:5b:00.0, compute capability: 7.5)
2021-03-03 21:29:46.399896: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5629c03ed780 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-03-03 21:29:46.399932: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5
/media/data1/DeepSuite/trained_models/mnist/leNet_1.h5
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
activation1 (Conv2D)         (None, 28, 28, 4)         104       
_________________________________________________________________
pool1 (MaxPooling2D)         (None, 14, 14, 4)         0         
_________________________________________________________________
activation2 (Conv2D)         (None, 14, 14, 12)        1212      
_________________________________________________________________
pool2 (MaxPooling2D)         (None, 7, 7, 12)          0         
_________________________________________________________________
flatten (Flatten)            (None, 588)               0         
_________________________________________________________________
dense (Dense)                (None, 10)                5890      
_________________________________________________________________
activation3 (Activation)     (None, 10)                0         
=================================================================
Total params: 7,206
Trainable params: 7,206
Non-trainable params: 0
_________________________________________________________________
None
  0%|          | 0/6 [00:00<?, ?it/s]2021-03-03 21:29:48.099360: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 21:29:49.838843: W tensorflow/stream_executor/gpu/asm_compiler.cc:116] *** WARNING *** You are using ptxas 9.1.108, which is older than 9.2.88. ptxas 9.x before 9.2.88 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You do not need to update to CUDA 9.2.88; cherry-picking the ptxas binary is sufficient.
2021-03-03 21:29:50.000369: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 65280, output: ptxas fatal   : Value 'sm_75' is not defined for option 'gpu-name'

Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
 37%|███▋      | 26/70 [07:06<13:45, 18.76s/it]2021-03-03 21:29:54.081194: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
 15%|█▍        | 29/196 [07:03<35:34, 12.78s/it]start time : Wed Mar  3 21:30:02 2021
Namespace(dataset='cifar10', k_kmnc=10, k_nc=0.75, k_tknc=3, model='resnet20_cifar10', path0='/media/data0/DeepSuite', path1='/media/data1/DeepSuite', sa_layer=-1, sa_n=1000)
 17%|█▋        | 1/6 [00:15<01:18, 15.61s/it]load resnet20_cifar10...
2021-03-03 21:30:06.089783: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-03-03 21:30:06.281449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:25:00.0 name: Quadro RTX 8000 computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.43GiB deviceMemoryBandwidth: 625.94GiB/s
2021-03-03 21:30:06.281547: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-03-03 21:30:06.282953: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-03-03 21:30:06.284431: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-03-03 21:30:06.284726: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-03-03 21:30:06.286104: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-03-03 21:30:06.286733: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-03-03 21:30:06.289571: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 21:30:06.294255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2021-03-03 21:30:06.294719: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2021-03-03 21:30:06.333903: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2600000000 Hz
2021-03-03 21:30:06.343785: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55eec22a64a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-03-03 21:30:06.343827: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-03-03 21:30:06.348382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:25:00.0 name: Quadro RTX 8000 computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.43GiB deviceMemoryBandwidth: 625.94GiB/s
2021-03-03 21:30:06.348449: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-03-03 21:30:06.348473: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-03-03 21:30:06.348492: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-03-03 21:30:06.348510: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-03-03 21:30:06.348529: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-03-03 21:30:06.348546: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-03-03 21:30:06.348565: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 21:30:06.355111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2021-03-03 21:30:06.355151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
 33%|███▎      | 2/6 [00:19<00:35,  8.82s/it] 39%|███▊      | 27/70 [07:24<13:13, 18.46s/it]2021-03-03 21:30:10.790961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-03 21:30:10.791017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2021-03-03 21:30:10.791024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2021-03-03 21:30:10.798136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 44688 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:25:00.0, compute capability: 7.5)
2021-03-03 21:30:10.800395: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ef70a48620 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-03-03 21:30:10.800436: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5
 15%|█▌        | 30/196 [07:19<37:30, 13.56s/it]/media/data1/DeepSuite/trained_models/cifar10/resnet20_cifar10.h5
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 16)   0           activation_1[0][0]               
                                                                 batch_normalization_3[0][0]      
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 32, 32, 16)   2320        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 32, 32, 16)   2320        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 16)   0           activation_3[0][0]               
                                                                 batch_normalization_5[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 32, 32, 16)   2320        activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 32, 32, 16)   2320        activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          conv2d_7[0][0]                   
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 16)   0           activation_5[0][0]               
                                                                 batch_normalization_7[0][0]      
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 16, 16, 32)   4640        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 16, 16, 32)   128         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 16, 16, 32)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 16, 16, 32)   9248        activation_8[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 16, 16, 32)   544         activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 16, 16, 32)   128         conv2d_9[0][0]                   
__________________________________________________________________________________________________
add_4 (Add)                     (None, 16, 16, 32)   0           conv2d_10[0][0]                  
                                                                 batch_normalization_9[0][0]      
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 16, 16, 32)   0           add_4[0][0]                      
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 16, 16, 32)   9248        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 16, 16, 32)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 16, 16, 32)   9248        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_12[0][0]                  
__________________________________________________________________________________________________
add_5 (Add)                     (None, 16, 16, 32)   0           activation_9[0][0]               
                                                                 batch_normalization_11[0][0]     
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]                      
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 16, 16, 32)   9248        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 16, 16, 32)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 16, 16, 32)   9248        activation_12[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 16, 16, 32)   128         conv2d_14[0][0]                  
__________________________________________________________________________________________________
add_6 (Add)                     (None, 16, 16, 32)   0           activation_11[0][0]              
                                                                 batch_normalization_13[0][0]     
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 16, 16, 32)   0           add_6[0][0]                      
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 8, 8, 64)     18496       activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 8, 8, 64)     256         conv2d_15[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 8, 8, 64)     0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 8, 8, 64)     36928       activation_14[0][0]              
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 8, 8, 64)     2112        activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 8, 8, 64)     256         conv2d_16[0][0]                  
__________________________________________________________________________________________________
add_7 (Add)                     (None, 8, 8, 64)     0           conv2d_17[0][0]                  
                                                                 batch_normalization_15[0][0]     
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 8, 8, 64)     0           add_7[0][0]                      
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 8, 8, 64)     36928       activation_15[0][0]              
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 8, 8, 64)     256         conv2d_18[0][0]                  
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 8, 8, 64)     0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 8, 8, 64)     36928       activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 8, 8, 64)     256         conv2d_19[0][0]                  
__________________________________________________________________________________________________
add_8 (Add)                     (None, 8, 8, 64)     0           activation_15[0][0]              
                                                                 batch_normalization_17[0][0]     
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 8, 8, 64)     0           add_8[0][0]                      
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 8, 8, 64)     36928       activation_17[0][0]              
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 8, 8, 64)     256         conv2d_20[0][0]                  
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 8, 8, 64)     0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 8, 8, 64)     36928       activation_18[0][0]              
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 8, 8, 64)     256         conv2d_21[0][0]                  
__________________________________________________________________________________________________
add_9 (Add)                     (None, 8, 8, 64)     0           activation_17[0][0]              
                                                                 batch_normalization_19[0][0]     
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 8, 8, 64)     0           add_9[0][0]                      
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_19[0][0]              
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 10)           650         flatten_1[0][0]                  
==================================================================================================
Total params: 274,442
Trainable params: 273,066
Non-trainable params: 1,376
__________________________________________________________________________________________________
None
  0%|          | 0/70 [00:00<?, ?it/s]2021-03-03 21:30:14.304038: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 21:30:16.315810: W tensorflow/stream_executor/gpu/asm_compiler.cc:116] *** WARNING *** You are using ptxas 9.1.108, which is older than 9.2.88. ptxas 9.x before 9.2.88 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You do not need to update to CUDA 9.2.88; cherry-picking the ptxas binary is sufficient.
2021-03-03 21:30:16.564454: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 65280, output: ptxas fatal   : Value 'sm_75' is not defined for option 'gpu-name'

Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
 16%|█▌        | 31/196 [07:31<36:11, 13.16s/it]2021-03-03 21:30:23.532389: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
 50%|█████     | 3/6 [00:38<00:40, 13.38s/it]2021-03-03 21:30:31.992750: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 3276800000 exceeds 10% of free system memory.
 67%|██████▋   | 4/6 [00:46<00:22, 11.27s/it] 83%|████████▎ | 5/6 [00:48<00:07,  7.88s/it]100%|██████████| 6/6 [00:50<00:00,  5.81s/it]100%|██████████| 6/6 [00:50<00:00,  8.36s/it]
  0%|          | 0/6 [00:00<?, ?it/s] 16%|█▋        | 32/196 [07:48<39:24, 14.42s/it] 17%|█▋        | 1/6 [00:05<00:29,  5.90s/it] 33%|███▎      | 2/6 [00:06<00:11,  2.82s/it]  1%|▏         | 1/70 [00:33<38:00, 33.06s/it]2021-03-03 21:30:48.663352: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 3276800000 exceeds 10% of free system memory.
 50%|█████     | 3/6 [00:13<00:13,  4.60s/it] 67%|██████▋   | 4/6 [00:14<00:06,  3.31s/it] 83%|████████▎ | 5/6 [00:14<00:02,  2.24s/it]100%|██████████| 6/6 [00:15<00:00,  1.58s/it]100%|██████████| 6/6 [00:15<00:00,  2.54s/it]
 17%|█▋        | 33/196 [08:05<40:48, 15.02s/it] 40%|████      | 28/70 [08:17<20:13, 28.90s/it]  3%|▎         | 2/70 [00:49<26:22, 23.28s/it]2021-03-03 21:31:04.812827: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 3276800000 exceeds 10% of free system memory.
start time : Wed Mar  3 21:31:07 2021
Namespace(dataset='cifar10', k_kmnc=10, k_nc=0.75, k_tknc=3, model='resnet50_cifar10', path0='/media/data0/DeepSuite', path1='/media/data1/DeepSuite', sa_layer=-1, sa_n=1000)
load resnet50_cifar10...
2021-03-03 21:31:11.929953: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-03-03 21:31:11.955688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:25:00.0 name: Quadro RTX 8000 computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.43GiB deviceMemoryBandwidth: 625.94GiB/s
2021-03-03 21:31:11.955777: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-03-03 21:31:11.957743: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-03-03 21:31:11.959754: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-03-03 21:31:11.960091: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-03-03 21:31:11.962278: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-03-03 21:31:11.963566: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-03-03 21:31:11.968114: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 21:31:11.970388: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2021-03-03 21:31:11.970920: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2021-03-03 21:31:12.025989: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2600000000 Hz
2021-03-03 21:31:12.043547: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564abde66520 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-03-03 21:31:12.043618: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-03-03 21:31:12.047081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:25:00.0 name: Quadro RTX 8000 computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.43GiB deviceMemoryBandwidth: 625.94GiB/s
2021-03-03 21:31:12.047197: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-03-03 21:31:12.047238: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-03-03 21:31:12.047273: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-03-03 21:31:12.047306: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-03-03 21:31:12.047340: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-03-03 21:31:12.047373: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-03-03 21:31:12.047407: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 21:31:12.051649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2021-03-03 21:31:12.051711: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
 17%|█▋        | 34/196 [08:20<40:49, 15.12s/it]2021-03-03 21:31:16.531214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-03 21:31:16.531284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2021-03-03 21:31:16.531293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2021-03-03 21:31:16.535234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1101 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:25:00.0, compute capability: 7.5)
2021-03-03 21:31:16.538292: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564b6d0c28e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-03-03 21:31:16.538331: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5
/media/data1/DeepSuite/trained_models/cifar10/resnet50_cifar10.h5
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 16)   0           activation_1[0][0]               
                                                                 batch_normalization_3[0][0]      
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 32, 32, 16)   2320        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 32, 32, 16)   2320        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 16)   0           activation_3[0][0]               
                                                                 batch_normalization_5[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 32, 32, 16)   2320        activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 32, 32, 16)   2320        activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          conv2d_7[0][0]                   
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 16)   0           activation_5[0][0]               
                                                                 batch_normalization_7[0][0]      
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 32, 32, 16)   2320        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 32, 32, 16)   2320        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]                   
__________________________________________________________________________________________________
add_4 (Add)                     (None, 32, 32, 16)   0           activation_7[0][0]               
                                                                 batch_normalization_9[0][0]      
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 32, 32, 16)   0           add_4[0][0]                      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 32, 32, 16)   2320        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 32, 32, 16)   64          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 32, 32, 16)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 32, 32, 16)   2320        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 32, 32, 16)   64          conv2d_11[0][0]                  
__________________________________________________________________________________________________
add_5 (Add)                     (None, 32, 32, 16)   0           activation_9[0][0]               
                                                                 batch_normalization_11[0][0]     
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 32, 32, 16)   0           add_5[0][0]                      
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 32, 32, 16)   2320        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 32, 32, 16)   64          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 32, 32, 16)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 32, 32, 16)   2320        activation_12[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 32, 32, 16)   64          conv2d_13[0][0]                  
__________________________________________________________________________________________________
add_6 (Add)                     (None, 32, 32, 16)   0           activation_11[0][0]              
                                                                 batch_normalization_13[0][0]     
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 32, 32, 16)   0           add_6[0][0]                      
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 32, 32, 16)   2320        activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 32, 32, 16)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 32, 32, 16)   2320        activation_14[0][0]              
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 32, 32, 16)   64          conv2d_15[0][0]                  
__________________________________________________________________________________________________
add_7 (Add)                     (None, 32, 32, 16)   0           activation_13[0][0]              
                                                                 batch_normalization_15[0][0]     
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 32, 32, 16)   0           add_7[0][0]                      
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 32, 32, 16)   2320        activation_15[0][0]              
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 32, 32, 16)   64          conv2d_16[0][0]                  
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 32, 32, 16)   0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 32, 32, 16)   2320        activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 32, 32, 16)   64          conv2d_17[0][0]                  
__________________________________________________________________________________________________
add_8 (Add)                     (None, 32, 32, 16)   0           activation_15[0][0]              
                                                                 batch_normalization_17[0][0]     
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 32, 32, 16)   0           add_8[0][0]                      
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 32, 32, 16)   2320        activation_17[0][0]              
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 32, 32, 16)   64          conv2d_18[0][0]                  
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 32, 32, 16)   0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 32, 32, 16)   2320        activation_18[0][0]              
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 32, 32, 16)   64          conv2d_19[0][0]                  
__________________________________________________________________________________________________
add_9 (Add)                     (None, 32, 32, 16)   0           activation_17[0][0]              
                                                                 batch_normalization_19[0][0]     
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 32, 32, 16)   0           add_9[0][0]                      
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 16, 16, 32)   4640        activation_19[0][0]              
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 16, 16, 32)   128         conv2d_20[0][0]                  
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 16, 16, 32)   0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 16, 16, 32)   9248        activation_20[0][0]              
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 16, 16, 32)   544         activation_19[0][0]              
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 16, 16, 32)   128         conv2d_21[0][0]                  
__________________________________________________________________________________________________
add_10 (Add)                    (None, 16, 16, 32)   0           conv2d_22[0][0]                  
                                                                 batch_normalization_21[0][0]     
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 16, 16, 32)   0           add_10[0][0]                     
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 16, 16, 32)   9248        activation_21[0][0]              
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 16, 16, 32)   128         conv2d_23[0][0]                  
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 16, 16, 32)   0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 16, 16, 32)   9248        activation_22[0][0]              
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 16, 16, 32)   128         conv2d_24[0][0]                  
__________________________________________________________________________________________________
add_11 (Add)                    (None, 16, 16, 32)   0           activation_21[0][0]              
                                                                 batch_normalization_23[0][0]     
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 16, 16, 32)   0           add_11[0][0]                     
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 16, 16, 32)   9248        activation_23[0][0]              
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 16, 16, 32)   128         conv2d_25[0][0]                  
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 16, 16, 32)   0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 16, 16, 32)   9248        activation_24[0][0]              
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 16, 16, 32)   128         conv2d_26[0][0]                  
__________________________________________________________________________________________________
add_12 (Add)                    (None, 16, 16, 32)   0           activation_23[0][0]              
                                                                 batch_normalization_25[0][0]     
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 16, 16, 32)   0           add_12[0][0]                     
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 16, 16, 32)   9248        activation_25[0][0]              
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 16, 16, 32)   128         conv2d_27[0][0]                  
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 16, 16, 32)   0           batch_normalization_26[0][0]     
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 16, 16, 32)   9248        activation_26[0][0]              
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 16, 16, 32)   128         conv2d_28[0][0]                  
__________________________________________________________________________________________________
add_13 (Add)                    (None, 16, 16, 32)   0           activation_25[0][0]              
                                                                 batch_normalization_27[0][0]     
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 16, 16, 32)   0           add_13[0][0]                     
__________________________________________________________________________________________________
conv2d_29 (Conv2D)              (None, 16, 16, 32)   9248        activation_27[0][0]              
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 16, 16, 32)   128         conv2d_29[0][0]                  
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 16, 16, 32)   0           batch_normalization_28[0][0]     
__________________________________________________________________________________________________
conv2d_30 (Conv2D)              (None, 16, 16, 32)   9248        activation_28[0][0]              
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 16, 16, 32)   128         conv2d_30[0][0]                  
__________________________________________________________________________________________________
add_14 (Add)                    (None, 16, 16, 32)   0           activation_27[0][0]              
                                                                 batch_normalization_29[0][0]     
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 16, 16, 32)   0           add_14[0][0]                     
__________________________________________________________________________________________________
conv2d_31 (Conv2D)              (None, 16, 16, 32)   9248        activation_29[0][0]              
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 16, 16, 32)   128         conv2d_31[0][0]                  
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 16, 16, 32)   0           batch_normalization_30[0][0]     
__________________________________________________________________________________________________
conv2d_32 (Conv2D)              (None, 16, 16, 32)   9248        activation_30[0][0]              
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 16, 16, 32)   128         conv2d_32[0][0]                  
__________________________________________________________________________________________________
add_15 (Add)                    (None, 16, 16, 32)   0           activation_29[0][0]              
                                                                 batch_normalization_31[0][0]     
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 16, 16, 32)   0           add_15[0][0]                     
__________________________________________________________________________________________________
conv2d_33 (Conv2D)              (None, 16, 16, 32)   9248        activation_31[0][0]              
__________________________________________________________________________________________________
batch_normalization_32 (BatchNo (None, 16, 16, 32)   128         conv2d_33[0][0]                  
__________________________________________________________________________________________________
activation_32 (Activation)      (None, 16, 16, 32)   0           batch_normalization_32[0][0]     
__________________________________________________________________________________________________
conv2d_34 (Conv2D)              (None, 16, 16, 32)   9248        activation_32[0][0]              
__________________________________________________________________________________________________
batch_normalization_33 (BatchNo (None, 16, 16, 32)   128         conv2d_34[0][0]                  
__________________________________________________________________________________________________
add_16 (Add)                    (None, 16, 16, 32)   0           activation_31[0][0]              
                                                                 batch_normalization_33[0][0]     
__________________________________________________________________________________________________
activation_33 (Activation)      (None, 16, 16, 32)   0           add_16[0][0]                     
__________________________________________________________________________________________________
conv2d_35 (Conv2D)              (None, 16, 16, 32)   9248        activation_33[0][0]              
__________________________________________________________________________________________________
batch_normalization_34 (BatchNo (None, 16, 16, 32)   128         conv2d_35[0][0]                  
__________________________________________________________________________________________________
activation_34 (Activation)      (None, 16, 16, 32)   0           batch_normalization_34[0][0]     
__________________________________________________________________________________________________
conv2d_36 (Conv2D)              (None, 16, 16, 32)   9248        activation_34[0][0]              
__________________________________________________________________________________________________
batch_normalization_35 (BatchNo (None, 16, 16, 32)   128         conv2d_36[0][0]                  
__________________________________________________________________________________________________
add_17 (Add)                    (None, 16, 16, 32)   0           activation_33[0][0]              
                                                                 batch_normalization_35[0][0]     
__________________________________________________________________________________________________
activation_35 (Activation)      (None, 16, 16, 32)   0           add_17[0][0]                     
__________________________________________________________________________________________________
conv2d_37 (Conv2D)              (None, 16, 16, 32)   9248        activation_35[0][0]              
__________________________________________________________________________________________________
batch_normalization_36 (BatchNo (None, 16, 16, 32)   128         conv2d_37[0][0]                  
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 16, 16, 32)   0           batch_normalization_36[0][0]     
__________________________________________________________________________________________________
conv2d_38 (Conv2D)              (None, 16, 16, 32)   9248        activation_36[0][0]              
__________________________________________________________________________________________________
batch_normalization_37 (BatchNo (None, 16, 16, 32)   128         conv2d_38[0][0]                  
__________________________________________________________________________________________________
add_18 (Add)                    (None, 16, 16, 32)   0           activation_35[0][0]              
                                                                 batch_normalization_37[0][0]     
__________________________________________________________________________________________________
activation_37 (Activation)      (None, 16, 16, 32)   0           add_18[0][0]                     
__________________________________________________________________________________________________
conv2d_39 (Conv2D)              (None, 8, 8, 64)     18496       activation_37[0][0]              
__________________________________________________________________________________________________
batch_normalization_38 (BatchNo (None, 8, 8, 64)     256         conv2d_39[0][0]                  
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 8, 8, 64)     0           batch_normalization_38[0][0]     
__________________________________________________________________________________________________
conv2d_40 (Conv2D)              (None, 8, 8, 64)     36928       activation_38[0][0]              
__________________________________________________________________________________________________
conv2d_41 (Conv2D)              (None, 8, 8, 64)     2112        activation_37[0][0]              
__________________________________________________________________________________________________
batch_normalization_39 (BatchNo (None, 8, 8, 64)     256         conv2d_40[0][0]                  
__________________________________________________________________________________________________
add_19 (Add)                    (None, 8, 8, 64)     0           conv2d_41[0][0]                  
                                                                 batch_normalization_39[0][0]     
__________________________________________________________________________________________________
activation_39 (Activation)      (None, 8, 8, 64)     0           add_19[0][0]                     
__________________________________________________________________________________________________
conv2d_42 (Conv2D)              (None, 8, 8, 64)     36928       activation_39[0][0]              
__________________________________________________________________________________________________
batch_normalization_40 (BatchNo (None, 8, 8, 64)     256         conv2d_42[0][0]                  
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 8, 8, 64)     0           batch_normalization_40[0][0]     
__________________________________________________________________________________________________
conv2d_43 (Conv2D)              (None, 8, 8, 64)     36928       activation_40[0][0]              
__________________________________________________________________________________________________
batch_normalization_41 (BatchNo (None, 8, 8, 64)     256         conv2d_43[0][0]                  
__________________________________________________________________________________________________
add_20 (Add)                    (None, 8, 8, 64)     0           activation_39[0][0]              
                                                                 batch_normalization_41[0][0]     
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 8, 8, 64)     0           add_20[0][0]                     
__________________________________________________________________________________________________
conv2d_44 (Conv2D)              (None, 8, 8, 64)     36928       activation_41[0][0]              
__________________________________________________________________________________________________
batch_normalization_42 (BatchNo (None, 8, 8, 64)     256         conv2d_44[0][0]                  
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 8, 8, 64)     0           batch_normalization_42[0][0]     
__________________________________________________________________________________________________
conv2d_45 (Conv2D)              (None, 8, 8, 64)     36928       activation_42[0][0]              
__________________________________________________________________________________________________
batch_normalization_43 (BatchNo (None, 8, 8, 64)     256         conv2d_45[0][0]                  
__________________________________________________________________________________________________
add_21 (Add)                    (None, 8, 8, 64)     0           activation_41[0][0]              
                                                                 batch_normalization_43[0][0]     
__________________________________________________________________________________________________
activation_43 (Activation)      (None, 8, 8, 64)     0           add_21[0][0]                     
__________________________________________________________________________________________________
conv2d_46 (Conv2D)              (None, 8, 8, 64)     36928       activation_43[0][0]              
__________________________________________________________________________________________________
batch_normalization_44 (BatchNo (None, 8, 8, 64)     256         conv2d_46[0][0]                  
__________________________________________________________________________________________________
activation_44 (Activation)      (None, 8, 8, 64)     0           batch_normalization_44[0][0]     
__________________________________________________________________________________________________
conv2d_47 (Conv2D)              (None, 8, 8, 64)     36928       activation_44[0][0]              
__________________________________________________________________________________________________
batch_normalization_45 (BatchNo (None, 8, 8, 64)     256         conv2d_47[0][0]                  
__________________________________________________________________________________________________
add_22 (Add)                    (None, 8, 8, 64)     0           activation_43[0][0]              
                                                                 batch_normalization_45[0][0]     
__________________________________________________________________________________________________
activation_45 (Activation)      (None, 8, 8, 64)     0           add_22[0][0]                     
__________________________________________________________________________________________________
conv2d_48 (Conv2D)              (None, 8, 8, 64)     36928       activation_45[0][0]              
__________________________________________________________________________________________________
batch_normalization_46 (BatchNo (None, 8, 8, 64)     256         conv2d_48[0][0]                  
__________________________________________________________________________________________________
activation_46 (Activation)      (None, 8, 8, 64)     0           batch_normalization_46[0][0]     
__________________________________________________________________________________________________
conv2d_49 (Conv2D)              (None, 8, 8, 64)     36928       activation_46[0][0]              
__________________________________________________________________________________________________
batch_normalization_47 (BatchNo (None, 8, 8, 64)     256         conv2d_49[0][0]                  
__________________________________________________________________________________________________
add_23 (Add)                    (None, 8, 8, 64)     0           activation_45[0][0]              
                                                                 batch_normalization_47[0][0]     
__________________________________________________________________________________________________
activation_47 (Activation)      (None, 8, 8, 64)     0           add_23[0][0]                     
__________________________________________________________________________________________________
conv2d_50 (Conv2D)              (None, 8, 8, 64)     36928       activation_47[0][0]              
__________________________________________________________________________________________________
batch_normalization_48 (BatchNo (None, 8, 8, 64)     256         conv2d_50[0][0]                  
__________________________________________________________________________________________________
activation_48 (Activation)      (None, 8, 8, 64)     0           batch_normalization_48[0][0]     
__________________________________________________________________________________________________
conv2d_51 (Conv2D)              (None, 8, 8, 64)     36928       activation_48[0][0]              
__________________________________________________________________________________________________
batch_normalization_49 (BatchNo (None, 8, 8, 64)     256         conv2d_51[0][0]                  
__________________________________________________________________________________________________
add_24 (Add)                    (None, 8, 8, 64)     0           activation_47[0][0]              
                                                                 batch_normalization_49[0][0]     
__________________________________________________________________________________________________
activation_49 (Activation)      (None, 8, 8, 64)     0           add_24[0][0]                     
__________________________________________________________________________________________________
conv2d_52 (Conv2D)              (None, 8, 8, 64)     36928       activation_49[0][0]              
__________________________________________________________________________________________________
batch_normalization_50 (BatchNo (None, 8, 8, 64)     256         conv2d_52[0][0]                  
__________________________________________________________________________________________________
activation_50 (Activation)      (None, 8, 8, 64)     0           batch_normalization_50[0][0]     
__________________________________________________________________________________________________
conv2d_53 (Conv2D)              (None, 8, 8, 64)     36928       activation_50[0][0]              
__________________________________________________________________________________________________
batch_normalization_51 (BatchNo (None, 8, 8, 64)     256         conv2d_53[0][0]                  
__________________________________________________________________________________________________
add_25 (Add)                    (None, 8, 8, 64)     0           activation_49[0][0]              
                                                                 batch_normalization_51[0][0]     
__________________________________________________________________________________________________
activation_51 (Activation)      (None, 8, 8, 64)     0           add_25[0][0]                     
__________________________________________________________________________________________________
conv2d_54 (Conv2D)              (None, 8, 8, 64)     36928       activation_51[0][0]              
__________________________________________________________________________________________________
batch_normalization_52 (BatchNo (None, 8, 8, 64)     256         conv2d_54[0][0]                  
__________________________________________________________________________________________________
activation_52 (Activation)      (None, 8, 8, 64)     0           batch_normalization_52[0][0]     
__________________________________________________________________________________________________
conv2d_55 (Conv2D)              (None, 8, 8, 64)     36928       activation_52[0][0]              
__________________________________________________________________________________________________
batch_normalization_53 (BatchNo (None, 8, 8, 64)     256         conv2d_55[0][0]                  
__________________________________________________________________________________________________
add_26 (Add)                    (None, 8, 8, 64)     0           activation_51[0][0]              
                                                                 batch_normalization_53[0][0]     
__________________________________________________________________________________________________
activation_53 (Activation)      (None, 8, 8, 64)     0           add_26[0][0]                     
__________________________________________________________________________________________________
conv2d_56 (Conv2D)              (None, 8, 8, 64)     36928       activation_53[0][0]              
__________________________________________________________________________________________________
batch_normalization_54 (BatchNo (None, 8, 8, 64)     256         conv2d_56[0][0]                  
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 8, 8, 64)     0           batch_normalization_54[0][0]     
__________________________________________________________________________________________________
conv2d_57 (Conv2D)              (None, 8, 8, 64)     36928       activation_54[0][0]              
__________________________________________________________________________________________________
batch_normalization_55 (BatchNo (None, 8, 8, 64)     256         conv2d_57[0][0]                  
__________________________________________________________________________________________________
add_27 (Add)                    (None, 8, 8, 64)     0           activation_53[0][0]              
                                                                 batch_normalization_55[0][0]     
__________________________________________________________________________________________________
activation_55 (Activation)      (None, 8, 8, 64)     0           add_27[0][0]                     
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_55[0][0]              
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 10)           650         flatten_1[0][0]                  
==================================================================================================
Total params: 861,770
Trainable params: 857,706
Non-trainable params: 4,064
__________________________________________________________________________________________________
None
  0%|          | 0/196 [00:00<?, ?it/s]  4%|▍         | 3/70 [01:07<23:15, 20.83s/it]2021-03-03 21:31:21.028475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 21:31:21.547127: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2021-03-03 21:31:21.556237: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
  0%|          | 0/196 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "second_clf.py", line 168, in <module>
    main()
  File "second_clf.py", line 118, in main
    ori_train_traces, ori_test_traces, ori_train_y, ori_test_y = load_ori_traces(args.path0, args.path1, args.dataset, args.model, fitness)
  File "second_clf.py", line 99, in load_ori_traces
    train_traces = cal_samples_trace(model, x_train, fitness)
  File "/home/zhiyu/DeepSuite/adversarial/adv_function/trace.py", line 51, in cal_samples_trace
    layer_output = temp_model.predict(dataset, batch_size=batch_size, verbose=0)
  File "/home/zhiyu/anaconda3/envs/GPU/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py", line 88, in _method_wrapper
    return method(self, *args, **kwargs)
  File "/home/zhiyu/anaconda3/envs/GPU/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py", line 1268, in predict
    tmp_batch_outputs = predict_function(iterator)
  File "/home/zhiyu/anaconda3/envs/GPU/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 580, in __call__
    result = self._call(*args, **kwds)
  File "/home/zhiyu/anaconda3/envs/GPU/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 650, in _call
    return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access
  File "/home/zhiyu/anaconda3/envs/GPU/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1665, in _filtered_call
    self.captured_inputs)
  File "/home/zhiyu/anaconda3/envs/GPU/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1746, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File "/home/zhiyu/anaconda3/envs/GPU/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 598, in call
    ctx=ctx)
  File "/home/zhiyu/anaconda3/envs/GPU/lib/python3.6/site-packages/tensorflow/python/eager/execute.py", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node model/conv2d_1/Conv2D (defined at /home/zhiyu/DeepSuite/adversarial/adv_function/trace.py:51) ]] [Op:__inference_predict_function_11757]

Function call stack:
predict_function

 18%|█▊        | 35/196 [08:33<39:03, 14.56s/it] 41%|████▏     | 29/70 [08:50<20:32, 30.06s/it] 18%|█▊        | 36/196 [08:46<37:06, 13.92s/it]2021-03-03 21:31:42.633342: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 3276800000 exceeds 10% of free system memory.
 19%|█▉        | 37/196 [08:58<35:29, 13.39s/it] 43%|████▎     | 30/70 [09:06<17:12, 25.80s/it]start time : Wed Mar  3 21:31:54 2021
Namespace(dataset='cifar10', k_kmnc=10, k_nc=0.75, k_tknc=3, model='resnet50_cifar10', path0='/media/data0/DeepSuite', path1='/media/data1/DeepSuite', sa_layer=-1, sa_n=1000)
  6%|▌         | 4/70 [01:43<29:35, 26.90s/it]load resnet50_cifar10...
2021-03-03 21:31:58.615513: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-03-03 21:31:58.726088: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 3276800000 exceeds 10% of free system memory.
2021-03-03 21:32:00.118072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:25:00.0 name: Quadro RTX 8000 computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.43GiB deviceMemoryBandwidth: 625.94GiB/s
2021-03-03 21:32:00.118163: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-03-03 21:32:00.119711: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-03-03 21:32:00.121299: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-03-03 21:32:00.121617: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-03-03 21:32:00.123118: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-03-03 21:32:00.123757: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-03-03 21:32:00.126879: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 21:32:00.128872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2021-03-03 21:32:00.129233: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2021-03-03 21:32:00.174037: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2600000000 Hz
2021-03-03 21:32:00.181029: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fdddd3a570 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-03-03 21:32:00.181069: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-03-03 21:32:00.182988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:25:00.0 name: Quadro RTX 8000 computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.43GiB deviceMemoryBandwidth: 625.94GiB/s
2021-03-03 21:32:00.183053: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-03-03 21:32:00.183076: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-03-03 21:32:00.183095: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-03-03 21:32:00.183114: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-03-03 21:32:00.183132: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-03-03 21:32:00.183150: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-03-03 21:32:00.183169: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 21:32:00.185694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2021-03-03 21:32:00.185731: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
 19%|█▉        | 38/196 [09:10<34:36, 13.14s/it] 44%|████▍     | 31/70 [09:22<14:56, 23.00s/it]2021-03-03 21:32:07.974123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-03 21:32:07.974182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2021-03-03 21:32:07.974189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2021-03-03 21:32:07.977582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1101 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:25:00.0, compute capability: 7.5)
2021-03-03 21:32:07.980250: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fe8d511500 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-03-03 21:32:07.980292: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5
/media/data1/DeepSuite/trained_models/cifar10/resnet50_cifar10.h5
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 16)   0           activation_1[0][0]               
                                                                 batch_normalization_3[0][0]      
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 32, 32, 16)   2320        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 32, 32, 16)   2320        activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 16)   0           activation_3[0][0]               
                                                                 batch_normalization_5[0][0]      
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 32, 32, 16)   2320        activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 32, 32, 16)   2320        activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          conv2d_7[0][0]                   
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 16)   0           activation_5[0][0]               
                                                                 batch_normalization_7[0][0]      
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 32, 32, 16)   2320        activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 32, 32, 16)   2320        activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]                   
__________________________________________________________________________________________________
add_4 (Add)                     (None, 32, 32, 16)   0           activation_7[0][0]               
                                                                 batch_normalization_9[0][0]      
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 32, 32, 16)   0           add_4[0][0]                      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 32, 32, 16)   2320        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 32, 32, 16)   64          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 32, 32, 16)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 32, 32, 16)   2320        activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 32, 32, 16)   64          conv2d_11[0][0]                  
__________________________________________________________________________________________________
add_5 (Add)                     (None, 32, 32, 16)   0           activation_9[0][0]               
                                                                 batch_normalization_11[0][0]     
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 32, 32, 16)   0           add_5[0][0]                      
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 32, 32, 16)   2320        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 32, 32, 16)   64          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 32, 32, 16)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 32, 32, 16)   2320        activation_12[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 32, 32, 16)   64          conv2d_13[0][0]                  
__________________________________________________________________________________________________
add_6 (Add)                     (None, 32, 32, 16)   0           activation_11[0][0]              
                                                                 batch_normalization_13[0][0]     
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 32, 32, 16)   0           add_6[0][0]                      
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 32, 32, 16)   2320        activation_13[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 32, 32, 16)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 32, 32, 16)   2320        activation_14[0][0]              
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 32, 32, 16)   64          conv2d_15[0][0]                  
__________________________________________________________________________________________________
add_7 (Add)                     (None, 32, 32, 16)   0           activation_13[0][0]              
                                                                 batch_normalization_15[0][0]     
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 32, 32, 16)   0           add_7[0][0]                      
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 32, 32, 16)   2320        activation_15[0][0]              
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 32, 32, 16)   64          conv2d_16[0][0]                  
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 32, 32, 16)   0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 32, 32, 16)   2320        activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 32, 32, 16)   64          conv2d_17[0][0]                  
__________________________________________________________________________________________________
add_8 (Add)                     (None, 32, 32, 16)   0           activation_15[0][0]              
                                                                 batch_normalization_17[0][0]     
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 32, 32, 16)   0           add_8[0][0]                      
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 32, 32, 16)   2320        activation_17[0][0]              
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 32, 32, 16)   64          conv2d_18[0][0]                  
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 32, 32, 16)   0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 32, 32, 16)   2320        activation_18[0][0]              
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 32, 32, 16)   64          conv2d_19[0][0]                  
__________________________________________________________________________________________________
add_9 (Add)                     (None, 32, 32, 16)   0           activation_17[0][0]              
                                                                 batch_normalization_19[0][0]     
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 32, 32, 16)   0           add_9[0][0]                      
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 16, 16, 32)   4640        activation_19[0][0]              
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 16, 16, 32)   128         conv2d_20[0][0]                  
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 16, 16, 32)   0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 16, 16, 32)   9248        activation_20[0][0]              
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 16, 16, 32)   544         activation_19[0][0]              
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 16, 16, 32)   128         conv2d_21[0][0]                  
__________________________________________________________________________________________________
add_10 (Add)                    (None, 16, 16, 32)   0           conv2d_22[0][0]                  
                                                                 batch_normalization_21[0][0]     
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 16, 16, 32)   0           add_10[0][0]                     
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 16, 16, 32)   9248        activation_21[0][0]              
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 16, 16, 32)   128         conv2d_23[0][0]                  
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 16, 16, 32)   0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 16, 16, 32)   9248        activation_22[0][0]              
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 16, 16, 32)   128         conv2d_24[0][0]                  
__________________________________________________________________________________________________
add_11 (Add)                    (None, 16, 16, 32)   0           activation_21[0][0]              
                                                                 batch_normalization_23[0][0]     
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 16, 16, 32)   0           add_11[0][0]                     
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 16, 16, 32)   9248        activation_23[0][0]              
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 16, 16, 32)   128         conv2d_25[0][0]                  
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 16, 16, 32)   0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 16, 16, 32)   9248        activation_24[0][0]              
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 16, 16, 32)   128         conv2d_26[0][0]                  
__________________________________________________________________________________________________
add_12 (Add)                    (None, 16, 16, 32)   0           activation_23[0][0]              
                                                                 batch_normalization_25[0][0]     
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 16, 16, 32)   0           add_12[0][0]                     
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 16, 16, 32)   9248        activation_25[0][0]              
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 16, 16, 32)   128         conv2d_27[0][0]                  
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 16, 16, 32)   0           batch_normalization_26[0][0]     
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 16, 16, 32)   9248        activation_26[0][0]              
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 16, 16, 32)   128         conv2d_28[0][0]                  
__________________________________________________________________________________________________
add_13 (Add)                    (None, 16, 16, 32)   0           activation_25[0][0]              
                                                                 batch_normalization_27[0][0]     
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 16, 16, 32)   0           add_13[0][0]                     
__________________________________________________________________________________________________
conv2d_29 (Conv2D)              (None, 16, 16, 32)   9248        activation_27[0][0]              
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 16, 16, 32)   128         conv2d_29[0][0]                  
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 16, 16, 32)   0           batch_normalization_28[0][0]     
__________________________________________________________________________________________________
conv2d_30 (Conv2D)              (None, 16, 16, 32)   9248        activation_28[0][0]              
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 16, 16, 32)   128         conv2d_30[0][0]                  
__________________________________________________________________________________________________
add_14 (Add)                    (None, 16, 16, 32)   0           activation_27[0][0]              
                                                                 batch_normalization_29[0][0]     
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 16, 16, 32)   0           add_14[0][0]                     
__________________________________________________________________________________________________
conv2d_31 (Conv2D)              (None, 16, 16, 32)   9248        activation_29[0][0]              
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 16, 16, 32)   128         conv2d_31[0][0]                  
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 16, 16, 32)   0           batch_normalization_30[0][0]     
__________________________________________________________________________________________________
conv2d_32 (Conv2D)              (None, 16, 16, 32)   9248        activation_30[0][0]              
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 16, 16, 32)   128         conv2d_32[0][0]                  
__________________________________________________________________________________________________
add_15 (Add)                    (None, 16, 16, 32)   0           activation_29[0][0]              
                                                                 batch_normalization_31[0][0]     
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 16, 16, 32)   0           add_15[0][0]                     
__________________________________________________________________________________________________
conv2d_33 (Conv2D)              (None, 16, 16, 32)   9248        activation_31[0][0]              
__________________________________________________________________________________________________
batch_normalization_32 (BatchNo (None, 16, 16, 32)   128         conv2d_33[0][0]                  
__________________________________________________________________________________________________
activation_32 (Activation)      (None, 16, 16, 32)   0           batch_normalization_32[0][0]     
__________________________________________________________________________________________________
conv2d_34 (Conv2D)              (None, 16, 16, 32)   9248        activation_32[0][0]              
__________________________________________________________________________________________________
batch_normalization_33 (BatchNo (None, 16, 16, 32)   128         conv2d_34[0][0]                  
__________________________________________________________________________________________________
add_16 (Add)                    (None, 16, 16, 32)   0           activation_31[0][0]              
                                                                 batch_normalization_33[0][0]     
__________________________________________________________________________________________________
activation_33 (Activation)      (None, 16, 16, 32)   0           add_16[0][0]                     
__________________________________________________________________________________________________
conv2d_35 (Conv2D)              (None, 16, 16, 32)   9248        activation_33[0][0]              
__________________________________________________________________________________________________
batch_normalization_34 (BatchNo (None, 16, 16, 32)   128         conv2d_35[0][0]                  
__________________________________________________________________________________________________
activation_34 (Activation)      (None, 16, 16, 32)   0           batch_normalization_34[0][0]     
__________________________________________________________________________________________________
conv2d_36 (Conv2D)              (None, 16, 16, 32)   9248        activation_34[0][0]              
__________________________________________________________________________________________________
batch_normalization_35 (BatchNo (None, 16, 16, 32)   128         conv2d_36[0][0]                  
__________________________________________________________________________________________________
add_17 (Add)                    (None, 16, 16, 32)   0           activation_33[0][0]              
                                                                 batch_normalization_35[0][0]     
__________________________________________________________________________________________________
activation_35 (Activation)      (None, 16, 16, 32)   0           add_17[0][0]                     
__________________________________________________________________________________________________
conv2d_37 (Conv2D)              (None, 16, 16, 32)   9248        activation_35[0][0]              
__________________________________________________________________________________________________
batch_normalization_36 (BatchNo (None, 16, 16, 32)   128         conv2d_37[0][0]                  
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 16, 16, 32)   0           batch_normalization_36[0][0]     
__________________________________________________________________________________________________
conv2d_38 (Conv2D)              (None, 16, 16, 32)   9248        activation_36[0][0]              
__________________________________________________________________________________________________
batch_normalization_37 (BatchNo (None, 16, 16, 32)   128         conv2d_38[0][0]                  
__________________________________________________________________________________________________
add_18 (Add)                    (None, 16, 16, 32)   0           activation_35[0][0]              
                                                                 batch_normalization_37[0][0]     
__________________________________________________________________________________________________
activation_37 (Activation)      (None, 16, 16, 32)   0           add_18[0][0]                     
__________________________________________________________________________________________________
conv2d_39 (Conv2D)              (None, 8, 8, 64)     18496       activation_37[0][0]              
__________________________________________________________________________________________________
batch_normalization_38 (BatchNo (None, 8, 8, 64)     256         conv2d_39[0][0]                  
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 8, 8, 64)     0           batch_normalization_38[0][0]     
__________________________________________________________________________________________________
conv2d_40 (Conv2D)              (None, 8, 8, 64)     36928       activation_38[0][0]              
__________________________________________________________________________________________________
conv2d_41 (Conv2D)              (None, 8, 8, 64)     2112        activation_37[0][0]              
__________________________________________________________________________________________________
batch_normalization_39 (BatchNo (None, 8, 8, 64)     256         conv2d_40[0][0]                  
__________________________________________________________________________________________________
add_19 (Add)                    (None, 8, 8, 64)     0           conv2d_41[0][0]                  
                                                                 batch_normalization_39[0][0]     
__________________________________________________________________________________________________
activation_39 (Activation)      (None, 8, 8, 64)     0           add_19[0][0]                     
__________________________________________________________________________________________________
conv2d_42 (Conv2D)              (None, 8, 8, 64)     36928       activation_39[0][0]              
__________________________________________________________________________________________________
batch_normalization_40 (BatchNo (None, 8, 8, 64)     256         conv2d_42[0][0]                  
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 8, 8, 64)     0           batch_normalization_40[0][0]     
__________________________________________________________________________________________________
conv2d_43 (Conv2D)              (None, 8, 8, 64)     36928       activation_40[0][0]              
__________________________________________________________________________________________________
batch_normalization_41 (BatchNo (None, 8, 8, 64)     256         conv2d_43[0][0]                  
__________________________________________________________________________________________________
add_20 (Add)                    (None, 8, 8, 64)     0           activation_39[0][0]              
                                                                 batch_normalization_41[0][0]     
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 8, 8, 64)     0           add_20[0][0]                     
__________________________________________________________________________________________________
conv2d_44 (Conv2D)              (None, 8, 8, 64)     36928       activation_41[0][0]              
__________________________________________________________________________________________________
batch_normalization_42 (BatchNo (None, 8, 8, 64)     256         conv2d_44[0][0]                  
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 8, 8, 64)     0           batch_normalization_42[0][0]     
__________________________________________________________________________________________________
conv2d_45 (Conv2D)              (None, 8, 8, 64)     36928       activation_42[0][0]              
__________________________________________________________________________________________________
batch_normalization_43 (BatchNo (None, 8, 8, 64)     256         conv2d_45[0][0]                  
__________________________________________________________________________________________________
add_21 (Add)                    (None, 8, 8, 64)     0           activation_41[0][0]              
                                                                 batch_normalization_43[0][0]     
__________________________________________________________________________________________________
activation_43 (Activation)      (None, 8, 8, 64)     0           add_21[0][0]                     
__________________________________________________________________________________________________
conv2d_46 (Conv2D)              (None, 8, 8, 64)     36928       activation_43[0][0]              
__________________________________________________________________________________________________
batch_normalization_44 (BatchNo (None, 8, 8, 64)     256         conv2d_46[0][0]                  
__________________________________________________________________________________________________
activation_44 (Activation)      (None, 8, 8, 64)     0           batch_normalization_44[0][0]     
__________________________________________________________________________________________________
conv2d_47 (Conv2D)              (None, 8, 8, 64)     36928       activation_44[0][0]              
__________________________________________________________________________________________________
batch_normalization_45 (BatchNo (None, 8, 8, 64)     256         conv2d_47[0][0]                  
__________________________________________________________________________________________________
add_22 (Add)                    (None, 8, 8, 64)     0           activation_43[0][0]              
                                                                 batch_normalization_45[0][0]     
__________________________________________________________________________________________________
activation_45 (Activation)      (None, 8, 8, 64)     0           add_22[0][0]                     
__________________________________________________________________________________________________
conv2d_48 (Conv2D)              (None, 8, 8, 64)     36928       activation_45[0][0]              
__________________________________________________________________________________________________
batch_normalization_46 (BatchNo (None, 8, 8, 64)     256         conv2d_48[0][0]                  
__________________________________________________________________________________________________
activation_46 (Activation)      (None, 8, 8, 64)     0           batch_normalization_46[0][0]     
__________________________________________________________________________________________________
conv2d_49 (Conv2D)              (None, 8, 8, 64)     36928       activation_46[0][0]              
__________________________________________________________________________________________________
batch_normalization_47 (BatchNo (None, 8, 8, 64)     256         conv2d_49[0][0]                  
__________________________________________________________________________________________________
add_23 (Add)                    (None, 8, 8, 64)     0           activation_45[0][0]              
                                                                 batch_normalization_47[0][0]     
__________________________________________________________________________________________________
activation_47 (Activation)      (None, 8, 8, 64)     0           add_23[0][0]                     
__________________________________________________________________________________________________
conv2d_50 (Conv2D)              (None, 8, 8, 64)     36928       activation_47[0][0]              
__________________________________________________________________________________________________
batch_normalization_48 (BatchNo (None, 8, 8, 64)     256         conv2d_50[0][0]                  
__________________________________________________________________________________________________
activation_48 (Activation)      (None, 8, 8, 64)     0           batch_normalization_48[0][0]     
__________________________________________________________________________________________________
conv2d_51 (Conv2D)              (None, 8, 8, 64)     36928       activation_48[0][0]              
__________________________________________________________________________________________________
batch_normalization_49 (BatchNo (None, 8, 8, 64)     256         conv2d_51[0][0]                  
__________________________________________________________________________________________________
add_24 (Add)                    (None, 8, 8, 64)     0           activation_47[0][0]              
                                                                 batch_normalization_49[0][0]     
__________________________________________________________________________________________________
activation_49 (Activation)      (None, 8, 8, 64)     0           add_24[0][0]                     
__________________________________________________________________________________________________
conv2d_52 (Conv2D)              (None, 8, 8, 64)     36928       activation_49[0][0]              
__________________________________________________________________________________________________
batch_normalization_50 (BatchNo (None, 8, 8, 64)     256         conv2d_52[0][0]                  
__________________________________________________________________________________________________
activation_50 (Activation)      (None, 8, 8, 64)     0           batch_normalization_50[0][0]     
__________________________________________________________________________________________________
conv2d_53 (Conv2D)              (None, 8, 8, 64)     36928       activation_50[0][0]              
__________________________________________________________________________________________________
batch_normalization_51 (BatchNo (None, 8, 8, 64)     256         conv2d_53[0][0]                  
__________________________________________________________________________________________________
add_25 (Add)                    (None, 8, 8, 64)     0           activation_49[0][0]              
                                                                 batch_normalization_51[0][0]     
__________________________________________________________________________________________________
activation_51 (Activation)      (None, 8, 8, 64)     0           add_25[0][0]                     
__________________________________________________________________________________________________
conv2d_54 (Conv2D)              (None, 8, 8, 64)     36928       activation_51[0][0]              
__________________________________________________________________________________________________
batch_normalization_52 (BatchNo (None, 8, 8, 64)     256         conv2d_54[0][0]                  
__________________________________________________________________________________________________
activation_52 (Activation)      (None, 8, 8, 64)     0           batch_normalization_52[0][0]     
__________________________________________________________________________________________________
conv2d_55 (Conv2D)              (None, 8, 8, 64)     36928       activation_52[0][0]              
__________________________________________________________________________________________________
batch_normalization_53 (BatchNo (None, 8, 8, 64)     256         conv2d_55[0][0]                  
__________________________________________________________________________________________________
add_26 (Add)                    (None, 8, 8, 64)     0           activation_51[0][0]              
                                                                 batch_normalization_53[0][0]     
__________________________________________________________________________________________________
activation_53 (Activation)      (None, 8, 8, 64)     0           add_26[0][0]                     
__________________________________________________________________________________________________
conv2d_56 (Conv2D)              (None, 8, 8, 64)     36928       activation_53[0][0]              
__________________________________________________________________________________________________
batch_normalization_54 (BatchNo (None, 8, 8, 64)     256         conv2d_56[0][0]                  
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 8, 8, 64)     0           batch_normalization_54[0][0]     
__________________________________________________________________________________________________
conv2d_57 (Conv2D)              (None, 8, 8, 64)     36928       activation_54[0][0]              
__________________________________________________________________________________________________
batch_normalization_55 (BatchNo (None, 8, 8, 64)     256         conv2d_57[0][0]                  
__________________________________________________________________________________________________
add_27 (Add)                    (None, 8, 8, 64)     0           activation_53[0][0]              
                                                                 batch_normalization_55[0][0]     
__________________________________________________________________________________________________
activation_55 (Activation)      (None, 8, 8, 64)     0           add_27[0][0]                     
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_55[0][0]              
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 10)           650         flatten_1[0][0]                  
==================================================================================================
Total params: 861,770
Trainable params: 857,706
Non-trainable params: 4,064
__________________________________________________________________________________________________
None
  0%|          | 0/196 [00:00<?, ?it/s]2021-03-03 21:32:11.663188: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 21:32:12.123358: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2021-03-03 21:32:12.128902: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
  0%|          | 0/196 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "second_clf.py", line 168, in <module>
    main()
  File "second_clf.py", line 118, in main
    ori_train_traces, ori_test_traces, ori_train_y, ori_test_y = load_ori_traces(args.path0, args.path1, args.dataset, args.model, fitness)
  File "second_clf.py", line 99, in load_ori_traces
    train_traces = cal_samples_trace(model, x_train, fitness)
  File "/home/zhiyu/DeepSuite/adversarial/adv_function/trace.py", line 51, in cal_samples_trace
    layer_output = temp_model.predict(dataset, batch_size=batch_size, verbose=0)
  File "/home/zhiyu/anaconda3/envs/GPU/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py", line 88, in _method_wrapper
    return method(self, *args, **kwargs)
  File "/home/zhiyu/anaconda3/envs/GPU/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py", line 1268, in predict
    tmp_batch_outputs = predict_function(iterator)
  File "/home/zhiyu/anaconda3/envs/GPU/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 580, in __call__
    result = self._call(*args, **kwds)
  File "/home/zhiyu/anaconda3/envs/GPU/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py", line 650, in _call
    return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access
  File "/home/zhiyu/anaconda3/envs/GPU/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1665, in _filtered_call
    self.captured_inputs)
  File "/home/zhiyu/anaconda3/envs/GPU/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1746, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File "/home/zhiyu/anaconda3/envs/GPU/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 598, in call
    ctx=ctx)
  File "/home/zhiyu/anaconda3/envs/GPU/lib/python3.6/site-packages/tensorflow/python/eager/execute.py", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node model/conv2d_1/Conv2D (defined at /home/zhiyu/DeepSuite/adversarial/adv_function/trace.py:51) ]] [Op:__inference_predict_function_11757]

Function call stack:
predict_function

  7%|▋         | 5/70 [01:59<24:55, 23.01s/it] 20%|█▉        | 39/196 [09:24<35:02, 13.39s/it] 46%|████▌     | 32/70 [09:39<13:23, 21.14s/it]  9%|▊         | 6/70 [02:17<22:36, 21.20s/it] 20%|██        | 40/196 [09:40<36:50, 14.17s/it] 47%|████▋     | 33/70 [09:55<12:07, 19.67s/it] 21%|██        | 41/196 [09:55<37:00, 14.33s/it] 10%|█         | 7/70 [02:35<21:14, 20.24s/it] 49%|████▊     | 34/70 [10:12<11:23, 18.98s/it] 21%|██▏       | 42/196 [10:08<35:57, 14.01s/it] 11%|█▏        | 8/70 [02:51<19:36, 18.97s/it] 50%|█████     | 35/70 [10:28<10:28, 17.97s/it] 22%|██▏       | 43/196 [10:23<36:26, 14.29s/it] 13%|█▎        | 9/70 [03:07<18:07, 17.82s/it] 51%|█████▏    | 36/70 [10:44<09:48, 17.30s/it] 22%|██▏       | 44/196 [10:38<36:17, 14.33s/it] 14%|█▍        | 10/70 [03:22<17:10, 17.17s/it] 53%|█████▎    | 37/70 [11:00<09:15, 16.85s/it] 23%|██▎       | 45/196 [10:53<36:53, 14.66s/it] 16%|█▌        | 11/70 [03:38<16:29, 16.78s/it] 23%|██▎       | 46/196 [11:07<36:14, 14.50s/it] 54%|█████▍    | 38/70 [11:16<08:50, 16.59s/it] 17%|█▋        | 12/70 [03:55<16:02, 16.60s/it] 24%|██▍       | 47/196 [11:24<37:50, 15.24s/it] 56%|█████▌    | 39/70 [11:32<08:33, 16.55s/it] 19%|█▊        | 13/70 [04:13<16:12, 17.06s/it] 24%|██▍       | 48/196 [11:39<37:39, 15.27s/it] 57%|█████▋    | 40/70 [11:48<08:09, 16.33s/it] 20%|██        | 14/70 [04:29<15:48, 16.94s/it] 25%|██▌       | 49/196 [11:54<37:06, 15.15s/it] 59%|█████▊    | 41/70 [12:05<07:56, 16.43s/it] 26%|██▌       | 50/196 [12:09<36:35, 15.04s/it] 21%|██▏       | 15/70 [04:48<16:08, 17.61s/it] 60%|██████    | 42/70 [12:22<07:45, 16.62s/it] 26%|██▌       | 51/196 [12:29<39:52, 16.50s/it] 23%|██▎       | 16/70 [05:10<17:00, 18.90s/it] 61%|██████▏   | 43/70 [12:43<08:03, 17.92s/it] 27%|██▋       | 52/196 [12:46<39:53, 16.62s/it] 24%|██▍       | 17/70 [05:26<15:52, 17.96s/it] 63%|██████▎   | 44/70 [12:59<07:37, 17.59s/it] 27%|██▋       | 53/196 [13:01<38:16, 16.06s/it] 26%|██▌       | 18/70 [05:42<15:06, 17.44s/it] 64%|██████▍   | 45/70 [13:19<07:31, 18.05s/it] 28%|██▊       | 54/196 [13:15<36:47, 15.55s/it] 27%|██▋       | 19/70 [05:57<14:13, 16.74s/it] 66%|██████▌   | 46/70 [13:35<07:02, 17.60s/it] 28%|██▊       | 55/196 [13:29<35:11, 14.98s/it] 29%|██▊       | 20/70 [06:17<14:34, 17.50s/it] 29%|██▊       | 56/196 [13:47<37:07, 15.91s/it] 30%|███       | 21/70 [06:38<15:19, 18.77s/it] 29%|██▉       | 57/196 [14:07<40:11, 17.35s/it] 31%|███▏      | 22/70 [06:55<14:27, 18.07s/it] 30%|██▉       | 58/196 [14:22<38:09, 16.59s/it] 33%|███▎      | 23/70 [07:10<13:21, 17.04s/it] 67%|██████▋   | 47/70 [14:39<12:04, 31.48s/it] 30%|███       | 59/196 [14:37<36:28, 15.98s/it] 34%|███▍      | 24/70 [07:25<12:43, 16.60s/it] 31%|███       | 60/196 [14:51<35:16, 15.56s/it] 69%|██████▊   | 48/70 [15:07<11:08, 30.38s/it] 31%|███       | 61/196 [15:07<35:11, 15.64s/it] 32%|███▏      | 62/196 [15:20<32:56, 14.75s/it] 36%|███▌      | 25/70 [08:03<17:09, 22.88s/it] 70%|███████   | 49/70 [15:34<10:19, 29.52s/it] 32%|███▏      | 63/196 [15:33<31:50, 14.37s/it] 37%|███▋      | 26/70 [08:21<15:45, 21.48s/it] 33%|███▎      | 64/196 [15:47<31:23, 14.27s/it] 39%|███▊      | 27/70 [08:38<14:29, 20.22s/it] 33%|███▎      | 65/196 [16:02<31:26, 14.40s/it] 34%|███▎      | 66/196 [16:20<33:07, 15.29s/it] 71%|███████▏  | 50/70 [16:35<12:56, 38.82s/it] 40%|████      | 28/70 [09:34<21:41, 30.98s/it] 34%|███▍      | 67/196 [17:01<49:47, 23.16s/it] 73%|███████▎  | 51/70 [17:17<12:37, 39.86s/it] 35%|███▍      | 68/196 [17:19<46:04, 21.60s/it] 41%|████▏     | 29/70 [10:09<22:02, 32.25s/it] 35%|███▌      | 69/196 [17:36<42:36, 20.13s/it] 74%|███████▍  | 52/70 [17:44<10:50, 36.13s/it] 43%|████▎     | 30/70 [10:28<18:43, 28.10s/it] 76%|███████▌  | 53/70 [18:13<09:35, 33.85s/it] 44%|████▍     | 31/70 [10:46<16:16, 25.04s/it] 46%|████▌     | 32/70 [11:06<14:58, 23.64s/it] 36%|███▌      | 70/196 [18:37<1:08:06, 32.43s/it] 77%|███████▋  | 54/70 [18:44<08:48, 33.02s/it] 47%|████▋     | 33/70 [11:24<13:33, 21.98s/it] 49%|████▊     | 34/70 [11:41<12:19, 20.55s/it] 79%|███████▊  | 55/70 [19:13<07:56, 31.75s/it] 36%|███▌      | 71/196 [19:14<1:10:37, 33.90s/it] 50%|█████     | 35/70 [12:00<11:33, 19.81s/it] 37%|███▋      | 72/196 [19:33<1:00:29, 29.27s/it] 80%|████████  | 56/70 [19:41<07:10, 30.74s/it] 51%|█████▏    | 36/70 [12:17<10:48, 19.07s/it] 37%|███▋      | 73/196 [19:50<52:47, 25.75s/it]   53%|█████▎    | 37/70 [12:36<10:33, 19.19s/it] 81%|████████▏ | 57/70 [20:11<06:35, 30.46s/it] 38%|███▊      | 74/196 [20:08<47:29, 23.36s/it] 54%|█████▍    | 38/70 [12:54<10:02, 18.82s/it] 38%|███▊      | 75/196 [20:26<44:03, 21.85s/it] 83%|████████▎ | 58/70 [20:40<05:58, 29.87s/it] 56%|█████▌    | 39/70 [13:12<09:36, 18.61s/it] 39%|███▉      | 76/196 [20:47<43:12, 21.60s/it] 57%|█████▋    | 40/70 [13:31<09:18, 18.62s/it] 84%|████████▍ | 59/70 [21:10<05:29, 29.99s/it] 39%|███▉      | 77/196 [21:07<41:53, 21.13s/it] 59%|█████▊    | 41/70 [13:49<08:57, 18.54s/it] 40%|███▉      | 78/196 [21:28<41:20, 21.02s/it] 60%|██████    | 42/70 [14:08<08:36, 18.44s/it] 86%|████████▌ | 60/70 [21:39<04:57, 29.72s/it] 40%|████      | 79/196 [21:48<40:20, 20.69s/it] 61%|██████▏   | 43/70 [14:28<08:32, 18.97s/it] 87%|████████▋ | 61/70 [22:08<04:25, 29.46s/it] 41%|████      | 80/196 [22:06<38:35, 19.97s/it] 63%|██████▎   | 44/70 [14:46<08:05, 18.69s/it] 41%|████▏     | 81/196 [22:24<36:59, 19.30s/it] 64%|██████▍   | 45/70 [15:03<07:38, 18.33s/it] 89%|████████▊ | 62/70 [22:38<03:56, 29.56s/it] 42%|████▏     | 82/196 [22:41<35:21, 18.61s/it] 66%|██████▌   | 46/70 [15:22<07:19, 18.33s/it] 90%|█████████ | 63/70 [23:06<03:25, 29.37s/it] 42%|████▏     | 83/196 [23:01<35:34, 18.89s/it] 43%|████▎     | 84/196 [23:19<35:02, 18.77s/it] 91%|█████████▏| 64/70 [23:36<02:56, 29.49s/it] 43%|████▎     | 85/196 [23:37<34:15, 18.52s/it] 67%|██████▋   | 47/70 [16:22<11:52, 30.97s/it] 44%|████▍     | 86/196 [23:56<33:57, 18.53s/it] 93%|█████████▎| 65/70 [24:06<02:27, 29.42s/it] 69%|██████▊   | 48/70 [16:52<11:14, 30.68s/it] 44%|████▍     | 87/196 [24:14<33:34, 18.48s/it] 94%|█████████▍| 66/70 [24:34<01:57, 29.26s/it] 45%|████▍     | 88/196 [24:33<33:23, 18.55s/it] 70%|███████   | 49/70 [17:20<10:26, 29.83s/it] 45%|████▌     | 89/196 [24:53<34:08, 19.14s/it] 96%|█████████▌| 67/70 [25:04<01:28, 29.33s/it] 46%|████▌     | 90/196 [25:11<32:59, 18.67s/it] 97%|█████████▋| 68/70 [25:32<00:57, 28.97s/it] 46%|████▋     | 91/196 [25:29<32:30, 18.57s/it] 71%|███████▏  | 50/70 [18:22<13:08, 39.45s/it] 47%|████▋     | 92/196 [25:47<32:05, 18.51s/it] 99%|█████████▊| 69/70 [26:01<00:28, 28.89s/it]100%|██████████| 70/70 [26:05<00:00, 21.63s/it]100%|██████████| 70/70 [26:05<00:00, 22.37s/it]
  0%|          | 0/70 [00:00<?, ?it/s] 47%|████▋     | 93/196 [26:07<32:29, 18.93s/it]  1%|▏         | 1/70 [00:20<23:22, 20.33s/it]  3%|▎         | 2/70 [00:23<11:28, 10.13s/it]  4%|▍         | 3/70 [00:25<07:24,  6.63s/it] 48%|████▊     | 94/196 [26:26<32:15, 18.97s/it] 73%|███████▎  | 51/70 [19:07<13:03, 41.26s/it]  6%|▌         | 4/70 [00:45<12:52, 11.71s/it] 48%|████▊     | 95/196 [26:45<31:46, 18.88s/it]  7%|▋         | 5/70 [00:47<09:06,  8.40s/it]  9%|▊         | 6/70 [00:50<06:56,  6.51s/it] 10%|█         | 7/70 [00:53<05:38,  5.38s/it] 11%|█▏        | 8/70 [00:56<04:48,  4.66s/it] 13%|█▎        | 9/70 [00:59<04:02,  3.98s/it] 14%|█▍        | 10/70 [01:01<03:30,  3.52s/it] 49%|████▉     | 96/196 [27:03<30:54, 18.54s/it] 16%|█▌        | 11/70 [01:04<03:09,  3.22s/it] 74%|███████▍  | 52/70 [19:43<11:52, 39.58s/it] 17%|█▋        | 12/70 [01:07<02:57,  3.06s/it] 19%|█▊        | 13/70 [01:09<02:46,  2.92s/it] 20%|██        | 14/70 [01:12<02:47,  2.99s/it] 21%|██▏       | 15/70 [01:15<02:41,  2.93s/it] 23%|██▎       | 16/70 [01:18<02:43,  3.03s/it] 24%|██▍       | 17/70 [01:21<02:35,  2.94s/it] 49%|████▉     | 97/196 [27:21<30:20, 18.39s/it] 26%|██▌       | 18/70 [01:24<02:37,  3.03s/it] 27%|██▋       | 19/70 [01:28<02:38,  3.11s/it] 29%|██▊       | 20/70 [01:30<02:31,  3.04s/it] 30%|███       | 21/70 [01:33<02:21,  2.89s/it] 76%|███████▌  | 53/70 [20:11<10:15, 36.20s/it] 31%|███▏      | 22/70 [01:36<02:16,  2.84s/it] 33%|███▎      | 23/70 [01:38<02:10,  2.77s/it] 50%|█████     | 98/196 [27:40<30:27, 18.65s/it] 34%|███▍      | 24/70 [01:41<02:06,  2.74s/it] 36%|███▌      | 25/70 [01:54<04:23,  5.86s/it] 37%|███▋      | 26/70 [01:58<03:46,  5.14s/it] 77%|███████▋  | 54/70 [20:39<08:59, 33.69s/it] 39%|███▊      | 27/70 [02:01<03:23,  4.72s/it] 51%|█████     | 99/196 [28:01<31:20, 19.39s/it] 40%|████      | 28/70 [02:22<06:40,  9.55s/it] 51%|█████     | 100/196 [28:24<32:28, 20.30s/it] 41%|████▏     | 29/70 [02:33<06:47,  9.93s/it] 79%|███████▊  | 55/70 [21:14<08:29, 34.00s/it] 43%|████▎     | 30/70 [02:37<05:23,  8.10s/it] 44%|████▍     | 31/70 [02:40<04:21,  6.71s/it] 46%|████▌     | 32/70 [02:44<03:36,  5.70s/it] 52%|█████▏    | 101/196 [28:45<32:29, 20.52s/it] 47%|████▋     | 33/70 [02:47<03:05,  5.01s/it] 49%|████▊     | 34/70 [02:51<02:45,  4.59s/it] 50%|█████     | 35/70 [02:54<02:32,  4.34s/it] 51%|█████▏    | 36/70 [02:58<02:18,  4.06s/it] 53%|█████▎    | 37/70 [03:01<02:08,  3.89s/it] 54%|█████▍    | 38/70 [03:05<02:01,  3.79s/it] 52%|█████▏    | 102/196 [29:04<31:38, 20.20s/it] 56%|█████▌    | 39/70 [03:09<01:59,  3.86s/it] 80%|████████  | 56/70 [21:49<08:01, 34.36s/it] 57%|█████▋    | 40/70 [03:12<01:53,  3.78s/it] 59%|█████▊    | 41/70 [03:16<01:48,  3.76s/it] 60%|██████    | 42/70 [03:20<01:42,  3.66s/it] 53%|█████▎    | 103/196 [29:22<30:22, 19.59s/it] 61%|██████▏   | 43/70 [03:23<01:38,  3.66s/it] 63%|██████▎   | 44/70 [03:27<01:37,  3.74s/it] 64%|██████▍   | 45/70 [03:31<01:31,  3.67s/it] 66%|██████▌   | 46/70 [03:34<01:26,  3.61s/it] 81%|████████▏ | 57/70 [22:17<07:01, 32.46s/it] 53%|█████▎    | 104/196 [29:41<29:44, 19.40s/it] 67%|██████▋   | 47/70 [03:51<02:52,  7.50s/it] 69%|██████▊   | 48/70 [03:56<02:32,  6.92s/it] 54%|█████▎    | 105/196 [30:00<29:13, 19.27s/it] 70%|███████   | 49/70 [04:02<02:19,  6.64s/it] 83%|████████▎ | 58/70 [22:45<06:12, 31.06s/it] 54%|█████▍    | 106/196 [30:19<28:33, 19.03s/it] 71%|███████▏  | 50/70 [04:27<03:59, 11.95s/it] 84%|████████▍ | 59/70 [23:13<05:30, 30.05s/it] 55%|█████▍    | 107/196 [30:38<28:15, 19.05s/it] 73%|███████▎  | 51/70 [04:40<03:55, 12.40s/it] 74%|███████▍  | 52/70 [04:46<03:07, 10.41s/it] 76%|███████▌  | 53/70 [04:52<02:33,  9.01s/it] 55%|█████▌    | 108/196 [30:56<27:27, 18.72s/it] 77%|███████▋  | 54/70 [04:57<02:09,  8.06s/it] 86%|████████▌ | 60/70 [23:41<04:54, 29.44s/it] 79%|███████▊  | 55/70 [05:03<01:51,  7.41s/it] 80%|████████  | 56/70 [05:09<01:37,  7.00s/it] 56%|█████▌    | 109/196 [31:14<26:56, 18.58s/it] 81%|████████▏ | 57/70 [05:15<01:26,  6.63s/it] 83%|████████▎ | 58/70 [05:21<01:17,  6.42s/it] 84%|████████▍ | 59/70 [05:27<01:08,  6.25s/it] 87%|████████▋ | 61/70 [24:09<04:22, 29.12s/it] 86%|████████▌ | 60/70 [05:33<01:01,  6.12s/it] 56%|█████▌    | 110/196 [31:33<26:38, 18.59s/it] 87%|████████▋ | 61/70 [05:39<00:54,  6.06s/it] 89%|████████▊ | 62/70 [05:45<00:48,  6.08s/it] 90%|█████████ | 63/70 [05:51<00:42,  6.04s/it] 57%|█████▋    | 111/196 [31:51<26:11, 18.49s/it] 91%|█████████▏| 64/70 [05:57<00:35,  5.99s/it] 93%|█████████▎| 65/70 [06:03<00:29,  5.97s/it] 89%|████████▊ | 62/70 [24:45<04:08, 31.05s/it] 94%|█████████▍| 66/70 [06:09<00:24,  6.00s/it] 57%|█████▋    | 112/196 [32:09<25:50, 18.46s/it] 96%|█████████▌| 67/70 [06:15<00:17,  5.99s/it] 97%|█████████▋| 68/70 [06:20<00:11,  5.96s/it] 99%|█████████▊| 69/70 [06:26<00:05,  5.90s/it]100%|██████████| 70/70 [06:27<00:00,  4.43s/it]100%|██████████| 70/70 [06:27<00:00,  5.54s/it]
 58%|█████▊    | 113/196 [32:28<25:40, 18.57s/it] 90%|█████████ | 63/70 [25:18<03:42, 31.75s/it] 58%|█████▊    | 114/196 [32:47<25:23, 18.57s/it] 59%|█████▊    | 115/196 [33:05<24:51, 18.41s/it] 91%|█████████▏| 64/70 [25:53<03:16, 32.75s/it] 59%|█████▉    | 116/196 [33:25<25:15, 18.94s/it] 60%|█████▉    | 117/196 [33:44<24:57, 18.95s/it] 93%|█████████▎| 65/70 [26:28<02:46, 33.30s/it] 60%|██████    | 118/196 [34:04<24:54, 19.16s/it] 94%|█████████▍| 66/70 [26:56<02:07, 31.92s/it] 61%|██████    | 119/196 [34:22<24:30, 19.10s/it] 61%|██████    | 120/196 [34:40<23:42, 18.72s/it] 96%|█████████▌| 67/70 [27:24<01:32, 30.76s/it] 62%|██████▏   | 121/196 [34:58<23:06, 18.48s/it] 97%|█████████▋| 68/70 [27:53<01:00, 30.03s/it] 62%|██████▏   | 122/196 [35:16<22:41, 18.40s/it] 63%|██████▎   | 123/196 [35:34<22:11, 18.25s/it] 99%|█████████▊| 69/70 [28:20<00:29, 29.14s/it]100%|██████████| 70/70 [28:24<00:00, 21.68s/it]100%|██████████| 70/70 [28:24<00:00, 24.35s/it]
  0%|          | 0/70 [00:00<?, ?it/s] 63%|██████▎   | 124/196 [35:53<22:05, 18.41s/it]  1%|▏         | 1/70 [00:21<24:16, 21.11s/it]  3%|▎         | 2/70 [00:23<11:40, 10.29s/it] 64%|██████▍   | 125/196 [36:12<21:46, 18.41s/it]  4%|▍         | 3/70 [00:26<07:49,  7.01s/it] 64%|██████▍   | 126/196 [36:30<21:26, 18.38s/it]  6%|▌         | 4/70 [00:48<14:11, 12.90s/it]  7%|▋         | 5/70 [00:52<10:10,  9.39s/it]  9%|▊         | 6/70 [00:54<07:36,  7.14s/it] 10%|█         | 7/70 [00:57<05:59,  5.71s/it] 11%|█▏        | 8/70 [01:00<04:59,  4.83s/it] 65%|██████▍   | 127/196 [36:48<21:11, 18.43s/it] 13%|█▎        | 9/70 [01:03<04:16,  4.21s/it] 14%|█▍        | 10/70 [01:06<03:48,  3.80s/it] 16%|█▌        | 11/70 [01:09<03:26,  3.49s/it] 17%|█▋        | 12/70 [01:11<03:11,  3.30s/it] 19%|█▊        | 13/70 [01:15<03:09,  3.32s/it] 20%|██        | 14/70 [01:18<03:04,  3.30s/it] 21%|██▏       | 15/70 [01:21<02:54,  3.17s/it] 65%|██████▌   | 128/196 [37:07<21:03, 18.59s/it] 23%|██▎       | 16/70 [01:24<02:47,  3.10s/it] 24%|██▍       | 17/70 [01:27<02:41,  3.04s/it] 26%|██▌       | 18/70 [01:30<02:35,  2.98s/it] 27%|██▋       | 19/70 [01:32<02:30,  2.95s/it] 29%|██▊       | 20/70 [01:35<02:25,  2.92s/it] 30%|███       | 21/70 [01:38<02:21,  2.89s/it] 66%|██████▌   | 129/196 [37:27<21:03, 18.86s/it] 31%|███▏      | 22/70 [01:41<02:18,  2.89s/it] 33%|███▎      | 23/70 [01:44<02:16,  2.90s/it] 34%|███▍      | 24/70 [01:47<02:18,  3.02s/it] 66%|██████▋   | 130/196 [37:45<20:34, 18.71s/it] 36%|███▌      | 25/70 [02:02<04:58,  6.63s/it] 37%|███▋      | 26/70 [02:06<04:09,  5.68s/it] 39%|███▊      | 27/70 [02:09<03:35,  5.00s/it] 40%|████      | 28/70 [02:32<07:20, 10.48s/it] 41%|████▏     | 29/70 [02:44<07:22, 10.80s/it] 43%|████▎     | 30/70 [02:47<05:44,  8.61s/it] 44%|████▍     | 31/70 [02:51<04:36,  7.08s/it] 67%|██████▋   | 131/196 [38:38<31:29, 29.07s/it] 46%|████▌     | 32/70 [02:55<03:49,  6.03s/it] 47%|████▋     | 33/70 [02:58<03:15,  5.28s/it] 49%|████▊     | 34/70 [03:02<02:56,  4.90s/it] 50%|█████     | 35/70 [03:06<02:36,  4.49s/it] 51%|█████▏    | 36/70 [03:09<02:22,  4.18s/it] 53%|█████▎    | 37/70 [03:13<02:12,  4.01s/it] 54%|█████▍    | 38/70 [03:16<02:03,  3.87s/it] 56%|█████▌    | 39/70 [03:20<01:56,  3.76s/it] 67%|██████▋   | 132/196 [39:08<31:04, 29.14s/it] 57%|█████▋    | 40/70 [03:23<01:51,  3.71s/it] 59%|█████▊    | 41/70 [03:27<01:46,  3.69s/it] 60%|██████    | 42/70 [03:31<01:42,  3.65s/it] 61%|██████▏   | 43/70 [03:34<01:37,  3.62s/it] 63%|██████▎   | 44/70 [03:38<01:33,  3.61s/it] 64%|██████▍   | 45/70 [03:41<01:29,  3.60s/it] 66%|██████▌   | 46/70 [03:46<01:31,  3.83s/it] 68%|██████▊   | 133/196 [39:37<30:35, 29.14s/it] 67%|██████▋   | 47/70 [04:04<03:06,  8.12s/it] 69%|██████▊   | 48/70 [04:09<02:42,  7.40s/it] 70%|███████   | 49/70 [04:15<02:23,  6.83s/it] 71%|███████▏  | 50/70 [04:42<04:18, 12.91s/it] 73%|███████▎  | 51/70 [04:59<04:26, 14.02s/it] 74%|███████▍  | 52/70 [05:06<03:34, 11.94s/it] 68%|██████▊   | 134/196 [40:53<44:49, 43.38s/it] 76%|███████▌  | 53/70 [05:12<02:51, 10.09s/it] 77%|███████▋  | 54/70 [05:17<02:20,  8.78s/it] 79%|███████▊  | 55/70 [05:23<01:58,  7.88s/it] 80%|████████  | 56/70 [05:29<01:42,  7.30s/it] 81%|████████▏ | 57/70 [05:35<01:28,  6.79s/it] 83%|████████▎ | 58/70 [05:40<01:17,  6.43s/it] 84%|████████▍ | 59/70 [05:46<01:08,  6.21s/it] 86%|████████▌ | 60/70 [05:52<01:00,  6.04s/it] 69%|██████▉   | 135/196 [41:42<45:48, 45.05s/it] 87%|████████▋ | 61/70 [05:57<00:53,  5.91s/it] 89%|████████▊ | 62/70 [06:03<00:46,  5.82s/it] 90%|█████████ | 63/70 [06:08<00:40,  5.74s/it] 91%|█████████▏| 64/70 [06:14<00:34,  5.69s/it] 93%|█████████▎| 65/70 [06:19<00:28,  5.66s/it] 94%|█████████▍| 66/70 [06:25<00:22,  5.67s/it] 69%|██████▉   | 136/196 [42:13<40:42, 40.71s/it] 96%|█████████▌| 67/70 [06:31<00:17,  5.67s/it] 97%|█████████▋| 68/70 [06:36<00:11,  5.64s/it] 99%|█████████▊| 69/70 [06:43<00:06,  6.05s/it]100%|██████████| 70/70 [06:44<00:00,  4.50s/it]100%|██████████| 70/70 [06:44<00:00,  5.78s/it]
 70%|██████▉   | 137/196 [42:43<36:44, 37.36s/it] 70%|███████   | 138/196 [43:13<34:05, 35.26s/it] 71%|███████   | 139/196 [43:42<31:40, 33.35s/it] 71%|███████▏  | 140/196 [44:11<30:01, 32.17s/it] 72%|███████▏  | 141/196 [44:41<28:41, 31.30s/it] 72%|███████▏  | 142/196 [45:10<27:34, 30.64s/it] 73%|███████▎  | 143/196 [45:39<26:41, 30.22s/it] 73%|███████▎  | 144/196 [46:08<25:54, 29.90s/it] 74%|███████▍  | 145/196 [46:37<25:12, 29.66s/it] 74%|███████▍  | 146/196 [47:06<24:37, 29.55s/it] 75%|███████▌  | 147/196 [47:36<24:08, 29.55s/it] 76%|███████▌  | 148/196 [48:05<23:36, 29.50s/it] 76%|███████▌  | 149/196 [48:34<22:56, 29.28s/it] 77%|███████▋  | 150/196 [49:04<22:30, 29.36s/it] 77%|███████▋  | 151/196 [49:33<21:58, 29.30s/it] 78%|███████▊  | 152/196 [50:02<21:26, 29.25s/it] 78%|███████▊  | 153/196 [50:32<21:02, 29.36s/it] 79%|███████▊  | 154/196 [51:01<20:29, 29.27s/it] 79%|███████▉  | 155/196 [51:30<20:03, 29.35s/it] 80%|███████▉  | 156/196 [52:00<19:37, 29.45s/it] 80%|████████  | 157/196 [52:29<19:06, 29.40s/it] 81%|████████  | 158/196 [52:58<18:36, 29.37s/it] 81%|████████  | 159/196 [53:28<18:04, 29.31s/it] 82%|████████▏ | 160/196 [53:57<17:34, 29.29s/it] 82%|████████▏ | 161/196 [54:27<17:10, 29.43s/it] 83%|████████▎ | 162/196 [54:56<16:38, 29.38s/it] 83%|████████▎ | 163/196 [55:25<16:10, 29.41s/it] 84%|████████▎ | 164/196 [55:55<15:40, 29.40s/it] 84%|████████▍ | 165/196 [56:24<15:11, 29.39s/it] 85%|████████▍ | 166/196 [56:53<14:39, 29.30s/it] 85%|████████▌ | 167/196 [57:23<14:12, 29.39s/it] 86%|████████▌ | 168/196 [57:52<13:44, 29.45s/it] 86%|████████▌ | 169/196 [58:21<13:11, 29.33s/it] 87%|████████▋ | 170/196 [58:51<12:45, 29.45s/it] 87%|████████▋ | 171/196 [59:21<12:17, 29.51s/it] 88%|████████▊ | 172/196 [59:50<11:48, 29.52s/it] 88%|████████▊ | 173/196 [1:00:20<11:17, 29.45s/it] 89%|████████▉ | 174/196 [1:00:49<10:48, 29.48s/it] 89%|████████▉ | 175/196 [1:01:18<10:17, 29.42s/it] 90%|████████▉ | 176/196 [1:01:48<09:50, 29.55s/it] 90%|█████████ | 177/196 [1:02:18<09:20, 29.52s/it] 91%|█████████ | 178/196 [1:02:47<08:51, 29.54s/it] 91%|█████████▏| 179/196 [1:03:17<08:22, 29.57s/it] 92%|█████████▏| 180/196 [1:03:47<07:55, 29.73s/it] 92%|█████████▏| 181/196 [1:04:16<07:24, 29.60s/it] 93%|█████████▎| 182/196 [1:04:46<06:53, 29.57s/it] 93%|█████████▎| 183/196 [1:05:16<06:25, 29.63s/it] 94%|█████████▍| 184/196 [1:05:45<05:55, 29.61s/it] 94%|█████████▍| 185/196 [1:06:15<05:24, 29.54s/it] 95%|█████████▍| 186/196 [1:06:44<04:55, 29.56s/it] 95%|█████████▌| 187/196 [1:07:14<04:27, 29.73s/it] 96%|█████████▌| 188/196 [1:07:48<04:08, 31.03s/it] 96%|█████████▋| 189/196 [1:08:19<03:36, 30.97s/it] 97%|█████████▋| 190/196 [1:08:49<03:03, 30.66s/it] 97%|█████████▋| 191/196 [1:09:19<02:32, 30.53s/it] 98%|█████████▊| 192/196 [1:09:49<02:01, 30.31s/it] 98%|█████████▊| 193/196 [1:10:19<01:30, 30.11s/it] 99%|█████████▉| 194/196 [1:10:49<01:00, 30.05s/it] 99%|█████████▉| 195/196 [1:11:18<00:29, 29.96s/it]100%|██████████| 196/196 [1:11:23<00:00, 22.47s/it]100%|██████████| 196/196 [1:11:23<00:00, 21.86s/it]
  0%|          | 0/196 [00:00<?, ?it/s]  1%|          | 1/196 [00:23<1:16:21, 23.49s/it]  1%|          | 2/196 [00:25<36:01, 11.14s/it]    2%|▏         | 3/196 [00:28<22:49,  7.09s/it]  2%|▏         | 4/196 [00:52<43:54, 13.72s/it]  3%|▎         | 5/196 [00:54<30:36,  9.62s/it]  3%|▎         | 6/196 [00:56<22:43,  7.18s/it]  4%|▎         | 7/196 [00:59<17:36,  5.59s/it]  4%|▍         | 8/196 [01:01<14:21,  4.58s/it]  5%|▍         | 9/196 [01:04<12:07,  3.89s/it]  5%|▌         | 10/196 [01:06<10:37,  3.43s/it]  6%|▌         | 11/196 [01:09<09:54,  3.21s/it]  6%|▌         | 12/196 [01:11<09:08,  2.98s/it]  7%|▋         | 13/196 [01:13<08:31,  2.80s/it]  7%|▋         | 14/196 [01:16<08:07,  2.68s/it]  8%|▊         | 15/196 [01:18<07:49,  2.60s/it]  8%|▊         | 16/196 [01:21<07:38,  2.55s/it]  9%|▊         | 17/196 [01:23<07:28,  2.51s/it]  9%|▉         | 18/196 [01:26<07:21,  2.48s/it] 10%|▉         | 19/196 [01:28<07:15,  2.46s/it] 10%|█         | 20/196 [01:30<07:10,  2.44s/it] 11%|█         | 21/196 [01:33<07:05,  2.43s/it] 11%|█         | 22/196 [01:35<07:04,  2.44s/it] 12%|█▏        | 23/196 [01:38<07:07,  2.47s/it] 12%|█▏        | 24/196 [01:40<07:06,  2.48s/it] 13%|█▎        | 25/196 [01:43<07:05,  2.49s/it] 13%|█▎        | 26/196 [01:45<07:01,  2.48s/it] 14%|█▍        | 27/196 [01:48<06:55,  2.46s/it] 14%|█▍        | 28/196 [01:50<06:56,  2.48s/it] 15%|█▍        | 29/196 [01:53<06:52,  2.47s/it] 15%|█▌        | 30/196 [01:55<06:48,  2.46s/it] 16%|█▌        | 31/196 [01:58<06:52,  2.50s/it] 16%|█▋        | 32/196 [02:00<06:48,  2.49s/it] 17%|█▋        | 33/196 [02:03<06:47,  2.50s/it] 17%|█▋        | 34/196 [02:05<06:44,  2.49s/it] 18%|█▊        | 35/196 [02:08<06:43,  2.50s/it] 18%|█▊        | 36/196 [02:10<06:44,  2.53s/it] 19%|█▉        | 37/196 [02:13<06:46,  2.56s/it] 19%|█▉        | 38/196 [02:16<06:49,  2.59s/it] 20%|█▉        | 39/196 [02:18<06:46,  2.59s/it] 20%|██        | 40/196 [02:21<06:45,  2.60s/it] 21%|██        | 41/196 [02:23<06:41,  2.59s/it] 21%|██▏       | 42/196 [02:26<06:39,  2.59s/it] 22%|██▏       | 43/196 [02:28<06:35,  2.58s/it] 22%|██▏       | 44/196 [02:31<06:34,  2.59s/it] 23%|██▎       | 45/196 [02:34<06:30,  2.58s/it] 23%|██▎       | 46/196 [02:36<06:30,  2.60s/it] 24%|██▍       | 47/196 [02:39<06:32,  2.63s/it] 24%|██▍       | 48/196 [02:42<06:33,  2.66s/it] 25%|██▌       | 49/196 [02:44<06:31,  2.67s/it] 26%|██▌       | 50/196 [02:47<06:32,  2.69s/it] 26%|██▌       | 51/196 [02:50<06:30,  2.69s/it] 27%|██▋       | 52/196 [02:53<06:28,  2.70s/it] 27%|██▋       | 53/196 [02:55<06:24,  2.69s/it] 28%|██▊       | 54/196 [02:59<06:47,  2.87s/it] 28%|██▊       | 55/196 [03:01<06:38,  2.82s/it] 29%|██▊       | 56/196 [03:04<06:30,  2.79s/it] 29%|██▉       | 57/196 [03:07<06:25,  2.78s/it] 30%|██▉       | 58/196 [03:09<06:23,  2.78s/it] 30%|███       | 59/196 [03:12<06:20,  2.78s/it] 31%|███       | 60/196 [03:15<06:15,  2.76s/it] 31%|███       | 61/196 [03:18<06:11,  2.75s/it] 32%|███▏      | 62/196 [03:20<06:09,  2.76s/it] 32%|███▏      | 63/196 [03:23<06:05,  2.75s/it] 33%|███▎      | 64/196 [03:26<06:03,  2.75s/it] 33%|███▎      | 65/196 [03:29<06:02,  2.77s/it] 34%|███▎      | 66/196 [03:32<06:00,  2.77s/it] 34%|███▍      | 67/196 [03:47<13:58,  6.50s/it] 35%|███▍      | 68/196 [03:50<11:58,  5.61s/it] 35%|███▌      | 69/196 [03:54<10:32,  4.98s/it] 36%|███▌      | 70/196 [04:18<22:50, 10.88s/it] 36%|███▌      | 71/196 [04:31<23:59, 11.52s/it] 37%|███▋      | 72/196 [04:35<18:54,  9.15s/it] 37%|███▋      | 73/196 [04:39<15:21,  7.49s/it] 38%|███▊      | 74/196 [04:42<12:54,  6.35s/it] 38%|███▊      | 75/196 [04:46<11:09,  5.53s/it] 39%|███▉      | 76/196 [04:50<09:55,  4.96s/it] 39%|███▉      | 77/196 [04:54<09:15,  4.67s/it] 40%|███▉      | 78/196 [04:57<08:33,  4.35s/it] 40%|████      | 79/196 [05:01<08:02,  4.12s/it] 41%|████      | 80/196 [05:04<07:40,  3.97s/it] 41%|████▏     | 81/196 [05:08<07:23,  3.86s/it] 42%|████▏     | 82/196 [05:12<07:13,  3.81s/it] 42%|████▏     | 83/196 [05:15<07:06,  3.77s/it] 43%|████▎     | 84/196 [05:19<06:58,  3.74s/it] 43%|████▎     | 85/196 [05:23<06:53,  3.72s/it] 44%|████▍     | 86/196 [05:26<06:48,  3.72s/it] 44%|████▍     | 87/196 [05:30<06:45,  3.72s/it] 45%|████▍     | 88/196 [05:34<06:40,  3.71s/it] 45%|████▌     | 89/196 [05:38<06:36,  3.71s/it] 46%|████▌     | 90/196 [05:41<06:31,  3.70s/it] 46%|████▋     | 91/196 [05:45<06:40,  3.81s/it] 47%|████▋     | 92/196 [05:49<06:32,  3.77s/it] 47%|████▋     | 93/196 [05:53<06:27,  3.76s/it] 48%|████▊     | 94/196 [05:56<06:22,  3.75s/it] 48%|████▊     | 95/196 [06:00<06:17,  3.73s/it] 49%|████▉     | 96/196 [06:04<06:12,  3.73s/it] 49%|████▉     | 97/196 [06:08<06:09,  3.74s/it] 50%|█████     | 98/196 [06:11<06:06,  3.74s/it] 51%|█████     | 99/196 [06:15<06:04,  3.76s/it] 51%|█████     | 100/196 [06:19<06:01,  3.77s/it] 52%|█████▏    | 101/196 [06:23<05:56,  3.76s/it] 52%|█████▏    | 102/196 [06:26<05:52,  3.75s/it] 53%|█████▎    | 103/196 [06:30<05:47,  3.74s/it] 53%|█████▎    | 104/196 [06:34<05:46,  3.76s/it] 54%|█████▎    | 105/196 [06:38<05:50,  3.85s/it] 54%|█████▍    | 106/196 [06:42<05:44,  3.82s/it] 55%|█████▍    | 107/196 [06:46<05:39,  3.81s/it] 55%|█████▌    | 108/196 [06:49<05:36,  3.82s/it] 56%|█████▌    | 109/196 [06:53<05:31,  3.81s/it] 56%|█████▌    | 110/196 [06:57<05:28,  3.82s/it] 57%|█████▋    | 111/196 [07:01<05:24,  3.82s/it] 57%|█████▋    | 112/196 [07:05<05:19,  3.81s/it] 58%|█████▊    | 113/196 [07:08<05:15,  3.81s/it] 58%|█████▊    | 114/196 [07:12<05:11,  3.80s/it] 59%|█████▊    | 115/196 [07:16<05:07,  3.80s/it] 59%|█████▉    | 116/196 [07:20<05:04,  3.81s/it] 60%|█████▉    | 117/196 [07:24<05:00,  3.81s/it] 60%|██████    | 118/196 [07:28<05:02,  3.88s/it] 61%|██████    | 119/196 [07:31<04:56,  3.85s/it] 61%|██████    | 120/196 [07:35<04:51,  3.84s/it] 62%|██████▏   | 121/196 [07:39<04:47,  3.83s/it] 62%|██████▏   | 122/196 [07:43<04:43,  3.83s/it] 63%|██████▎   | 123/196 [07:47<04:41,  3.86s/it] 63%|██████▎   | 124/196 [07:51<04:40,  3.89s/it] 64%|██████▍   | 125/196 [07:55<04:37,  3.91s/it] 64%|██████▍   | 126/196 [07:59<04:33,  3.91s/it] 65%|██████▍   | 127/196 [08:03<04:31,  3.94s/it] 65%|██████▌   | 128/196 [08:07<04:35,  4.05s/it] 66%|██████▌   | 129/196 [08:11<04:28,  4.00s/it] 66%|██████▋   | 130/196 [08:15<04:21,  3.96s/it] 67%|██████▋   | 131/196 [08:32<08:44,  8.06s/it] 67%|██████▋   | 132/196 [08:38<07:58,  7.47s/it] 68%|██████▊   | 133/196 [08:45<07:25,  7.07s/it] 68%|██████▊   | 134/196 [09:10<13:02, 12.62s/it] 69%|██████▉   | 135/196 [09:25<13:21, 13.14s/it] 69%|██████▉   | 136/196 [09:31<11:01, 11.03s/it] 70%|██████▉   | 137/196 [09:37<09:22,  9.53s/it] 70%|███████   | 138/196 [09:44<08:30,  8.81s/it] 71%|███████   | 139/196 [09:50<07:34,  7.97s/it] 71%|███████▏  | 140/196 [09:56<06:52,  7.37s/it] 72%|███████▏  | 141/196 [10:02<06:24,  6.99s/it] 72%|███████▏  | 142/196 [10:08<06:01,  6.70s/it] 73%|███████▎  | 143/196 [10:14<05:44,  6.50s/it] 73%|███████▎  | 144/196 [10:20<05:33,  6.41s/it] 74%|███████▍  | 145/196 [10:26<05:24,  6.36s/it] 74%|███████▍  | 146/196 [10:33<05:16,  6.33s/it] 75%|███████▌  | 147/196 [10:39<05:08,  6.29s/it] 76%|███████▌  | 148/196 [10:45<05:03,  6.33s/it] 76%|███████▌  | 149/196 [10:51<04:53,  6.26s/it] 77%|███████▋  | 150/196 [10:57<04:44,  6.18s/it] 77%|███████▋  | 151/196 [11:03<04:36,  6.16s/it] 78%|███████▊  | 152/196 [11:10<04:31,  6.17s/it] 78%|███████▊  | 153/196 [11:16<04:24,  6.16s/it] 79%|███████▊  | 154/196 [11:22<04:19,  6.17s/it] 79%|███████▉  | 155/196 [11:28<04:14,  6.21s/it] 80%|███████▉  | 156/196 [11:35<04:09,  6.23s/it] 80%|████████  | 157/196 [11:41<04:05,  6.28s/it] 81%|████████  | 158/196 [11:47<03:57,  6.24s/it] 81%|████████  | 159/196 [11:53<03:49,  6.21s/it] 82%|████████▏ | 160/196 [12:00<03:44,  6.23s/it] 82%|████████▏ | 161/196 [12:06<03:37,  6.21s/it] 83%|████████▎ | 162/196 [12:12<03:30,  6.20s/it] 83%|████████▎ | 163/196 [12:18<03:25,  6.23s/it] 84%|████████▎ | 164/196 [12:24<03:19,  6.25s/it] 84%|████████▍ | 165/196 [12:31<03:15,  6.31s/it] 85%|████████▍ | 166/196 [12:37<03:09,  6.32s/it]start time : Wed Mar  3 22:47:01 2021
Namespace(dataset='cifar10', k_kmnc=10, k_nc=0.75, k_tknc=3, model='MobileNet', path0='/media/data0/DeepSuite', path1='/media/data1/DeepSuite', sa_layer=-1, sa_n=1000)
 85%|████████▌ | 167/196 [12:43<03:02,  6.28s/it]load MobileNet...
2021-03-03 22:47:06.663633: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-03-03 22:47:06.697007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:9b:00.0 name: Quadro RTX 8000 computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.43GiB deviceMemoryBandwidth: 625.94GiB/s
2021-03-03 22:47:06.697107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-03-03 22:47:06.701619: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-03-03 22:47:06.715073: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-03-03 22:47:06.717131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-03-03 22:47:06.723648: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-03-03 22:47:06.726435: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-03-03 22:47:06.739105: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 22:47:06.743182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2021-03-03 22:47:06.743688: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2021-03-03 22:47:06.785885: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2600000000 Hz
2021-03-03 22:47:06.803415: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5620eb60ca10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-03-03 22:47:06.803520: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-03-03 22:47:06.810519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:9b:00.0 name: Quadro RTX 8000 computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.43GiB deviceMemoryBandwidth: 625.94GiB/s
2021-03-03 22:47:06.810711: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2021-03-03 22:47:06.810756: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2021-03-03 22:47:06.810790: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2021-03-03 22:47:06.810825: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2021-03-03 22:47:06.810859: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2021-03-03 22:47:06.810893: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2021-03-03 22:47:06.810928: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2021-03-03 22:47:06.816590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2021-03-03 22:47:06.817147: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
 86%|████████▌ | 168/196 [12:50<02:55,  6.27s/it] 86%|████████▌ | 169/196 [12:56<02:48,  6.26s/it]2021-03-03 22:47:17.090662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-03-03 22:47:17.090732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2021-03-03 22:47:17.090741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2021-03-03 22:47:17.097328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 32022 MB memory) -> physical GPU (device: 0, name: Quadro RTX 8000, pci bus id: 0000:9b:00.0, compute capability: 7.5)
2021-03-03 22:47:17.101109: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562199d72ec0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-03-03 22:47:17.101157: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5
 87%|████████▋ | 170/196 [13:02<02:43,  6.28s/it]start time : Wed Mar  3 22:47:23 2021
Namespace(dataset='cifar10', k_kmnc=10, k_nc=0.75, k_tknc=3, model='MobileNet', path0='/media/data0/DeepSuite', path1='/media/data1/DeepSuite', sa_layer=-1, sa_n=1000)
/media/data1/DeepSuite/trained_models/cifar10/MobileNet.h5
Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, None, None, 3)]   0         
_________________________________________________________________
conv1_pad (ZeroPadding2D)    (None, None, None, 3)     0         
_________________________________________________________________
conv1 (Conv2D)               (None, None, None, 32)    864       
_________________________________________________________________
conv1_bn (BatchNormalization (None, None, None, 32)    128       
_________________________________________________________________
conv1_relu (ReLU)            (None, None, None, 32)    0         
_________________________________________________________________
conv_dw_1 (DepthwiseConv2D)  (None, None, None, 32)    288       
_________________________________________________________________
conv_dw_1_bn (BatchNormaliza (None, None, None, 32)    128       
_________________________________________________________________
conv_dw_1_relu (ReLU)        (None, None, None, 32)    0         
_________________________________________________________________
conv_pw_1 (Conv2D)           (None, None, None, 64)    2048      
_________________________________________________________________
conv_pw_1_bn (BatchNormaliza (None, None, None, 64)    256       
_________________________________________________________________
conv_pw_1_relu (ReLU)        (None, None, None, 64)    0         
_________________________________________________________________
conv_pad_2 (ZeroPadding2D)   (None, None, None, 64)    0         
_________________________________________________________________
conv_dw_2 (DepthwiseConv2D)  (None, None, None, 64)    576       
_________________________________________________________________
conv_dw_2_bn (BatchNormaliza (None, None, None, 64)    256       
_________________________________________________________________
conv_dw_2_relu (ReLU)        (None, None, None, 64)    0         
_________________________________________________________________
conv_pw_2 (Conv2D)           (None, None, None, 128)   8192      
_________________________________________________________________
conv_pw_2_bn (BatchNormaliza (None, None, None, 128)   512       
_________________________________________________________________
conv_pw_2_relu (ReLU)        (None, None, None, 128)   0         
_________________________________________________________________
conv_dw_3 (DepthwiseConv2D)  (None, None, None, 128)   1152      
_________________________________________________________________
conv_dw_3_bn (BatchNormaliza (None, None, None, 128)   512       
_________________________________________________________________
conv_dw_3_relu (ReLU)        (None, None, None, 128)   0         
_________________________________________________________________
conv_pw_3 (Conv2D)           (None, None, None, 128)   16384     
_________________________________________________________________
conv_pw_3_bn (BatchNormaliza (None, None, None, 128)   512       
_________________________________________________________________
conv_pw_3_relu (ReLU)        (None, None, None, 128)   0         
_________________________________________________________________
conv_pad_4 (ZeroPadding2D)   (None, None, None, 128)   0         
_________________________________________________________________
conv_dw_4 (DepthwiseConv2D)  (None, None, None, 128)   1152      
_________________________________________________________________
conv_dw_4_bn (BatchNormaliza (None, None, None, 128)   512       
_________________________________________________________________
conv_dw_4_relu (ReLU)        (None, None, None, 128)   0         
_________________________________________________________________
conv_pw_4 (Conv2D)           (None, None, None, 256)   32768     
_________________________________________________________________
conv_pw_4_bn (BatchNormaliza (None, None, None, 256)   1024      
_________________________________________________________________
conv_pw_4_relu (ReLU)        (None, None, None, 256)   0         
_________________________________________________________________
conv_dw_5 (DepthwiseConv2D)  (None, None, None, 256)   2304      
_________________________________________________________________
conv_dw_5_bn (BatchNormaliza (None, None, None, 256)   1024      
_________________________________________________________________
conv_dw_5_relu (ReLU)        (None, None, None, 256)   0         
_________________________________________________________________
conv_pw_5 (Conv2D)           (None, None, None, 256)   65536     
_________________________________________________________________
conv_pw_5_bn (BatchNormaliza (None, None, None, 256)   1024      
_________________________________________________________________
conv_pw_5_relu (ReLU)        (None, None, None, 256)   0         
_________________________________________________________________
conv_pad_6 (ZeroPadding2D)   (None, None, None, 256)   0         
_________________________________________________________________
conv_dw_6 (DepthwiseConv2D)  (None, None, None, 256)   2304      
_________________________________________________________________
conv_dw_6_bn (BatchNormaliza (None, None, None, 256)   1024      
_________________________________________________________________
conv_dw_6_relu (ReLU)        (None, None, None, 256)   0         
_________________________________________________________________
conv_pw_6 (Conv2D)           (None, None, None, 512)   131072    
_________________________________________________________________
conv_pw_6_bn (BatchNormaliza (None, None, None, 512)   2048      
_________________________________________________________________
conv_pw_6_relu (ReLU)        (None, None, None, 512)   0         
_________________________________________________________________
conv_dw_7 (DepthwiseConv2D)  (None, None, None, 512)   4608      
_________________________________________________________________
conv_dw_7_bn (BatchNormaliza (None, None, None, 512)   2048      
_________________________________________________________________
conv_dw_7_relu (ReLU)        (None, None, None, 512)   0         
_________________________________________________________________
conv_pw_7 (Conv2D)           (None, None, None, 512)   262144    
_________________________________________________________________
conv_pw_7_bn (BatchNormaliza (None, None, None, 512)   2048      
_________________________________________________________________
conv_pw_7_relu (ReLU)        (None, None, None, 512)   0         
_________________________________________________________________
conv_dw_8 (DepthwiseConv2D)  (None, None, None, 512)   4608      
_________________________________________________________________
conv_dw_8_bn (BatchNormaliza (None, None, None, 512)   2048      
_________________________________________________________________
conv_dw_8_relu (ReLU)        (None, None, None, 512)   0         
_________________________________________________________________
conv_pw_8 (Conv2D)           (None, None, None, 512)   262144    
_________________________________________________________________
conv_pw_8_bn (BatchNormaliza (None, None, None, 512)   2048      
_________________________________________________________________
conv_pw_8_relu (ReLU)        (None, None, None, 512)   0         
_________________________________________________________________
conv_dw_9 (DepthwiseConv2D)  (None, None, None, 512)   4608      
_________________________________________________________________
conv_dw_9_bn (BatchNormaliza (None, None, None, 512)   2048      
_________________________________________________________________
conv_dw_9_relu (ReLU)        (None, None, None, 512)   0         
_________________________________________________________________
conv_pw_9 (Conv2D)           (None, None, None, 512)   262144    
_________________________________________________________________
conv_pw_9_bn (BatchNormaliza (None, None, None, 512)   2048      
_________________________________________________________________
conv_pw_9_relu (ReLU)        (None, None, None, 512)   0         
_________________________________________________________________
conv_dw_10 (DepthwiseConv2D) (None, None, None, 512)   4608      
_________________________________________________________________
conv_dw_10_bn (BatchNormaliz (None, None, None, 512)   2048      
_________________________________________________________________
conv_dw_10_relu (ReLU)       (None, None, None, 512)   0         
_________________________________________________________________
conv_pw_10 (Conv2D)          (None, None, None, 512)   262144    
_________________________________________________________________
conv_pw_10_bn (BatchNormaliz (None, None, None, 512)   2048      
_________________________________________________________________
conv_pw_10_relu (ReLU)       (None, None, None, 512)   0         
_________________________________________________________________
conv_dw_11 (DepthwiseConv2D) (None, None, None, 512)   4608      
_________________________________________________________________
conv_dw_11_bn (BatchNormaliz (None, None, None, 512)   2048      
_________________________________________________________________
conv_dw_11_relu (ReLU)       (None, None, None, 512)   0         
_________________________________________________________________
conv_pw_11 (Conv2D)          (None, None, None, 512)   262144    
_________________________________________________________________
conv_pw_11_bn (BatchNormaliz (None, None, None, 512)   2048      
_________________________________________________________________
conv_pw_11_relu (ReLU)       (None, None, None, 512)   0         
_________________________________________________________________
conv_pad_12 (ZeroPadding2D)  (None, None, None, 512)   0         
_________________________________________________________________
conv_dw_12 (DepthwiseConv2D) (None, None, None, 512)   4608      
_________________________________________________________________
conv_dw_12_bn (BatchNormaliz (None, None, None, 512)   2048      
_________________________________________________________________
conv_dw_12_relu (ReLU)       (None, None, None, 512)   0         
_________________________________________________________________
conv_pw_12 (Conv2D)          (None, None, None, 1024)  524288    
_________________________________________________________________
conv_pw_12_bn (BatchNormaliz (None, None, None, 1024)  4096      
_________________________________________________________________
conv_pw_12_relu (ReLU)       (None, None, None, 1024)  0         
_________________________________________________________________
conv_dw_13 (DepthwiseConv2D) (None, None, None, 1024)  9216      
_________________________________________________________________
conv_dw_13_bn (BatchNormaliz (None, None, None, 1024)  4096      
_________________________________________________________________
conv_dw_13_relu (ReLU)       (None, None, None, 1024)  0         
_________________________________________________________________
conv_pw_13 (Conv2D)          (None, None, None, 1024)  1048576   
_________________________________________________________________
conv_pw_13_bn (BatchNormaliz (None, None, None, 1024)  4096      
_________________________________________________________________
conv_pw_13_relu (ReLU)       (None, None, None, 1024)  0         
_________________________________________________________________
global_average_pooling2d (Gl (None, 1024)              0         
_________________________________________________________________
dense (Dense)                (None, 64)                65600     
_________________________________________________________________
dense_1 (Dense)              (None, 10)                650       
=================================================================
Total params: 3,295,114
Trainable params: 3,273,226
Non-trainable params: 21,888
_________________________________________________________________
None
  0%|          | 0/89 [00:00<?, ?it/s]load MobileNet...
2021-03-03 22:47:26.415592: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2021-03-03 22:47:26.443229: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2021-03-03 22:47:26.443290: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: dell-PowerEdge-R940xa
2021-03-03 22:47:26.443296: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: dell-PowerEdge-R940xa
2021-03-03 22:47:26.443415: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 418.113.0
2021-03-03 22:47:26.443435: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.113.0
2021-03-03 22:47:26.443440: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 418.113.0
2021-03-03 22:47:26.443613: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2021-03-03 22:47:26.482006: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2600000000 Hz
2021-03-03 22:47:26.487412: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5556508a4690 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-03-03 22:47:26.487456: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
 87%|████████▋ | 171/196 [13:09<02:39,  6.37s/it]/media/data1/DeepSuite/trained_models/cifar10/MobileNet.h5
Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         [(None, None, None, 3)]   0         
_________________________________________________________________
conv1_pad (ZeroPadding2D)    (None, None, None, 3)     0         
_________________________________________________________________
conv1 (Conv2D)               (None, None, None, 32)    864       
_________________________________________________________________
conv1_bn (BatchNormalization (None, None, None, 32)    128       
_________________________________________________________________
conv1_relu (ReLU)            (None, None, None, 32)    0         
_________________________________________________________________
conv_dw_1 (DepthwiseConv2D)  (None, None, None, 32)    288       
_________________________________________________________________
conv_dw_1_bn (BatchNormaliza (None, None, None, 32)    128       
_________________________________________________________________
conv_dw_1_relu (ReLU)        (None, None, None, 32)    0         
_________________________________________________________________
conv_pw_1 (Conv2D)           (None, None, None, 64)    2048      
_________________________________________________________________
conv_pw_1_bn (BatchNormaliza (None, None, None, 64)    256       
_________________________________________________________________
conv_pw_1_relu (ReLU)        (None, None, None, 64)    0         
_________________________________________________________________
conv_pad_2 (ZeroPadding2D)   (None, None, None, 64)    0         
_________________________________________________________________
conv_dw_2 (DepthwiseConv2D)  (None, None, None, 64)    576       
_________________________________________________________________
conv_dw_2_bn (BatchNormaliza (None, None, None, 64)    256       
_________________________________________________________________
conv_dw_2_relu (ReLU)        (None, None, None, 64)    0         
_________________________________________________________________
conv_pw_2 (Conv2D)           (None, None, None, 128)   8192      
_________________________________________________________________
conv_pw_2_bn (BatchNormaliza (None, None, None, 128)   512       
_________________________________________________________________
conv_pw_2_relu (ReLU)        (None, None, None, 128)   0         
_________________________________________________________________
conv_dw_3 (DepthwiseConv2D)  (None, None, None, 128)   1152      
_________________________________________________________________
conv_dw_3_bn (BatchNormaliza (None, None, None, 128)   512       
_________________________________________________________________
conv_dw_3_relu (ReLU)        (None, None, None, 128)   0         
_________________________________________________________________
conv_pw_3 (Conv2D)           (None, None, None, 128)   16384     
_________________________________________________________________
conv_pw_3_bn (BatchNormaliza (None, None, None, 128)   512       
_________________________________________________________________
conv_pw_3_relu (ReLU)        (None, None, None, 128)   0         
_________________________________________________________________
conv_pad_4 (ZeroPadding2D)   (None, None, None, 128)   0         
_________________________________________________________________
conv_dw_4 (DepthwiseConv2D)  (None, None, None, 128)   1152      
_________________________________________________________________
conv_dw_4_bn (BatchNormaliza (None, None, None, 128)   512       
_________________________________________________________________
conv_dw_4_relu (ReLU)        (None, None, None, 128)   0         
_________________________________________________________________
conv_pw_4 (Conv2D)           (None, None, None, 256)   32768     
_________________________________________________________________
conv_pw_4_bn (BatchNormaliza (None, None, None, 256)   1024      
_________________________________________________________________
conv_pw_4_relu (ReLU)        (None, None, None, 256)   0         
_________________________________________________________________
conv_dw_5 (DepthwiseConv2D)  (None, None, None, 256)   2304      
_________________________________________________________________
conv_dw_5_bn (BatchNormaliza (None, None, None, 256)   1024      
_________________________________________________________________
conv_dw_5_relu (ReLU)        (None, None, None, 256)   0         
_________________________________________________________________
conv_pw_5 (Conv2D)           (None, None, None, 256)   65536     
_________________________________________________________________
conv_pw_5_bn (BatchNormaliza (None, None, None, 256)   1024      
_________________________________________________________________
conv_pw_5_relu (ReLU)        (None, None, None, 256)   0         
_________________________________________________________________
conv_pad_6 (ZeroPadding2D)   (None, None, None, 256)   0         
_________________________________________________________________
conv_dw_6 (DepthwiseConv2D)  (None, None, None, 256)   2304      
_________________________________________________________________
conv_dw_6_bn (BatchNormaliza (None, None, None, 256)   1024      
_________________________________________________________________
conv_dw_6_relu (ReLU)        (None, None, None, 256)   0         
_________________________________________________________________
conv_pw_6 (Conv2D)           (None, None, None, 512)   131072    
_________________________________________________________________
conv_pw_6_bn (BatchNormaliza (None, None, None, 512)   2048      
_________________________________________________________________
conv_pw_6_relu (ReLU)        (None, None, None, 512)   0         
_________________________________________________________________
conv_dw_7 (DepthwiseConv2D)  (None, None, None, 512)   4608      
_________________________________________________________________
conv_dw_7_bn (BatchNormaliza (None, None, None, 512)   2048      
_________________________________________________________________
conv_dw_7_relu (ReLU)        (None, None, None, 512)   0         
_________________________________________________________________
conv_pw_7 (Conv2D)           (None, None, None, 512)   262144    
_________________________________________________________________
conv_pw_7_bn (BatchNormaliza (None, None, None, 512)   2048      
_________________________________________________________________
conv_pw_7_relu (ReLU)        (None, None, None, 512)   0         
_________________________________________________________________
conv_dw_8 (DepthwiseConv2D)  (None, None, None, 512)   4608      
_________________________________________________________________
conv_dw_8_bn (BatchNormaliza (None, None, None, 512)   2048      
_________________________________________________________________
conv_dw_8_relu (ReLU)        (None, None, None, 512)   0         
_________________________________________________________________
conv_pw_8 (Conv2D)           (None, None, None, 512)   262144    
_________________________________________________________________
conv_pw_8_bn (BatchNormaliza (None, None, None, 512)   2048      
_________________________________________________________________
conv_pw_8_relu (ReLU)        (None, None, None, 512)   0         
_________________________________________________________________
conv_dw_9 (DepthwiseConv2D)  (None, None, None, 512)   4608      
_________________________________________________________________
conv_dw_9_bn (BatchNormaliza (None, None, None, 512)   2048      
_________________________________________________________________
conv_dw_9_relu (ReLU)        (None, None, None, 512)   0         
_________________________________________________________________
conv_pw_9 (Conv2D)           (None, None, None, 512)   262144    
_________________________________________________________________
conv_pw_9_bn (BatchNormaliza (None, None, None, 512)   2048      
_________________________________________________________________
conv_pw_9_relu (ReLU)        (None, None, None, 512)   0         
_________________________________________________________________
conv_dw_10 (DepthwiseConv2D) (None, None, None, 512)   4608      
_________________________________________________________________
conv_dw_10_bn (BatchNormaliz (None, None, None, 512)   2048      
_________________________________________________________________
conv_dw_10_relu (ReLU)       (None, None, None, 512)   0         
_________________________________________________________________
conv_pw_10 (Conv2D)          (None, None, None, 512)   262144    
_________________________________________________________________
conv_pw_10_bn (BatchNormaliz (None, None, None, 512)   2048      
_________________________________________________________________
conv_pw_10_relu (ReLU)       (None, None, None, 512)   0         
_________________________________________________________________
conv_dw_11 (DepthwiseConv2D) (None, None, None, 512)   4608      
_________________________________________________________________
conv_dw_11_bn (BatchNormaliz (None, None, None, 512)   2048      
_________________________________________________________________
conv_dw_11_relu (ReLU)       (None, None, None, 512)   0         
_________________________________________________________________
conv_pw_11 (Conv2D)          (None, None, None, 512)   262144    
_________________________________________________________________
conv_pw_11_bn (BatchNormaliz (None, None, None, 512)   2048      
_________________________________________________________________
conv_pw_11_relu (ReLU)       (None, None, None, 512)   0         
_________________________________________________________________
conv_pad_12 (ZeroPadding2D)  (None, None, None, 512)   0         
_________________________________________________________________
conv_dw_12 (DepthwiseConv2D) (None, None, None, 512)   4608      
_________________________________________________________________
conv_dw_12_bn (BatchNormaliz (None, None, None, 512)   2048      
_________________________________________________________________
conv_dw_12_relu (ReLU)       (None, None, None, 512)   0         
_________________________________________________________________
conv_pw_12 (Conv2D)          (None, None, None, 1024)  524288    
_________________________________________________________________
conv_pw_12_bn (BatchNormaliz (None, None, None, 1024)  4096      
_________________________________________________________________
conv_pw_12_relu (ReLU)       (None, None, None, 1024)  0         
_________________________________________________________________
conv_dw_13 (DepthwiseConv2D) (None, None, None, 1024)  9216      
_________________________________________________________________
conv_dw_13_bn (BatchNormaliz (None, None, None, 1024)  4096      
_________________________________________________________________
conv_dw_13_relu (ReLU)       (None, None, None, 1024)  0         
_________________________________________________________________
conv_pw_13 (Conv2D)          (None, None, None, 1024)  1048576   
_________________________________________________________________
conv_pw_13_bn (BatchNormaliz (None, None, None, 1024)  4096      
_________________________________________________________________
conv_pw_13_relu (ReLU)       (None, None, None, 1024)  0         
_________________________________________________________________
global_average_pooling2d (Gl (None, 1024)              0         
_________________________________________________________________
dense (Dense)                (None, 64)                65600     
_________________________________________________________________
dense_1 (Dense)              (None, 10)                650       
=================================================================
Total params: 3,295,114
Trainable params: 3,273,226
Non-trainable params: 21,888
_________________________________________________________________
None
  0%|          | 0/89 [00:00<?, ?it/s]  1%|          | 1/89 [00:05<07:27,  5.08s/it]2021-03-03 22:47:29.451424: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
  1%|          | 1/89 [00:03<04:29,  3.06s/it]2021-03-03 22:47:31.777225: W tensorflow/stream_executor/gpu/asm_compiler.cc:116] *** WARNING *** You are using ptxas 9.1.108, which is older than 9.2.88. ptxas 9.x before 9.2.88 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You do not need to update to CUDA 9.2.88; cherry-picking the ptxas binary is sufficient.
2021-03-03 22:47:32.110556: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 65280, output: ptxas fatal   : Value 'sm_75' is not defined for option 'gpu-name'

Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
 88%|████████▊ | 172/196 [13:16<02:36,  6.52s/it]2021-03-03 22:47:36.350304: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
 88%|████████▊ | 173/196 [13:22<02:29,  6.48s/it] 89%|████████▉ | 174/196 [13:29<02:24,  6.56s/it]  2%|▏         | 2/89 [00:19<16:13, 11.18s/it] 89%|████████▉ | 175/196 [13:37<02:27,  7.02s/it]  2%|▏         | 2/89 [00:36<30:09, 20.80s/it] 90%|████████▉ | 176/196 [13:43<02:15,  6.77s/it] 90%|█████████ | 177/196 [13:49<02:06,  6.64s/it]  3%|▎         | 3/89 [00:40<22:23, 15.62s/it] 91%|█████████ | 178/196 [13:56<02:00,  6.68s/it]  3%|▎         | 3/89 [00:55<28:18, 19.75s/it] 91%|█████████▏| 179/196 [14:03<01:53,  6.65s/it]  4%|▍         | 4/89 [00:57<22:53, 16.16s/it] 92%|█████████▏| 180/196 [14:11<01:54,  7.16s/it] 92%|█████████▏| 181/196 [14:18<01:44,  6.94s/it]  4%|▍         | 4/89 [01:13<26:49, 18.94s/it]  6%|▌         | 5/89 [01:15<23:10, 16.55s/it] 93%|█████████▎| 182/196 [14:25<01:39,  7.07s/it] 93%|█████████▎| 183/196 [14:32<01:32,  7.14s/it]  6%|▌         | 5/89 [01:32<26:52, 19.20s/it] 94%|█████████▍| 184/196 [14:39<01:22,  6.89s/it]  7%|▋         | 6/89 [01:32<23:06, 16.71s/it] 94%|█████████▍| 185/196 [14:46<01:16,  6.93s/it] 95%|█████████▍| 186/196 [14:52<01:08,  6.82s/it] 95%|█████████▌| 187/196 [14:58<01:00,  6.68s/it]  8%|▊         | 7/89 [01:49<23:08, 16.94s/it]  7%|▋         | 6/89 [01:54<27:58, 20.23s/it] 96%|█████████▌| 188/196 [15:06<00:54,  6.80s/it] 96%|█████████▋| 189/196 [15:12<00:47,  6.83s/it]  8%|▊         | 7/89 [02:12<26:23, 19.31s/it] 97%|█████████▋| 190/196 [15:19<00:39,  6.65s/it] 97%|█████████▋| 191/196 [15:25<00:32,  6.51s/it]  9%|▉         | 8/89 [02:19<28:23, 21.03s/it] 98%|█████████▊| 192/196 [15:32<00:26,  6.70s/it] 98%|█████████▊| 193/196 [15:38<00:19,  6.62s/it] 99%|█████████▉| 194/196 [15:45<00:13,  6.58s/it] 99%|█████████▉| 195/196 [15:51<00:06,  6.48s/it]100%|██████████| 196/196 [15:53<00:00,  5.07s/it]100%|██████████| 196/196 [15:53<00:00,  4.86s/it]
 10%|█         | 9/89 [02:48<31:25, 23.57s/it]  9%|▉         | 8/89 [03:05<40:48, 30.23s/it] 11%|█         | 10/89 [03:16<33:02, 25.10s/it] 10%|█         | 9/89 [03:39<41:46, 31.33s/it] 12%|█▏        | 11/89 [03:47<34:38, 26.64s/it] 11%|█         | 10/89 [04:12<41:45, 31.71s/it] 13%|█▎        | 12/89 [04:16<35:07, 27.38s/it] 12%|█▏        | 11/89 [04:45<41:50, 32.19s/it] 15%|█▍        | 13/89 [04:44<34:56, 27.58s/it] 13%|█▎        | 12/89 [05:14<39:51, 31.06s/it] 16%|█▌        | 14/89 [05:12<34:47, 27.83s/it] 15%|█▍        | 13/89 [05:42<38:14, 30.19s/it] 16%|█▌        | 14/89 [06:09<36:34, 29.26s/it] 17%|█▋        | 15/89 [06:05<43:42, 35.44s/it] 18%|█▊        | 16/89 [06:58<49:37, 40.78s/it] 17%|█▋        | 15/89 [07:24<53:08, 43.09s/it] 19%|█▉        | 17/89 [07:52<53:43, 44.77s/it] 18%|█▊        | 16/89 [08:19<56:54, 46.77s/it] 20%|██        | 18/89 [08:46<55:59, 47.31s/it] 19%|█▉        | 17/89 [09:12<58:20, 48.61s/it] 21%|██▏       | 19/89 [09:40<57:35, 49.37s/it] 20%|██        | 18/89 [10:06<59:13, 50.05s/it] 22%|██▏       | 20/89 [10:34<58:18, 50.70s/it] 21%|██▏       | 19/89 [11:02<1:00:40, 52.01s/it] 24%|██▎       | 21/89 [11:27<58:29, 51.61s/it] 22%|██▏       | 20/89 [11:58<1:01:14, 53.26s/it] 25%|██▍       | 22/89 [12:21<58:14, 52.16s/it] 24%|██▎       | 21/89 [13:18<1:09:24, 61.24s/it] 26%|██▌       | 23/89 [13:15<58:01, 52.74s/it] 27%|██▋       | 24/89 [14:08<57:21, 52.95s/it] 25%|██▍       | 22/89 [14:15<1:06:50, 59.85s/it] 28%|██▊       | 25/89 [15:02<56:42, 53.17s/it] 26%|██▌       | 23/89 [15:11<1:04:31, 58.66s/it] 29%|██▉       | 26/89 [15:56<55:56, 53.27s/it] 27%|██▋       | 24/89 [16:08<1:03:07, 58.26s/it] 30%|███       | 27/89 [16:50<55:25, 53.63s/it] 28%|██▊       | 25/89 [17:02<1:00:47, 57.00s/it] 29%|██▉       | 26/89 [17:55<58:31, 55.74s/it]   31%|███▏      | 28/89 [18:32<1:09:19, 68.19s/it] 30%|███       | 27/89 [18:49<57:10, 55.34s/it] 33%|███▎      | 29/89 [20:15<1:18:39, 78.66s/it] 31%|███▏      | 28/89 [21:01<1:19:29, 78.19s/it] 34%|███▎      | 30/89 [21:58<1:24:30, 85.94s/it] 33%|███▎      | 29/89 [22:46<1:26:08, 86.15s/it] 35%|███▍      | 31/89 [23:42<1:28:08, 91.18s/it] 34%|███▎      | 30/89 [24:29<1:29:44, 91.26s/it] 36%|███▌      | 32/89 [25:24<1:29:56, 94.68s/it] 35%|███▍      | 31/89 [26:11<1:31:29, 94.64s/it] 37%|███▋      | 33/89 [27:08<1:30:56, 97.43s/it] 36%|███▌      | 32/89 [27:56<1:32:55, 97.81s/it] 38%|███▊      | 34/89 [28:51<1:30:48, 99.06s/it] 37%|███▋      | 33/89 [29:39<1:32:39, 99.28s/it] 39%|███▉      | 35/89 [30:34<1:30:06, 100.11s/it] 38%|███▊      | 34/89 [32:00<1:42:30, 111.83s/it] 40%|████      | 36/89 [32:17<1:29:09, 100.93s/it] 39%|███▉      | 35/89 [33:43<1:38:08, 109.04s/it] 42%|████▏     | 37/89 [33:59<1:27:59, 101.53s/it] 40%|████      | 36/89 [35:27<1:35:05, 107.64s/it] 43%|████▎     | 38/89 [35:41<1:26:21, 101.60s/it] 42%|████▏     | 37/89 [37:12<1:32:28, 106.71s/it] 44%|████▍     | 39/89 [37:24<1:24:55, 101.92s/it] 43%|████▎     | 38/89 [38:53<1:29:18, 105.06s/it] 45%|████▍     | 40/89 [39:06<1:23:19, 102.03s/it] 44%|████▍     | 39/89 [40:36<1:27:10, 104.61s/it] 45%|████▍     | 40/89 [42:17<1:24:21, 103.29s/it] 46%|████▌     | 41/89 [43:17<1:57:14, 146.54s/it] 46%|████▌     | 41/89 [46:18<1:55:52, 144.83s/it] 47%|████▋     | 42/89 [46:33<2:06:37, 161.65s/it] 47%|████▋     | 42/89 [49:44<2:07:36, 162.91s/it] 48%|████▊     | 43/89 [49:51<2:12:16, 172.53s/it] 48%|████▊     | 43/89 [53:06<2:13:57, 174.74s/it] 49%|████▉     | 44/89 [53:11<2:15:34, 180.76s/it] 49%|████▉     | 44/89 [56:28<2:17:11, 182.92s/it] 51%|█████     | 45/89 [56:28<2:16:08, 185.64s/it] 52%|█████▏    | 46/89 [59:46<2:15:31, 189.11s/it] 51%|█████     | 45/89 [59:52<2:18:48, 189.27s/it] 53%|█████▎    | 47/89 [1:03:04<2:14:20, 191.92s/it] 52%|█████▏    | 46/89 [1:03:15<2:18:34, 193.36s/it] 54%|█████▍    | 48/89 [1:06:21<2:12:05, 193.31s/it] 53%|█████▎    | 47/89 [1:07:11<2:24:25, 206.32s/it] 55%|█████▌    | 49/89 [1:09:40<2:10:09, 195.23s/it] 54%|█████▍    | 48/89 [1:10:32<2:19:47, 204.58s/it] 56%|█████▌    | 50/89 [1:12:59<2:07:38, 196.38s/it] 55%|█████▌    | 49/89 [1:13:57<2:16:32, 204.81s/it] 57%|█████▋    | 51/89 [1:16:17<2:04:35, 196.74s/it] 56%|█████▌    | 50/89 [1:17:21<2:12:53, 204.44s/it] 58%|█████▊    | 52/89 [1:19:37<2:01:56, 197.75s/it] 57%|█████▋    | 51/89 [1:21:14<2:14:51, 212.95s/it] 60%|█████▉    | 53/89 [1:22:59<1:59:27, 199.09s/it] 58%|█████▊    | 52/89 [1:24:49<2:11:47, 213.71s/it] 61%|██████    | 54/89 [1:26:18<1:55:59, 198.85s/it] 60%|█████▉    | 53/89 [1:28:06<2:05:13, 208.70s/it] 62%|██████▏   | 55/89 [1:29:38<1:53:01, 199.46s/it] 61%|██████    | 54/89 [1:31:20<1:59:10, 204.31s/it] 63%|██████▎   | 56/89 [1:32:59<1:49:57, 199.92s/it] 62%|██████▏   | 55/89 [1:34:35<1:54:09, 201.46s/it] 64%|██████▍   | 57/89 [1:36:21<1:46:56, 200.52s/it] 63%|██████▎   | 56/89 [1:37:50<1:49:39, 199.39s/it] 65%|██████▌   | 58/89 [1:39:41<1:43:32, 200.40s/it] 64%|██████▍   | 57/89 [1:41:05<1:45:39, 198.12s/it] 66%|██████▋   | 59/89 [1:43:55<1:48:12, 216.42s/it] 65%|██████▌   | 58/89 [1:44:23<1:42:21, 198.12s/it] 67%|██████▋   | 60/89 [1:47:16<1:42:19, 211.71s/it] 66%|██████▋   | 59/89 [1:47:36<1:38:17, 196.59s/it] 69%|██████▊   | 61/89 [1:50:37<1:37:18, 208.52s/it] 67%|██████▋   | 60/89 [1:50:49<1:34:28, 195.47s/it] 69%|██████▊   | 61/89 [1:54:00<1:30:37, 194.21s/it] 70%|██████▉   | 62/89 [1:53:59<1:32:58, 206.60s/it] 70%|██████▉   | 62/89 [1:57:16<1:27:36, 194.68s/it] 71%|███████   | 63/89 [1:57:22<1:28:59, 205.37s/it] 71%|███████   | 63/89 [2:00:31<1:24:26, 194.85s/it] 72%|███████▏  | 64/89 [2:00:44<1:25:13, 204.55s/it] 72%|███████▏  | 64/89 [2:03:49<1:21:33, 195.73s/it] 73%|███████▎  | 65/89 [2:04:10<1:21:55, 204.81s/it] 73%|███████▎  | 65/89 [2:07:05<1:18:23, 195.98s/it] 74%|███████▍  | 66/89 [2:07:32<1:18:10, 203.92s/it] 74%|███████▍  | 66/89 [2:10:18<1:14:46, 195.05s/it] 75%|███████▌  | 67/89 [2:10:54<1:14:34, 203.39s/it] 75%|███████▌  | 67/89 [2:13:34<1:11:35, 195.25s/it] 76%|███████▋  | 68/89 [2:14:17<1:11:07, 203.20s/it] 76%|███████▋  | 68/89 [2:16:50<1:08:25, 195.51s/it] 78%|███████▊  | 69/89 [2:17:41<1:07:50, 203.53s/it] 78%|███████▊  | 69/89 [2:20:08<1:05:25, 196.25s/it] 79%|███████▊  | 70/89 [2:21:02<1:04:15, 202.93s/it] 79%|███████▊  | 70/89 [2:24:04<1:05:56, 208.23s/it] 80%|███████▉  | 71/89 [2:24:25<1:00:53, 202.99s/it] 80%|███████▉  | 71/89 [2:27:19<1:01:16, 204.27s/it] 81%|████████  | 72/89 [2:27:49<57:31, 203.02s/it]   81%|████████  | 72/89 [2:30:31<56:49, 200.53s/it]   82%|████████▏ | 73/89 [2:31:12<54:10, 203.15s/it] 82%|████████▏ | 73/89 [2:33:48<53:12, 199.53s/it] 83%|████████▎ | 74/89 [2:34:34<50:44, 202.94s/it] 83%|████████▎ | 74/89 [2:37:01<49:22, 197.51s/it] 84%|████████▍ | 75/89 [2:37:59<47:28, 203.47s/it] 84%|████████▍ | 75/89 [2:40:19<46:05, 197.57s/it] 85%|████████▌ | 76/89 [2:41:25<44:13, 204.12s/it] 85%|████████▌ | 76/89 [2:43:34<42:38, 196.77s/it] 87%|████████▋ | 77/89 [2:44:50<40:51, 204.30s/it] 87%|████████▋ | 77/89 [2:46:51<39:22, 196.84s/it] 88%|████████▊ | 78/89 [2:51:27<48:05, 262.34s/it] 88%|████████▊ | 78/89 [2:53:43<47:54, 261.34s/it] 89%|████████▉ | 79/89 [2:58:07<50:34, 303.47s/it] 89%|████████▉ | 79/89 [3:00:12<49:58, 299.87s/it] 90%|████████▉ | 80/89 [3:04:46<49:49, 332.17s/it] 90%|████████▉ | 80/89 [3:08:26<53:42, 358.03s/it] 91%|█████████ | 81/89 [3:11:28<47:05, 353.17s/it] 91%|█████████ | 81/89 [3:16:45<53:21, 400.17s/it] 92%|█████████▏| 82/89 [3:18:06<42:47, 366.73s/it] 93%|█████████▎| 83/89 [3:24:45<37:38, 376.38s/it] 92%|█████████▏| 82/89 [3:25:02<50:05, 429.40s/it] 93%|█████████▎| 83/89 [3:31:26<41:35, 415.86s/it] 94%|█████████▍| 84/89 [3:31:27<31:59, 383.88s/it] 96%|█████████▌| 85/89 [3:38:10<25:59, 389.81s/it] 94%|█████████▍| 84/89 [3:38:28<34:47, 417.53s/it] 97%|█████████▋| 86/89 [3:44:48<19:36, 392.10s/it] 96%|█████████▌| 85/89 [3:44:53<27:11, 407.83s/it] 98%|█████████▊| 87/89 [3:45:04<09:18, 279.38s/it] 99%|█████████▉| 88/89 [3:45:21<03:20, 200.48s/it]100%|██████████| 89/89 [3:45:37<00:00, 145.23s/it]100%|██████████| 89/89 [3:45:37<00:00, 152.10s/it]
  0%|          | 0/89 [00:00<?, ?it/s]  1%|          | 1/89 [00:00<00:40,  2.16it/s]  2%|▏         | 2/89 [00:03<02:38,  1.82s/it]  3%|▎         | 3/89 [00:06<03:16,  2.28s/it]  4%|▍         | 4/89 [00:08<03:34,  2.52s/it]  6%|▌         | 5/89 [00:11<03:46,  2.70s/it]  7%|▋         | 6/89 [00:15<03:56,  2.85s/it]  8%|▊         | 7/89 [00:18<03:58,  2.91s/it]  9%|▉         | 8/89 [00:23<05:11,  3.84s/it] 10%|█         | 9/89 [00:29<05:56,  4.45s/it] 11%|█         | 10/89 [00:35<06:22,  4.84s/it] 12%|█▏        | 11/89 [00:41<06:45,  5.19s/it] 13%|█▎        | 12/89 [00:47<06:48,  5.31s/it] 15%|█▍        | 13/89 [00:53<07:17,  5.75s/it] 16%|█▌        | 14/89 [01:00<07:34,  6.06s/it] 17%|█▋        | 15/89 [01:11<09:08,  7.41s/it] 18%|█▊        | 16/89 [01:21<10:08,  8.34s/it] 19%|█▉        | 17/89 [01:32<10:44,  8.95s/it] 20%|██        | 18/89 [01:42<11:08,  9.42s/it] 21%|██▏       | 19/89 [01:53<11:27,  9.82s/it] 22%|██▏       | 20/89 [02:03<11:34, 10.06s/it] 24%|██▎       | 21/89 [02:14<11:42, 10.33s/it] 25%|██▍       | 22/89 [02:25<11:41, 10.47s/it] 26%|██▌       | 23/89 [02:36<11:34, 10.52s/it] 27%|██▋       | 24/89 [02:47<11:29, 10.60s/it] 28%|██▊       | 25/89 [03:00<12:04, 11.33s/it] 29%|██▉       | 26/89 [03:10<11:37, 11.08s/it] 30%|███       | 27/89 [03:23<12:10, 11.78s/it] 31%|███▏      | 28/89 [03:44<14:29, 14.25s/it] 33%|███▎      | 29/89 [04:03<15:57, 15.96s/it] 34%|███▎      | 30/89 [04:24<17:06, 17.39s/it] 35%|███▍      | 31/89 [04:45<17:45, 18.37s/it] 36%|███▌      | 32/89 [05:05<18:04, 19.03s/it] 37%|███▋      | 33/89 [05:26<18:11, 19.50s/it] 97%|█████████▋| 86/89 [3:51:32<20:15, 405.27s/it] 38%|███▊      | 34/89 [05:52<19:32, 21.32s/it] 98%|█████████▊| 87/89 [3:51:39<09:31, 285.63s/it] 99%|█████████▉| 88/89 [3:51:42<03:20, 200.99s/it]100%|██████████| 89/89 [3:51:46<00:00, 141.82s/it]100%|██████████| 89/89 [3:51:46<00:00, 156.25s/it]
  0%|          | 0/89 [00:00<?, ?it/s]  1%|          | 1/89 [00:00<01:25,  1.03it/s] 39%|███▉      | 35/89 [06:13<19:05, 21.21s/it]  2%|▏         | 2/89 [00:15<13:07,  9.05s/it]  3%|▎         | 3/89 [00:19<09:17,  6.48s/it]  4%|▍         | 4/89 [00:22<07:31,  5.31s/it]  6%|▌         | 5/89 [00:26<06:51,  4.90s/it] 40%|████      | 36/89 [06:33<18:32, 20.99s/it]  7%|▋         | 6/89 [00:31<06:33,  4.74s/it]  8%|▊         | 7/89 [00:34<05:53,  4.31s/it] 42%|████▏     | 37/89 [06:53<18:02, 20.81s/it]  9%|▉         | 8/89 [00:58<14:24, 10.68s/it] 10%|█         | 9/89 [01:05<12:22,  9.28s/it] 43%|████▎     | 38/89 [07:14<17:40, 20.79s/it] 11%|█         | 10/89 [01:12<11:31,  8.76s/it] 12%|█▏        | 11/89 [01:19<10:28,  8.06s/it] 13%|█▎        | 12/89 [01:26<09:52,  7.70s/it] 15%|█▍        | 13/89 [01:31<08:53,  7.03s/it] 44%|████▍     | 39/89 [07:40<18:30, 22.21s/it] 16%|█▌        | 14/89 [01:39<09:01,  7.22s/it] 45%|████▍     | 40/89 [08:00<17:44, 21.72s/it] 17%|█▋        | 15/89 [02:07<16:51, 13.67s/it] 18%|█▊        | 16/89 [02:18<15:27, 12.70s/it] 19%|█▉        | 17/89 [02:28<14:23, 12.00s/it] 46%|████▌     | 41/89 [08:39<21:32, 26.92s/it] 20%|██        | 18/89 [02:39<13:52, 11.72s/it] 21%|██▏       | 19/89 [02:51<13:41, 11.74s/it] 22%|██▏       | 20/89 [03:01<13:02, 11.35s/it] 47%|████▋     | 42/89 [09:19<24:11, 30.89s/it] 24%|██▎       | 21/89 [03:26<17:16, 15.24s/it] 25%|██▍       | 22/89 [03:36<15:22, 13.77s/it] 26%|██▌       | 23/89 [03:46<14:00, 12.73s/it] 48%|████▊     | 43/89 [09:59<25:40, 33.49s/it] 27%|██▋       | 24/89 [03:57<13:12, 12.20s/it] 28%|██▊       | 25/89 [04:07<12:20, 11.57s/it] 29%|██▉       | 26/89 [04:17<11:36, 11.06s/it] 30%|███       | 27/89 [04:30<11:56, 11.56s/it] 49%|████▉     | 44/89 [10:40<26:43, 35.63s/it] 31%|███▏      | 28/89 [05:13<21:27, 21.11s/it] 51%|█████     | 45/89 [11:19<26:53, 36.66s/it] 33%|███▎      | 29/89 [05:39<22:19, 22.32s/it] 52%|█████▏    | 46/89 [11:58<26:55, 37.58s/it] 34%|███▎      | 30/89 [06:02<22:19, 22.71s/it] 35%|███▍      | 31/89 [06:24<21:46, 22.53s/it] 53%|█████▎    | 47/89 [12:38<26:44, 38.20s/it] 36%|███▌      | 32/89 [06:44<20:38, 21.73s/it] 37%|███▋      | 33/89 [07:05<20:02, 21.47s/it] 54%|█████▍    | 48/89 [13:18<26:29, 38.77s/it] 38%|███▊      | 34/89 [07:43<24:10, 26.37s/it] 55%|█████▌    | 49/89 [13:57<25:56, 38.90s/it] 39%|███▉      | 35/89 [08:03<21:57, 24.40s/it] 40%|████      | 36/89 [08:22<20:18, 22.99s/it] 42%|████▏     | 37/89 [08:42<19:06, 22.05s/it] 56%|█████▌    | 50/89 [14:48<27:31, 42.35s/it] 43%|████▎     | 38/89 [09:02<18:09, 21.36s/it] 44%|████▍     | 39/89 [09:21<17:19, 20.80s/it] 57%|█████▋    | 51/89 [15:28<26:26, 41.74s/it] 45%|████▍     | 40/89 [09:41<16:44, 20.51s/it] 58%|█████▊    | 52/89 [16:08<25:26, 41.26s/it] 46%|████▌     | 41/89 [10:38<25:05, 31.37s/it] 60%|█████▉    | 53/89 [16:48<24:23, 40.66s/it] 47%|████▋     | 42/89 [11:17<26:18, 33.58s/it] 61%|██████    | 54/89 [17:28<23:41, 40.60s/it] 48%|████▊     | 43/89 [11:55<26:52, 35.06s/it] 62%|██████▏   | 55/89 [18:08<22:53, 40.39s/it] 49%|████▉     | 44/89 [12:35<27:23, 36.53s/it] 63%|██████▎   | 56/89 [18:48<22:07, 40.24s/it] 64%|██████▍   | 57/89 [19:27<21:22, 40.07s/it] 51%|█████     | 45/89 [13:27<30:05, 41.04s/it] 65%|██████▌   | 58/89 [20:07<20:38, 39.95s/it] 52%|█████▏    | 46/89 [14:05<28:53, 40.31s/it] 66%|██████▋   | 59/89 [20:57<21:29, 42.99s/it] 53%|█████▎    | 47/89 [15:02<31:33, 45.08s/it] 67%|██████▋   | 60/89 [21:37<20:20, 42.08s/it] 54%|█████▍    | 48/89 [15:40<29:32, 43.22s/it] 69%|██████▊   | 61/89 [22:17<19:18, 41.36s/it] 55%|█████▌    | 49/89 [16:18<27:43, 41.60s/it] 70%|██████▉   | 62/89 [22:57<18:29, 41.09s/it] 56%|█████▌    | 50/89 [16:57<26:32, 40.82s/it] 71%|███████   | 63/89 [23:37<17:40, 40.78s/it] 57%|█████▋    | 51/89 [17:36<25:31, 40.31s/it] 72%|███████▏  | 64/89 [24:18<16:56, 40.66s/it] 58%|█████▊    | 52/89 [18:15<24:35, 39.89s/it] 73%|███████▎  | 65/89 [24:58<16:10, 40.43s/it] 60%|█████▉    | 53/89 [18:55<23:58, 39.97s/it] 74%|███████▍  | 66/89 [25:38<15:30, 40.45s/it] 61%|██████    | 54/89 [19:38<23:42, 40.63s/it] 75%|███████▌  | 67/89 [26:18<14:48, 40.38s/it] 62%|██████▏   | 55/89 [20:18<22:58, 40.55s/it] 76%|███████▋  | 68/89 [26:59<14:07, 40.37s/it] 63%|██████▎   | 56/89 [20:59<22:19, 40.58s/it] 78%|███████▊  | 69/89 [27:39<13:25, 40.29s/it] 64%|██████▍   | 57/89 [21:40<21:42, 40.71s/it] 79%|███████▊  | 70/89 [28:19<12:46, 40.35s/it] 65%|██████▌   | 58/89 [22:31<22:38, 43.82s/it] 80%|███████▉  | 71/89 [29:00<12:08, 40.44s/it] 66%|██████▋   | 59/89 [23:21<22:50, 45.69s/it] 81%|████████  | 72/89 [29:40<11:28, 40.49s/it] 67%|██████▋   | 60/89 [24:10<22:39, 46.88s/it] 82%|████████▏ | 73/89 [30:21<10:46, 40.44s/it] 83%|████████▎ | 74/89 [31:02<10:09, 40.63s/it] 69%|██████▊   | 61/89 [25:00<22:15, 47.70s/it] 70%|██████▉   | 62/89 [25:39<20:12, 44.92s/it] 84%|████████▍ | 75/89 [31:42<09:28, 40.59s/it] 85%|████████▌ | 76/89 [32:23<08:48, 40.64s/it] 71%|███████   | 63/89 [26:29<20:09, 46.51s/it] 87%|████████▋ | 77/89 [33:04<08:09, 40.77s/it] 72%|███████▏  | 64/89 [27:15<19:20, 46.41s/it] 73%|███████▎  | 65/89 [27:53<17:35, 43.99s/it] 88%|████████▊ | 78/89 [34:23<09:33, 52.09s/it] 74%|███████▍  | 66/89 [28:32<16:16, 42.47s/it] 75%|███████▌  | 67/89 [29:11<15:08, 41.29s/it] 89%|████████▉ | 79/89 [35:42<10:02, 60.21s/it] 76%|███████▋  | 68/89 [29:50<14:16, 40.78s/it] 78%|███████▊  | 69/89 [30:29<13:20, 40.04s/it] 90%|████████▉ | 80/89 [37:01<09:53, 65.99s/it] 79%|███████▊  | 70/89 [31:08<12:36, 39.79s/it] 80%|███████▉  | 71/89 [31:48<12:00, 40.02s/it] 91%|█████████ | 81/89 [38:20<09:19, 69.89s/it] 81%|████████  | 72/89 [32:30<11:27, 40.45s/it] 82%|████████▏ | 73/89 [33:09<10:42, 40.17s/it] 92%|█████████▏| 82/89 [39:39<08:28, 72.64s/it] 83%|████████▎ | 74/89 [33:51<10:08, 40.55s/it] 84%|████████▍ | 75/89 [34:31<09:25, 40.38s/it] 93%|█████████▎| 83/89 [40:58<07:26, 74.44s/it] 85%|████████▌ | 76/89 [35:12<08:50, 40.77s/it] 87%|████████▋ | 77/89 [35:52<08:05, 40.50s/it] 94%|█████████▍| 84/89 [42:17<06:19, 75.93s/it] 88%|████████▊ | 78/89 [37:28<10:26, 56.93s/it] 96%|█████████▌| 85/89 [43:37<05:08, 77.07s/it] 89%|████████▉ | 79/89 [38:46<10:33, 63.37s/it] 97%|█████████▋| 86/89 [44:56<03:53, 77.73s/it] 98%|█████████▊| 87/89 [45:00<01:51, 55.51s/it] 99%|█████████▉| 88/89 [45:04<00:39, 39.91s/it]100%|██████████| 89/89 [45:07<00:00, 29.08s/it]100%|██████████| 89/89 [45:07<00:00, 30.43s/it]
 90%|████████▉ | 80/89 [40:05<10:12, 68.08s/it] 91%|█████████ | 81/89 [41:20<09:21, 70.20s/it] 92%|█████████▏| 82/89 [42:37<08:24, 72.12s/it] 93%|█████████▎| 83/89 [43:53<07:20, 73.39s/it] 94%|█████████▍| 84/89 [45:27<06:38, 79.65s/it] 96%|█████████▌| 85/89 [46:44<05:14, 78.66s/it] 97%|█████████▋| 86/89 [48:00<03:53, 77.93s/it] 98%|█████████▊| 87/89 [48:01<01:49, 54.90s/it] 99%|█████████▉| 88/89 [48:02<00:38, 38.74s/it]100%|██████████| 89/89 [48:06<00:00, 28.20s/it]100%|██████████| 89/89 [48:06<00:00, 32.43s/it]
